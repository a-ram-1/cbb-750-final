{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CBB 750 final project",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgWbhw86P6Xl"
      },
      "source": [
        "# Classifying cardiomyopathy v. coronary artery disease for patients with and without vectorized text data\n",
        "\n",
        "\n",
        "A Ram, Jason Liu, Saejeong Park, Sarah Dudgeon\n",
        "\n",
        "\n",
        "## Here's the basic outline of our project.\n",
        "\n",
        "* We input subject ids and their associated ICD9 codes, NOTEEVENTS data and processed LABEVENTS [\"non-text\"] data\n",
        "* We extract the most recent notes for each patient and run [Doc2Vec](https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html) to create vectors out of each patient's most recent notes\n",
        "  * We consolidate this into a \"text data\" matrix\n",
        "* We combine the text and non-text data matrices by subject id into a new \"text+non-text\" data matrix\n",
        "* We generate labels for text, non-text and text+non-text data matrices based on each patient's ICD9 codes\n",
        "* We classify using GLM [logistic regression], decision tree, SVM, random forest and majority vote\n",
        "  * We run GLM and decision tree with [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) to see if this will improve performance\n",
        "  * We run majority vote to see if a consensus approach will improve performance. We use all other classifiers for the vote, namely:\n",
        "    * GLM \n",
        "    * GLM with boosting\n",
        "    * Decision tree\n",
        "    * Decision tree with boosting\n",
        "    * SVM\n",
        "    * Random forest\n",
        "* We run k-fold cross validation [k=10] to more robustly assess classifier accuracy beyond counting misclassified points\n",
        "* We generate ROC curves/AUC for each classifier to provide another estimate of performance beyond accuracy \n",
        "* We check feature importance [when possible, not all models, like SVM with nonlinear kernel, allow] to better understand why our model performance is often not great \n",
        "\n",
        "\n",
        "**Input files:**\n",
        "\n",
        "* ```SubID_ICD_Disease.csv```, which isolates patients with our ICD codes of interest [generated from ```SubID_ICD_Diseases.ipynb```]\n",
        "\n",
        "* ```nontext/labevents2_processed_matrix.csv```, which takes the \"most recent\" LABEVENTS data for each patient and processes into a matrix [generated from ```nontext/mimic_processing.Rmd```]\n",
        "\n",
        "* ```NOTEEVENTS.csv```, which is just MIMIC ```NOTEEVENTS```` data\n",
        "\n",
        "**Outputs:**\n",
        "\n",
        "* ```noteevents_most_recent.csv```, which contains NOTEEVENTS data and document vectors for each patient\n",
        "* ```textdatamat.csv```, which contains document vectors for each patient [csv form of ```textDataMat```]\n",
        "* ```filledna_processed_nontext.csv```, which contains imputed ```LABEVENTS``` data for each patient [csv form of ```filledna_processed_nontext```]\n",
        "* ```text_nontext_data.csv```, which is a merge of the data ```textdatamat.csv``` and ```filledna_processed_nontext.csv``` [csv form of ```textNontextData```] \n",
        "\n",
        "* Three matrices with text, non-text and text+non-text data: \n",
        "  * ```textDataMat```, which contains document vectors for each patient\n",
        "\n",
        "  * ```filledna_processed_nontext```, which contains imputed ```LABEVENTS``` information for each patient\n",
        "  * ```textNontextData```, which is just the merge of ```textDataMat``` and ```filledna_processed_nontext```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0LLTl3WRTa_"
      },
      "source": [
        "## First we'll mount our drive and import all salient libraries.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1QErK9vVVJa",
        "outputId": "d0186f3a-16f6-48bd-f713-a968e4f1f9bc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# for vectorization of text\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from tqdm import tqdm\n",
        "\n",
        "# for doc2vec, to expedite runtime\n",
        "import multiprocessing\n",
        "\n",
        "# to separate the data into train/test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# for k-fold validation\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# for GLM\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# for decision tree\n",
        "from sklearn import tree\n",
        "\n",
        "# for svm\n",
        "from sklearn import svm\n",
        "\n",
        "# for random forest and majority vote\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "\n",
        "# for adaboost\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# for roc/auc scores\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "# for plotting\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhtIFWwyhGGi"
      },
      "source": [
        "## Next, let's import our data and do some preliminary processing \n",
        "\n",
        "We've already done some of the preprocessing in the script ```SubID_ICD_Diseases.ipynb```. Very quickly, here's what we did: \n",
        "\n",
        "1. Import data from MIMIC-II tables ```D_ICD_DIAGNOSES``` and ```DIAGNOSES_ICD```\n",
        "2. Find ICD-9 codes for \"cardiomyopath\" and \"atherosclerosis\" in ```D_ICD_DIAGNOSES```\n",
        "3. Select rows for patients with the resulting ICD-9 codes in ```DIAGNOSES_ICD```:\n",
        "  \n",
        "  1. [425.11](http://www.icd9data.com/2014/Volume1/390-459/420-429/425/425.11.htm), [425.18](http://www.icd9data.com/2014/Volume1/390-459/420-429/425/425.18.htm) and [425.4](http://www.icd9data.com/2014/Volume1/390-459/420-429/425/425.4.htm) for cardiomyopathy\n",
        "  2. [440.29](http://www.icd9data.com/2014/Volume1/390-459/440-449/440/440.29.htm), [440.9](http://www.icd9data.com/2014/Volume1/390-459/440-449/440/440.9.htm), [414.01](http://www.icd9data.com/2014/Volume1/390-459/410-414/414/414.01.htm) and [414.3](http://www.icd9data.com/2014/Volume1/390-459/410-414/414/414.3.htm) for coronary artery disease\n",
        "4. Combined all into ```SubID_ICD_Disease.csv```. \n",
        "\n",
        "\n",
        "From here we read in that csv file along with MIMIC's ```NOTEEVENTS```.\n",
        "\n",
        "As for the ```LABEVENTS``` data matrix -- we process the data in ```nontext/mimic_processing.R``` and export to ```labevents_processed_matrix.csv```. This data matrix contains all ```LABEVENTS``` data for our patients of interest. We'll use it for classification purposes. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQyeHtDQUaff"
      },
      "source": [
        "# read in saejeong's subject_id with icd codes\n",
        "data = pd.read_csv('/content/drive/MyDrive/cbb 750 final/SubID_ICD_Disease.csv')\n",
        "\n",
        "# read in jason's LABEVENTS data matrix\n",
        "nontext = pd.read_csv(\"/content/drive/MyDrive/cbb 750 final/nontext/labevents2_processed_matrix.csv\")\n",
        "\n",
        "# read in NOTEEVENTS from mimic--can take up to 2 mins!\n",
        "notes = pd.read_csv('/content/drive/MyDrive/cbb 750 final/mimic/NOTEEVENTS.csv')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZgq7Vo87Sfo"
      },
      "source": [
        "### Extracting the most recent notes for each patient\n",
        "\n",
        "\n",
        "Now, our goal is to find text notes for all patients in ```SubID_ICD_Disease.csv```. Specifically, we want to find the most recent text notes for each patient, which should hopefully be the most salient to determining their disease state. [The assumption is that earlier patient notes may include data that's completely extraneous to our classification task, which in turn will make classification harder.]\n",
        "\n",
        "We realized that the ```CHARTDATE``` column [which represents when the notes were recorded] was the only reliable indicator of time here [others are frequently NA whereas this appears to have a value in all rows], and even then it outputs things in a weird format. Ostensibly it is in \"year-date-month\" but the years are... in the future? \n",
        "\n",
        "Here's an example: \n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "We're unsure as to why this is the case but we sorted based on \"most recent date.\" Here's how: \n",
        "\n",
        "1. Since these \"dates\" are stored as strings, we first strip \"-\" and convert to ints. We store that in a new column called ```DATETOUSE```. \n",
        "2. We get a list of unique ```SUBJECT_ID```s. This is easily done using python's set operations.\n",
        "3. We create a new empty dataframe called ```uniqueNotes``` with the same columns as ```NOTEEVENTS```. It will become a subset of rows in ```NOTEEVENTS```, namely all rows containing the \"most recent\" note for each unique patient.\n",
        "4. We iterate over each unique patient, find the notes associated with them and find the row corresponding to the \"most recent\" one. \n",
        "  * Finding the \"most recent\" date just means finding the max of all ```DATETOUSE``` values associated with this patient. \n",
        "5. We then add that row to ```uniqueNotes``` and export as ```noteevents_most_recent.csv```\n",
        "  * I know exporting is not strictly necessary but we may want to work on the data in a different notebook/script. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "QfcdsReusRNf",
        "outputId": "89e87707-06a9-4e33-9dfa-3bb61fccf75f"
      },
      "source": [
        "# merge icd codes with NOTEEVENTS\n",
        "subjectNotes = pd.merge(data, notes, on=\"SUBJECT_ID\")\n",
        "\n",
        "# create a new column DATETOUSE, which gets rid of the hyphens in CHARTDATE strings and converts to int\n",
        "subjectNotes['DATETOUSE'] = subjectNotes['CHARTDATE'].map(lambda CHARTDATE: int(CHARTDATE.replace('-','')))\n",
        "\n",
        "# see which patients have multiple notes: see https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.duplicated.html\n",
        "duplicates = subjectNotes[subjectNotes.duplicated(subset=[\"SUBJECT_ID\"])]\n",
        "\n",
        "# find the unique subject ids--we have to make it a list else python will throw an error later\n",
        "uniqueIDs = list(set(duplicates['SUBJECT_ID']))\n",
        "\n",
        "# create a new dataframe for the unique notes with the same columns as subjectnotes\n",
        "uniqueNotes = pd.DataFrame(columns=subjectNotes.columns)\n",
        "\n",
        "# go through the unique subject ids and find the most recent notes for each patient \n",
        "for i in range(len(uniqueIDs)):\n",
        "\n",
        "  id = uniqueIDs[i]\n",
        "\n",
        "  # find notes associated with a given subjectid\n",
        "  assocNotes = subjectNotes.loc[subjectNotes['SUBJECT_ID'].isin([id])]\n",
        "\n",
        "  # now we'll get the max value of all DATETOUSE values associated with each patient [idxmax gives you the row index]\n",
        "  # for idxmax info see here: https://www.kite.com/python/answers/how-to-find-the-max-value-of-a-pandas-dataframe-column-in-python\n",
        "  date = assocNotes['DATETOUSE']\n",
        "  chartMaxInd = date.idxmax()\n",
        "\n",
        "  # extract that row--the index we get is from subjectNotes since assocNotes is a subset of subjectNotes, not its own dataframe \n",
        "  chartMax = subjectNotes.iloc[chartMaxInd,:]\n",
        "  \n",
        "  # chartMax is a series, which we need to convert to a dataframe. It is also transposed from the original for some reason so we need to transpose it back\n",
        "  maxRow = chartMax.to_frame().T\n",
        "\n",
        "  # add it on to uniqueNotes\n",
        "  uniqueNotes = pd.concat([uniqueNotes, maxRow])\n",
        "\n",
        "\n",
        "uniqueNotes.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>SUBJECT_ID</th>\n",
              "      <th>ICD9_CODE</th>\n",
              "      <th>SHORT_TITLE</th>\n",
              "      <th>LONG_TITLE</th>\n",
              "      <th>ROW_ID</th>\n",
              "      <th>HADM_ID</th>\n",
              "      <th>CHARTDATE</th>\n",
              "      <th>CHARTTIME</th>\n",
              "      <th>STORETIME</th>\n",
              "      <th>CATEGORY</th>\n",
              "      <th>DESCRIPTION</th>\n",
              "      <th>CGID</th>\n",
              "      <th>ISERROR</th>\n",
              "      <th>TEXT</th>\n",
              "      <th>DATETOUSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>475330</th>\n",
              "      <td>12232</td>\n",
              "      <td>3</td>\n",
              "      <td>4254</td>\n",
              "      <td>Prim cardiomyopathy NEC</td>\n",
              "      <td>Other primary cardiomyopathies</td>\n",
              "      <td>784268</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2102-04-18</td>\n",
              "      <td>2102-04-18 13:22:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Radiology</td>\n",
              "      <td>ART DUP EXT LO UNI;F/U</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[**2102-4-18**] 1:22 PM\\n ART DUP EXT LO UNI;F...</td>\n",
              "      <td>21020418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>427689</th>\n",
              "      <td>10946</td>\n",
              "      <td>32773</td>\n",
              "      <td>41401</td>\n",
              "      <td>Crnry athrscl natve vssl</td>\n",
              "      <td>Coronary atherosclerosis of native coronary ar...</td>\n",
              "      <td>34384</td>\n",
              "      <td>129856</td>\n",
              "      <td>2185-10-05</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Discharge summary</td>\n",
              "      <td>Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Admission Date:  [**2185-9-26**]              ...</td>\n",
              "      <td>21851005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67171</th>\n",
              "      <td>1413</td>\n",
              "      <td>98310</td>\n",
              "      <td>41401</td>\n",
              "      <td>Crnry athrscl natve vssl</td>\n",
              "      <td>Coronary atherosclerosis of native coronary ar...</td>\n",
              "      <td>129334</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2175-05-17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ECG</td>\n",
              "      <td>Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Baseline artifact\\nVentricular paced rhythm\\nI...</td>\n",
              "      <td>21750517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245933</th>\n",
              "      <td>6167</td>\n",
              "      <td>32777</td>\n",
              "      <td>41401</td>\n",
              "      <td>Crnry athrscl natve vssl</td>\n",
              "      <td>Coronary atherosclerosis of native coronary ar...</td>\n",
              "      <td>220354</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2113-11-18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ECG</td>\n",
              "      <td>Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Normal sinus rhythm with marked A-V conduction...</td>\n",
              "      <td>21131118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>905</th>\n",
              "      <td>25</td>\n",
              "      <td>32779</td>\n",
              "      <td>41401</td>\n",
              "      <td>Crnry athrscl natve vssl</td>\n",
              "      <td>Coronary atherosclerosis of native coronary ar...</td>\n",
              "      <td>37</td>\n",
              "      <td>133757</td>\n",
              "      <td>2167-10-27</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Discharge summary</td>\n",
              "      <td>Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Admission Date:  [**2167-10-20**]             ...</td>\n",
              "      <td>21671027</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  ... DATETOUSE\n",
              "475330      12232  ...  21020418\n",
              "427689      10946  ...  21851005\n",
              "67171        1413  ...  21750517\n",
              "245933       6167  ...  21131118\n",
              "905            25  ...  21671027\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fL5Gv-B90fI"
      },
      "source": [
        "##### Type of notes used for text-based classification\n",
        "\n",
        "The ```NOTEEVENTS``` table places each note into a specific category under the column ```CATEGORY```. Let's take a look at the distribution of notes in our text data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "AX9rRbt09dO7",
        "outputId": "ec9ac9c2-7053-4792-e46b-c3e99d3845e7"
      },
      "source": [
        "# make a histogram of the CATEGORY column of the uniqueNotes\n",
        "p = plt.hist(uniqueNotes['CATEGORY'])\n",
        "\n",
        "# rotate x-axis names so they fit nicely on the page\n",
        "plt.xticks(rotation='vertical') \n",
        "\n",
        "plt.show()\n",
        "plt.xlabel()\n",
        "plt.savefig('hist_noteCategory')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZhjFo2gGsOx"
      },
      "source": [
        "## Now we can conduct NLP on the text data matrix.\n",
        "\n",
        "Now that we have our data matrix set up, we'll normalize the text, remove stop words, and vectorize the data using doc2vec. We do this to get into the same form as the LABEVENTS matrix and to use it for classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF5gRoNyf94Q",
        "outputId": "b2fd4e8e-c895-4b7d-d0ae-ef7080cf467f"
      },
      "source": [
        "# extract the column: 'TEXT' - save as variable: 'textData'\n",
        "textData = uniqueNotes['TEXT']\n",
        "\n",
        "# check my work - print the checks\n",
        "print(len(textData)) #each row = 1 document, length of vector = number documents\n",
        "textData[0:4] #scope the scene - view the first five documents"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11572\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "475330    [**2102-4-18**] 1:22 PM\\n ART DUP EXT LO UNI;F...\n",
              "427689    Admission Date:  [**2185-9-26**]              ...\n",
              "67171     Baseline artifact\\nVentricular paced rhythm\\nI...\n",
              "245933    Normal sinus rhythm with marked A-V conduction...\n",
              "Name: TEXT, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpdJ5mKAVyLs"
      },
      "source": [
        "### Text Processing\n",
        "\n",
        "Explain what is being done here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0zuZBn0Xh6S",
        "outputId": "8b8355a6-f84e-4d39-84ca-baf80d410467"
      },
      "source": [
        "#clean the data\n",
        "def cleanText(text):\n",
        "    text = text.lower() #normalize\n",
        "    ## can add other text processing commands here \n",
        "    return text\n",
        "\n",
        "#apply the cleanText function to the text data\n",
        "cleanTextData = textData.apply(cleanText)\n",
        "\n",
        "# tokenize the data\n",
        "tokenTextData = [nltk.word_tokenize(row) for row in cleanTextData] \n",
        "\n",
        "# check that it worked\n",
        "print('original:', textData[0])\n",
        "print('cleaned:', cleanTextData[0])\n",
        "print('tokenized:', tokenTextData[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original: Admission Date:  [**2151-7-16**]       Discharge Date:  [**2151-8-4**]\n",
            "\n",
            "\n",
            "Service:\n",
            "ADDENDUM:\n",
            "\n",
            "RADIOLOGIC STUDIES:  Radiologic studies also included a chest\n",
            "CT, which confirmed cavitary lesions in the left lung apex\n",
            "consistent with infectious process/tuberculosis.  This also\n",
            "moderate-sized left pleural effusion.\n",
            "\n",
            "HEAD CT:  Head CT showed no intracranial hemorrhage or mass\n",
            "effect, but old infarction consistent with past medical\n",
            "history.\n",
            "\n",
            "ABDOMINAL CT:  Abdominal CT showed lesions of\n",
            "T10 and sacrum most likely secondary to osteoporosis. These can\n",
            "be followed by repeat imaging as an outpatient.\n",
            "\n",
            "\n",
            "\n",
            "                            [**First Name8 (NamePattern2) **] [**First Name4 (NamePattern1) 1775**] [**Last Name (NamePattern1) **], M.D.  [**MD Number(1) 1776**]\n",
            "\n",
            "Dictated By:[**Hospital 1807**]\n",
            "MEDQUIST36\n",
            "\n",
            "D:  [**2151-8-5**]  12:11\n",
            "T:  [**2151-8-5**]  12:21\n",
            "JOB#:  [**Job Number 1808**]\n",
            "\n",
            "cleaned: admission date:  [**2151-7-16**]       discharge date:  [**2151-8-4**]\n",
            "\n",
            "\n",
            "service:\n",
            "addendum:\n",
            "\n",
            "radiologic studies:  radiologic studies also included a chest\n",
            "ct, which confirmed cavitary lesions in the left lung apex\n",
            "consistent with infectious process/tuberculosis.  this also\n",
            "moderate-sized left pleural effusion.\n",
            "\n",
            "head ct:  head ct showed no intracranial hemorrhage or mass\n",
            "effect, but old infarction consistent with past medical\n",
            "history.\n",
            "\n",
            "abdominal ct:  abdominal ct showed lesions of\n",
            "t10 and sacrum most likely secondary to osteoporosis. these can\n",
            "be followed by repeat imaging as an outpatient.\n",
            "\n",
            "\n",
            "\n",
            "                            [**first name8 (namepattern2) **] [**first name4 (namepattern1) 1775**] [**last name (namepattern1) **], m.d.  [**md number(1) 1776**]\n",
            "\n",
            "dictated by:[**hospital 1807**]\n",
            "medquist36\n",
            "\n",
            "d:  [**2151-8-5**]  12:11\n",
            "t:  [**2151-8-5**]  12:21\n",
            "job#:  [**job number 1808**]\n",
            "\n",
            "tokenized: ['[', '**2102-4-18**', ']', '1:22', 'pm', 'art', 'dup', 'ext', 'lo', 'uni', ';', 'f/u', 'clip', '#', '[', '**clip', 'number', '(', 'radiology', ')', '69444**', ']', 'reason', ':', 'arterial', 'left', 'leg', ',', 'graft', 'surveillance', '______________________________________________________________________________', '[', '**hospital', '2**', ']', 'medical', 'condition', ':', '76', 'year', 'old', 'man', 'with', 'reason', 'for', 'this', 'examination', ':', 'graft', 'survelliance', '______________________________________________________________________________', 'final', 'report', '[', '**2102-4-18**', ']', ',', 'duplex', 'lower', 'extremity', 'reason', ':', 'the', 'patient', 'is', 'status', 'post', 'left', 'lower', 'extremity', 'bypass', 'graft', ',', 'followup', 'for', 'surveillance', '.', 'new', 'heel', 'ulcer', '.', 'findings', ':', 'duplex', 'evaluation', 'was', 'performed', 'of', 'the', 'left', 'lower', 'extremity', 'femoral', 'to', 'anterior', 'tibial', 'bypass', 'graft', '.', 'peak', 'systolic', 'velocities', 'in', 'cm', 'per', 'second', 'are', 'as', 'follows', ':', '48', ',', '98', ',', '86', ',', '86', 'in', 'the', 'proximal', 'vessel', ',', 'proximal', 'anastomosis', ',', 'distal', 'anastomosis', 'and', 'native', 'distal', 'vessel', ',', 'respectively', '.', 'throughout', 'the', 'body', 'of', 'the', 'graft', ',', 'velocities', 'range', 'from', '34', 'through', '80.', 'there', 'are', 'no', 'peak', 'velocity', 'ratios', 'greater', 'than', 'equal', 'to', '2.', 'impression', ':', 'widely', 'patent', 'left', 'femoral', 'to', 'anterior', 'tibial', 'artery', 'bypass', 'graft', 'without', 'any', 'evidence', 'of', 'stenosis', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrYpQnUs4o34"
      },
      "source": [
        "### Tag the Processed Text\n",
        "\n",
        "Now we need to tag the documents because the vectorizor likes to ingest data this way. \n",
        "\n",
        "There are many ways to experiment here: \n",
        "\n",
        "*   We can tag the documents with the labels (as performed below)\n",
        "*   We can tag the documents with unique identifiers, to train our vectorizer to know that each document is unique\n",
        "*   We can tag the documents with multiple labels, a combination of the two examples above or use other factors from the dataframe. In adding more data to the tags, we may increase predictability of our resulting vectors.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3xv1mr535ew"
      },
      "source": [
        "#### Make labels for tagging\n",
        "\n",
        "Unfortunately this block of code is used multiple times throughout the notebook. For now we recognize the redundancy. It gets the job done and will have to do.  \n",
        "\n",
        "Here's how we generate labels: \n",
        "\n",
        "* We find each patient's ICD9 code [under column ```ICD9_CODE``` in uniqueNotes]\n",
        "* Label cardiomyopathy ICD codes as 0 and CAD as 1\n",
        "  *   Cardiomyopathy codes are  [425.11](http://www.icd9data.com/2014/Volume1/390-459/420-429/425/425.11.htm), [425.18](http://www.icd9data.com/2014/Volume1/390-459/420-429/425/425.18.htm) and [425.4](http://www.icd9data.com/2014/Volume1/390-459/420-429/425/425.4.htm) \n",
        "  * CAD codes are [440.29](http://www.icd9data.com/2014/Volume1/390-459/440-449/440/440.29.htm), [440.9](http://www.icd9data.com/2014/Volume1/390-459/440-449/440/440.9.htm), [414.01](http://www.icd9data.com/2014/Volume1/390-459/410-414/414/414.01.htm) and [414.3](http://www.icd9data.com/2014/Volume1/390-459/410-414/414/414.3.htm) \n",
        "\n",
        "* Add all labels to the array ```tagging_labels```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ytWuguF3o8n",
        "outputId": "1c91d20a-e419-40a3-f911-d7df73262b71"
      },
      "source": [
        "# let's make the labels--basically we want to separate out by icd code\n",
        "# we'll make 0=cardiomyopathy, 1=CAD\n",
        "cm = [42511, 42518, 4254]\n",
        "cad = [44029, 4409, 41401, 4143]\n",
        "\n",
        "# this array contains all the ICD codes in order\n",
        "codes = uniqueNotes['ICD9_CODE'].tolist()\n",
        "\n",
        "# this array will contain all the data labels in order\n",
        "tagging_labels = []\n",
        "\n",
        "# iterate through the rows of textVectorMat and create labels \n",
        "for i in range(len(codes)):\n",
        "\n",
        "  # grab the icd code from row i\n",
        "  icd = codes[i]\n",
        "\n",
        "  # if the icd code is a CM one, append 0 to labels, else if it's CAD append 1\n",
        "  if icd in cm: \n",
        "    tagging_labels.append(0)\n",
        "  else: \n",
        "    tagging_labels.append(1)\n",
        "\n",
        "# ensure that the length of the list of labels is the same as the length of codes\n",
        "print(\"labels:\", len(tagging_labels))\n",
        "print(\"codes:\", len(codes))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labels: 11572\n",
            "codes: 11572\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTgaxIaz38ck"
      },
      "source": [
        "#### Perform the tagging\n",
        "\n",
        "Explain what this entails"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "5vd0LeaTcE85",
        "outputId": "3731fb0d-eb1b-4f84-8d09-f56ae421ab49"
      },
      "source": [
        "# initialize the array \n",
        "documents = []\n",
        "\n",
        "# tag each document with the associated label\n",
        "for i in range(len(tokenTextData)):\n",
        "  taggedDoc = TaggedDocument(words=tokenTextData[i], tags=[tagging_labels[i]])\n",
        "  documents.append(taggedDoc)\n",
        "\n",
        "# check that it worked\n",
        "print('tagged:', documents[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c76bec74d0a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# tag each document with the associated label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenTextData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mtaggedDoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTaggedDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenTextData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtagging_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mdocuments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaggedDoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenTextData' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaEg3lkBb3fx"
      },
      "source": [
        "### Vectorizing with Doc2Vec\n",
        "\n",
        "Now we will build a vectorizer using the Doc2Vec model.\n",
        "\n",
        "We will split the tagged data into train and test with a 70-30 train-test split. Train data will be used to train the vectorizer and we'll be using that same 70-30 train-test split when running our models, just to keep things consistent. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm5ocbGrqjgF",
        "outputId": "2ca110e1-3cb8-44cb-bfca-64a9f33fd8a4"
      },
      "source": [
        "# split into train and test\n",
        "trainDocuments, testDocuments = train_test_split(documents, test_size=0.3, random_state=42)\n",
        "\n",
        "# check our work:\n",
        "print(len(documents))\n",
        "print(len(trainDocuments))\n",
        "print(len(testDocuments))\n",
        "print(trainDocuments[10]) # printing a random trainDocument to check formatting"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11572\n",
            "8100\n",
            "3472\n",
            "TaggedDocument(['[', '**2136-3-6**', ']', '8:30', 'am', 'ct', 'chest', 'w/o', 'contrast', 'clip', '#', '[', '**clip', 'number', '(', 'radiology', ')', '77439**', ']', 'reason', ':', 'f/u', 'left', 'upper', '[', '**clip', 'number', '(', 'radiology', ')', '**', ']', ';', 'lung', 'ca', '______________________________________________________________________________', '[', '**hospital', '2**', ']', 'medical', 'condition', ':', '83', 'year', 'old', 'man', 'with', 'left', 'upper', '[', '**hospital', '1618**', ']', 'nodule', 'reason', 'for', 'this', 'examination', ':', 'followup', 'left', 'upper', '[', '**hospital', '1618**', ']', 'nodule', ',', 'please', 'compare', 'to', 'prior', 'studies', 'no', 'contraindications', 'for', 'iv', 'contrast', '______________________________________________________________________________', 'final', 'report', 'ct', 'chest', 'without', 'contrast', 'dated', '[', '**2136-3-6**', ']', 'comparison', ':', '[', '**2135-8-29**', ']', 'chest', 'cta', '.', 'indication', ':', 'lung', 'nodule', '.', 'multidetector', 'ct', 'of', 'the', 'chest', 'was', 'performed', 'without', 'intravenous', 'or', 'oral', 'contrast', 'administration', '.', 'images', 'are', 'presented', 'for', 'display', 'in', 'the', 'axial', 'plane', 'at', '5', 'mm', 'and', '1.25', 'mm', 'collimation', '.', 'a', 'series', 'of', 'coronal', 'reformation', 'images', 'were', 'also', 'presented', 'for', 'review', '.', 'findings', ':', 'a', 'spiculated', 'nodular', 'opacity', 'in', 'the', 'right', 'upper', '[', '**year', '(', '4', 'digits', ')', '1618**', ']', 'directly', 'abutting', 'the', 'minor', 'fissure', 'is', 'without', 'change', 'from', 'the', 'prior', 'ct.', 'this', 'measures', 'about', '8', 'mm', 'in', 'greatest', 'dimension', 'and', 'is', 'contiguous', 'with', 'an', 'area', 'of', 'longer', 'linear', 'opacification', ',', 'which', 'may', 'be', 'due', 'to', 'an', 'area', 'of', 'adjacent', 'scarring', '.', 'more', 'superiorly', 'at', 'both', 'lung', 'apices', ',', 'nodular', 'opacities', 'are', 'identified', 'and', 'contiguous', 'with', 'areas', 'of', 'linear', 'scarring', 'and', 'probably', 'reflect', 'nodular', 'areas', 'of', 'scar', '.', 'these', 'border', 'emphysematous', 'spaces', ',', 'and', 'the', 'right', 'apical', 'lesion', 'is', 'associated', 'with', 'eccentric', 'calcification', '.', 'tiny', 'calcified', 'granuloma', 'is', 'present', 'in', 'the', 'left', 'apex', 'posteriorly', '.', 'extensive', 'emphysema', 'is', 'present', 'with', 'both', 'paraseptal', 'and', 'centrilobular', 'components', '.', 'within', 'the', 'right', 'middle', '[', '**last', 'name', '(', 'lf', ')', '1618**', ']', ',', '[', '**first', 'name3', '(', 'lf', ')', '**', ']', 'additional', 'noncalcified', 'nodule', 'is', 'present', 'measuring', '5', 'mm', 'with', 'slightly', 'lobulated', 'borders', ',', 'also', 'unchanged', '(', 'image', '163', ',', 'series', '4', ')', '.', 'an', 'additional', 'small', 'granuloma', 'is', 'present', 'in', 'the', 'left', 'lower', '[', '**first', 'name3', '(', 'lf', ')', '1618**', ']', '.', 'at', 'the', 'extreme', 'left', 'lung', 'base', 'laterally', ',', 'a', 'cluster', 'of', 'nodules', 'has', 'developed', '(', 'image', '55', ',', 'series', '3', ')', 'adjacent', 'to', 'an', 'area', 'of', 'preexisting', 'linear', 'scar', 'or', 'atelectasis', '.', 'one', 'previously', 'reported', 'right', 'lower', '[', '**first', 'name3', '(', 'lf', ')', '1618**', ']', 'nodule', 'is', 'no', 'longer', 'visualized', '.', 'central', 'airways', 'are', 'patent', 'with', 'no', 'suspicious', 'endobronchial', 'lesions', '.', 'asymmetric', 'enlargement', 'of', 'the', 'right', '[', '**first', 'name3', '(', 'lf', ')', '1618**', ']', 'of', 'the', 'thyroid', 'gland', 'is', 'again', 'demonstrated', 'as', 'well', 'as', 'heterogeneous', 'appearance', 'of', 'both', 'lobes', 'with', 'areas', 'of', 'low', 'attenuation', 'and', 'foci', 'of', 'calcification', ',', 'unchanged', '.', 'several', 'small', ',', 'subcentimeter', 'mediastinal', 'lymph', 'nodes', 'are', 'without', 'change', ',', 'but', 'a', 'precarinal', 'node', 'has', 'grown', 'from', '10', 'mm', 'to', '14', 'mm', 'short', 'axis', 'dimension', '.', 'no', 'definite', 'hilar', 'lymphadenopathy', 'is', 'evident', 'on', 'this', 'unenhanced', 'ct.', 'central', 'arteries', 'appear', 'enlarged', 'suggesting', 'pulmonary', 'arterial', 'hypertension', '.', 'heart', 'size', 'is', 'normal', '.', 'diffuse', 'coronary', 'artery', 'calcifications', 'are', 'present', '.', 'aorta', 'is', 'atherosclerotic', 'and', 'diffusely', 'ectatic', '.', 'in', 'the', 'imaged', 'portion', 'of', 'the', 'upper', 'abdomen', ',', 'adrenal', 'glands', 'are', 'normal', '.', '(', 'over', ')', '[', '**2136-3-6**', ']', '8:30', 'am', 'ct', 'chest', 'w/o', 'contrast', 'clip', '#', '[', '**clip', 'number', '(', 'radiology', ')', '77439**', ']', 'reason', ':', 'f/u', 'left', 'upper', '[', '**clip', 'number', '(', 'radiology', ')', '**', ']', ';', 'lung', 'ca', '______________________________________________________________________________', 'final', 'report', '(', 'cont', ')', 'several', 'low-attenuation', 'lesions', 'are', 'present', 'in', 'the', 'imaged', 'portions', 'of', 'both', 'kidneys', ',', 'incompletely', 'assessed', '.', 'vascular', 'calcifications', 'are', 'present', 'in', 'the', 'abdominal', 'aorta', 'extending', 'into', 'the', 'renal', 'arteries', '.', 'the', 'remaining', 'imaged', 'portion', 'of', 'the', 'upper', 'abdomen', 'is', 'unremarkable', 'on', 'this', 'unenhanced', 'ct', ',', 'which', 'was', 'not', 'specifically', 'tailored', 'to', 'evaluate', 'the', 'abdominal', 'organs', '.', 'skeletal', 'structures', 'demonstrate', 'no', 'suspicious', 'lytic', 'or', 'blastic', 'lesions', '.', 'additional', 'prior', 'ct', 'from', '[', '**2135-3-5**', ']', 'is', 'available', 'for', 'comparison', '.', 'as', 'compared', 'to', 'that', 'exam', ',', 'there', 'has', 'not', 'been', 'a', 'substantial', 'change', 'in', 'the', 'perifissural', 'nodule', ',', 'right', 'middle', '[', '**year', '(', '4', 'digits', ')', '1618**', ']', 'nodule', ',', 'or', 'in', 'the', 'areas', 'of', 'apparent', 'nodular', 'scarring', 'at', 'the', 'lung', 'apices', '.', 'impression', ':', '1.', 'spiculated', '8', 'mm', 'right', 'upper', '[', '**year', '(', '4', 'digits', ')', '1618**', ']', 'perifissural', 'lung', 'nodule', 'without', 'change', 'since', '[', '**2135-3-5**', ']', '.', 'although', 'possibly', 'due', 'to', 'nodular', 'scar', ',', 'its', 'morphology', 'remains', 'suspicious', 'for', 'lung', 'neoplasm', '.', 'considering', 'an', 'enlarging', 'precarinal', 'lymph', 'node', ',', 'pet-ct', 'may', 'be', 'helpful', 'for', 'further', 'assessment', 'of', 'the', 'lung', 'nodule', 'and', 'lymph', 'nodes', '.', 'if', 'pet', 'is', 'negative', ',', 'then', 'a', 'final', 'followup', 'ct', 'in', '[', '**2137-3-5**', ']', 'could', 'be', 'performed', 'to', 'confirm', 'two-year', 'stability', '.', '2.', 'no', 'change', 'in', 'smaller', 'right', 'middle', '[', '**year', '(', '4', 'digits', ')', '1618**', ']', 'nodule', 'and', 'biapical', 'nodular', 'scarring', '.', 'these', 'areas', 'can', 'also', 'be', 'reassessed', 'at', 'the', 'one-year', 'followup', 'ct', 'and', ',', 'if', 'performed', ',', 'at', 'pet', '.', '3.', 'new', 'peripheral', 'left', 'basilar', 'opacities', 'likely', 'due', 'to', 'atelectasis', 'or', 'infectious/inflammatory', 'process', '.', '4.', 'mildly', 'dilated', 'descending', 'thoracic', 'aorta', 'without', 'change', '.', '5.', 'diffuse', 'coronary', 'artery', 'calcifications', '.', '6.', 'probable', 'multinodular', 'goiter', '.'], [0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jEHOcoQ4-LW"
      },
      "source": [
        "After splitting the tagged data, we'll do the following: \n",
        "  \n",
        "  * Build the model and input model parameters\n",
        "  * Build the vocabulary that will be used in the model\n",
        "    * The vocabulary is based on every token in the entire corpus of train documents.\n",
        "\n",
        "Importantly, we make the document vector size **438**, which is the same number of features as the nontext matrix [minus the subject_id column]. This helps facilitate comparison between the two models. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktXQfChzlLX8",
        "outputId": "d0902f78-32da-46c0-91ca-27a1a5e73771"
      },
      "source": [
        "# To run a parallelized approach, we count our processing cores\n",
        "# This significantly expedites runtime\n",
        "cores = multiprocessing.cpu_count()\n",
        "\n",
        "# initialize the model\n",
        "doc2VecModel = Doc2Vec(dm=1, # using the Paragraph Vector-Distributed Memory (PV-DM) model, similar to CBOW in word2vec\n",
        "                vector_size=438, # size of each vector, 1 vector per document\n",
        "                window=10, # number of surrounding tokens impacting each token's weight\n",
        "                negative=5, hs=0, min_count=1, # minimum acceptances\n",
        "                workers=cores, # off for now, using the cores found for parallelized approach described above.\n",
        "                alpha=0.025, min_alpha=0.001) # learning rates\n",
        "\n",
        "# build vocab\n",
        "doc2VecModel.build_vocab([x for x in tqdm(trainDocuments)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 8100/8100 [00:00<00:00, 1201721.28it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9N-c1fqq2qBo"
      },
      "source": [
        "Lets train the model:\n",
        "\n",
        "We'll record the time just so we know about how long everything takes. We run for 10 epochs, which is a [standard](https://radimrehurek.com/gensim/models/doc2vec.html) value. This will take a while--roughly ~32-34 minutes when we've run it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82UmOpf53hlf",
        "outputId": "dd4b6f9d-9735-4c2c-95b3-3277016f1339"
      },
      "source": [
        "# record the time -> usually takes about 30 minutes\n",
        "%%time\n",
        "\n",
        "# run the model with 10 epochs\n",
        "for epoch in range(10):\n",
        "    print('iteration {0}'.format(epoch))\n",
        "    doc2VecModel.train(utils.shuffle([x for x in tqdm(trainDocuments)]), total_examples=len(trainDocuments), epochs=doc2VecModel.iter)\n",
        "    #doc2VecModel.alpha -= 0.002\n",
        "    #doc2VecModel.min_alpha = doc2VecModel.alpha\n",
        "\n",
        "\n",
        "# save the model to use at a later date:\n",
        "#doc2VecModel.save(\"d2v.model\")\n",
        "#print(\"Model Saved\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 8100/8100 [00:00<00:00, 736512.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iteration 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
            "  \"\"\"\n",
            "100%|| 8100/8100 [00:00<00:00, 1010044.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iteration 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|| 8100/8100 [00:00<00:00, 733792.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iteration 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|| 8100/8100 [00:00<00:00, 1098659.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iteration 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|| 8100/8100 [00:00<00:00, 1957809.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iteration 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|| 8100/8100 [00:00<00:00, 1945254.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iteration 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|| 8100/8100 [00:00<00:00, 1155770.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iteration 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|| 8100/8100 [00:00<00:00, 1096390.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iteration 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|| 8100/8100 [00:00<00:00, 1646818.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iteration 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|| 8100/8100 [00:00<00:00, 1164724.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "iteration 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1h 1min 34s, sys: 13.2 s, total: 1h 1min 47s\n",
            "Wall time: 32min 9s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtKGUQNQk-Gn"
      },
      "source": [
        "We'll use the trained model to create vectors for the corpus. \n",
        "\n",
        "We'll store the vectors in a list of vectors, which we may then add to our dataframe as a new column of data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMmLQNb2kdaE",
        "outputId": "9df9865b-c8f7-41ad-e400-04fe4e5da004"
      },
      "source": [
        "# initialize an empty vector\n",
        "docVectors = []\n",
        "\n",
        "# for each tokenized document, use the model to infer a vector, store the vector in 'docVectors'\n",
        "for i in range(len(tokenTextData)):\n",
        "  vec = doc2VecModel.infer_vector(tokenTextData[i])\n",
        "  docVectors.append(vec)\n",
        "\n",
        "\n",
        "#   sanity check\n",
        "print(len(docVectors)) # should be same length as number of unique patients/length of corpus\n",
        "print(len(docVectors[0])) # should be same length as the vector_size input into the doc2vec model\n",
        "print(docVectors[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11572\n",
            "438\n",
            "[ 0.08961867  0.05225237 -0.02182593 -0.1325062  -0.04235648  0.02031939\n",
            " -0.08463685  0.04356737  0.08568966  0.10413086 -0.21926095 -0.00684133\n",
            " -0.01473457 -0.13951817 -0.12634423 -0.03330374 -0.1431566   0.06908908\n",
            "  0.0303576  -0.04515759 -0.01950812  0.10817665 -0.03878772  0.03911992\n",
            " -0.09959868  0.0362013   0.06340539  0.127625   -0.11943384  0.06101257\n",
            "  0.06145218  0.04829501 -0.01267216  0.10782479  0.02743006 -0.06273396\n",
            " -0.11657942 -0.23513135  0.18746036  0.01065594 -0.26709786  0.04581324\n",
            "  0.0941978   0.3220771  -0.00433553 -0.17525579  0.03197254 -0.18911512\n",
            "  0.02110042 -0.23297629  0.2148378   0.20676813  0.14064737 -0.09921738\n",
            " -0.03083138 -0.02958974  0.21416457  0.23716375  0.02600233 -0.16001174\n",
            " -0.20877701  0.0783632   0.21053301 -0.05782223 -0.24427009 -0.12009718\n",
            "  0.0107403  -0.11264966 -0.03861984 -0.09781489 -0.00978167  0.10278507\n",
            " -0.13497302  0.09719813 -0.06187553 -0.09187638 -0.06818846 -0.08530002\n",
            "  0.05947986 -0.00988815  0.08655977 -0.15744297  0.16750114 -0.0577914\n",
            " -0.01054781  0.02640717 -0.04676557  0.14195149 -0.08474749  0.23248552\n",
            " -0.24864763 -0.24968977  0.16226782  0.08936989  0.10532796  0.05767107\n",
            "  0.11182954  0.05724065  0.01755268  0.08955921  0.13550511 -0.16919366\n",
            "  0.27539533 -0.03585109 -0.1818621   0.10151511 -0.08959356  0.10840933\n",
            " -0.00388503 -0.0972654  -0.27579066  0.19052364 -0.20834552 -0.02611735\n",
            "  0.15271382 -0.11451467 -0.13260204  0.10344773 -0.13072507  0.11644011\n",
            " -0.230649   -0.00947537 -0.03088283 -0.2864261  -0.03134954 -0.00781252\n",
            " -0.07251817 -0.1119656  -0.10888456  0.01533228  0.0115016  -0.04881382\n",
            "  0.11302007  0.00210381 -0.07039084 -0.02694093 -0.10961331 -0.13792437\n",
            " -0.15115207  0.06110924 -0.08900317 -0.18410417 -0.12335454  0.13477041\n",
            " -0.03836388 -0.22312634 -0.00859229 -0.0550656  -0.09780447 -0.20465784\n",
            " -0.28998786  0.11192021  0.02310114  0.08105829  0.23193955 -0.17795613\n",
            " -0.03655326 -0.2977125  -0.07411332 -0.20840898 -0.14996964 -0.05738916\n",
            " -0.1633061  -0.07305516  0.09861068 -0.00536515 -0.25022635  0.1429435\n",
            " -0.13627099  0.09693448  0.00406044 -0.27903733  0.0607837  -0.01754207\n",
            " -0.12416279  0.03757113  0.3004434   0.07635796 -0.06197833  0.18305606\n",
            "  0.03834979 -0.11127421  0.17967208  0.18292867  0.00550684 -0.00110707\n",
            " -0.05985809 -0.04737998  0.2963891   0.13500017  0.05612987 -0.0661101\n",
            "  0.10514576  0.20261183  0.09315394 -0.1367      0.15199433  0.03357917\n",
            " -0.12298122 -0.10316359  0.11252709 -0.05353208  0.06305987  0.17937392\n",
            "  0.12902594 -0.10308055  0.09153927  0.0511573   0.04961599 -0.10941812\n",
            " -0.04372091  0.24578612  0.04566896  0.03601994 -0.06074023  0.19802888\n",
            "  0.09326818 -0.02816044 -0.22531392 -0.0063968   0.38964224 -0.01080604\n",
            "  0.0581206   0.08692487  0.02037274  0.17534901  0.10283413 -0.11249264\n",
            " -0.03532213 -0.25889263 -0.23109184  0.10971674 -0.11437337  0.0111973\n",
            " -0.12998503  0.09057149 -0.11092891 -0.07432532  0.07224647 -0.14043184\n",
            " -0.18897198  0.04426597  0.5297656  -0.05660856 -0.04035958 -0.38511178\n",
            "  0.04210966  0.03954312 -0.02560484  0.0582815   0.07585103 -0.2689654\n",
            " -0.0952373  -0.4008827   0.15161058 -0.19820423 -0.14719744  0.07302053\n",
            "  0.03581501 -0.00920453  0.28524622  0.1302734  -0.1949924  -0.18881492\n",
            "  0.0588476   0.01398777 -0.3243703   0.08197551  0.09731132 -0.01553551\n",
            "  0.3508482   0.18741736  0.28280926  0.2501262   0.03309017  0.1636857\n",
            "  0.00760783 -0.10393655 -0.14195217 -0.35368416 -0.16430458  0.0992386\n",
            "  0.03861924 -0.04513012  0.09362862 -0.04828623 -0.15186903  0.07155585\n",
            "  0.197222   -0.00435003 -0.16519032 -0.0014422   0.06651279  0.04840231\n",
            " -0.06073564  0.24838883  0.15041244 -0.27326244  0.1568804   0.04762768\n",
            " -0.09328152  0.12087324 -0.16298743 -0.1455484   0.2416798   0.20936795\n",
            " -0.02295525 -0.30979022 -0.00782047 -0.07797041 -0.07721961 -0.30507106\n",
            "  0.2234859  -0.2884997   0.20892869  0.12851655 -0.03362731 -0.03388709\n",
            " -0.30484718  0.13156562  0.05582858 -0.06327863  0.03609436  0.09457456\n",
            " -0.17533149 -0.07306478  0.35118115 -0.04297834  0.04330418 -0.21069677\n",
            "  0.0983291  -0.18382716 -0.08892655  0.03825657  0.02349344 -0.19484581\n",
            "  0.2332969   0.06851408 -0.13837458 -0.21481921  0.2068975  -0.09399612\n",
            "  0.07218442 -0.15047717 -0.00122487  0.00918281  0.00940498 -0.30564746\n",
            "  0.07206708  0.17907847  0.20669745  0.19442569 -0.05243837  0.13323955\n",
            "  0.08648845 -0.14360596 -0.11105551  0.08711319 -0.12211576  0.01611543\n",
            "  0.00849085 -0.00682554  0.13561256  0.3523133  -0.04633227 -0.17091927\n",
            " -0.08017014 -0.05340557 -0.10639886 -0.2707865   0.06100615  0.10228048\n",
            "  0.24559684  0.31898627 -0.16386512  0.06417837 -0.17786142 -0.06367078\n",
            "  0.21799223  0.37154073 -0.07793237 -0.2950179   0.04222553 -0.09260712\n",
            " -0.24478777 -0.13725835 -0.11549711  0.20760244  0.2353183   0.06424659\n",
            " -0.05859648  0.02638388  0.09031475  0.02679541 -0.3620225  -0.10085998\n",
            " -0.13817012 -0.05293055 -0.11299871 -0.02346992 -0.05141185 -0.03511541\n",
            " -0.1816735  -0.3345764   0.05416825  0.27760306  0.04413396  0.0676764\n",
            "  0.01257025 -0.02154538 -0.09422734  0.18762714 -0.1088706   0.39253366\n",
            "  0.18275073 -0.01571128  0.02822197  0.09422883 -0.07904644 -0.04704449\n",
            " -0.0476431  -0.03638447 -0.07666113 -0.19059284 -0.2586446  -0.16175397\n",
            " -0.10188648  0.2476187   0.14851809 -0.27215663  0.37785122  0.04435937\n",
            " -0.02858903 -0.04437929 -0.25139412 -0.05824789  0.02603637  0.06635423]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pX6Iy_-aCngV"
      },
      "source": [
        "Let's save these document vectors as a new column in the dataframe uniqueNotes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "mLObb7lUnurz",
        "outputId": "1d41fa45-5b27-4188-f82e-74c4ce9362f4"
      },
      "source": [
        "#add vectors to uniqueNotes\n",
        "uniqueNotes[\"DOC_VECTORS\"] = docVectors\n",
        "\n",
        "# check our work\n",
        "uniqueNotes.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>SUBJECT_ID</th>\n",
              "      <th>ICD9_CODE</th>\n",
              "      <th>SHORT_TITLE</th>\n",
              "      <th>LONG_TITLE</th>\n",
              "      <th>ROW_ID</th>\n",
              "      <th>HADM_ID</th>\n",
              "      <th>CHARTDATE</th>\n",
              "      <th>CHARTTIME</th>\n",
              "      <th>STORETIME</th>\n",
              "      <th>CATEGORY</th>\n",
              "      <th>DESCRIPTION</th>\n",
              "      <th>CGID</th>\n",
              "      <th>ISERROR</th>\n",
              "      <th>TEXT</th>\n",
              "      <th>DATETOUSE</th>\n",
              "      <th>LABELS</th>\n",
              "      <th>DOC_VECTORS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>475330</td>\n",
              "      <td>12232</td>\n",
              "      <td>3</td>\n",
              "      <td>4254</td>\n",
              "      <td>Prim cardiomyopathy NEC</td>\n",
              "      <td>Other primary cardiomyopathies</td>\n",
              "      <td>784268</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2102-04-18</td>\n",
              "      <td>2102-04-18 13:22:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Radiology</td>\n",
              "      <td>ART DUP EXT LO UNI;F/U</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[**2102-4-18**] 1:22 PM\\n ART DUP EXT LO UNI;F...</td>\n",
              "      <td>21020418</td>\n",
              "      <td>0</td>\n",
              "      <td>[0.08961867, 0.052252375, -0.021825928, -0.132...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>427689</td>\n",
              "      <td>10946</td>\n",
              "      <td>32773</td>\n",
              "      <td>41401</td>\n",
              "      <td>Crnry athrscl natve vssl</td>\n",
              "      <td>Coronary atherosclerosis of native coronary ar...</td>\n",
              "      <td>34384</td>\n",
              "      <td>129856.0</td>\n",
              "      <td>2185-10-05</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Discharge summary</td>\n",
              "      <td>Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Admission Date:  [**2185-9-26**]              ...</td>\n",
              "      <td>21851005</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.037899565, 1.2805989, -1.1988019, 0.2361796...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>67171</td>\n",
              "      <td>1413</td>\n",
              "      <td>98310</td>\n",
              "      <td>41401</td>\n",
              "      <td>Crnry athrscl natve vssl</td>\n",
              "      <td>Coronary atherosclerosis of native coronary ar...</td>\n",
              "      <td>129334</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2175-05-17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ECG</td>\n",
              "      <td>Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Baseline artifact\\nVentricular paced rhythm\\nI...</td>\n",
              "      <td>21750517</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.024404855, 0.060916033, -0.026240427, 0.021...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>245933</td>\n",
              "      <td>6167</td>\n",
              "      <td>32777</td>\n",
              "      <td>41401</td>\n",
              "      <td>Crnry athrscl natve vssl</td>\n",
              "      <td>Coronary atherosclerosis of native coronary ar...</td>\n",
              "      <td>220354</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2113-11-18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ECG</td>\n",
              "      <td>Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Normal sinus rhythm with marked A-V conduction...</td>\n",
              "      <td>21131118</td>\n",
              "      <td>1</td>\n",
              "      <td>[-0.058894467, 0.12551542, -0.17900251, -0.047...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>905</td>\n",
              "      <td>25</td>\n",
              "      <td>32779</td>\n",
              "      <td>41401</td>\n",
              "      <td>Crnry athrscl natve vssl</td>\n",
              "      <td>Coronary atherosclerosis of native coronary ar...</td>\n",
              "      <td>37</td>\n",
              "      <td>133757.0</td>\n",
              "      <td>2167-10-27</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Discharge summary</td>\n",
              "      <td>Report</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Admission Date:  [**2167-10-20**]             ...</td>\n",
              "      <td>21671027</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.29772723, 0.7641294, -0.79556525, 0.1366110...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                        DOC_VECTORS\n",
              "0      475330  ...  [0.08961867, 0.052252375, -0.021825928, -0.132...\n",
              "1      427689  ...  [0.037899565, 1.2805989, -1.1988019, 0.2361796...\n",
              "2       67171  ...  [0.024404855, 0.060916033, -0.026240427, 0.021...\n",
              "3      245933  ...  [-0.058894467, 0.12551542, -0.17900251, -0.047...\n",
              "4         905  ...  [0.29772723, 0.7641294, -0.79556525, 0.1366110...\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QpRukvJN1En"
      },
      "source": [
        "Finally, we'll just save uniqueNotes as a csv."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_hH0SCzpJQa"
      },
      "source": [
        "uniqueNotes.to_csv(\"/content/drive/MyDrive/cbb 750 final/noteevents_most_recent.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgUu24-0MyFz"
      },
      "source": [
        "## We are now equipped to generate labels for text and non-text data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IukJYeq44e31"
      },
      "source": [
        "[**OPTIONAL CODE BLOCK**] I use this so we don't have to run through the vectorization etc [which takes a long tme] every time I want to classify. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfuOhzgpE0MA"
      },
      "source": [
        "uniqueNotes = pd.read_csv(\"/content/drive/MyDrive/cbb 750 final/noteevents_most_recent.csv\")"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dd5Gut4y170"
      },
      "source": [
        "### Reformatting the document vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7P2K0ebWwhT"
      },
      "source": [
        "The doc vectors are formatted as strings, e.g. ```\"[1 2\\n 3]\"``` so I need to convert into an actual list that I can use for classification. Here's what I do:\n",
        "\n",
        "\n",
        "1.   Split by \" \": ```[\"[1\",\"\",\"2\\n\",\"\",\"3]\"]```\n",
        "2.   Remove ```\"\"``` and ```\\n```: ```[\"[1\",\"2\",\"3]\"]```\n",
        "3.   Remove ```\"[\"```,```\"]\"```: ```[\"1\",\"2\",\"3\"]```\n",
        "4.   Convert all numbers into floats: ```[1,2,3]```\n",
        "\n",
        "After that, we add in subjectids and icd9 codes for each patient, both pulled from the dataframe ```uniqueNotes```. In total we get a df with subjectid, doc vectors and icd9 code. \n",
        "\n",
        "And yes -- we could've used ```docVectors``` here instead of making ```vectorList```, or even bothering to save the ```uniqueNotes``` csv earlier. However, since that would require us to run the doc2Vec step every time we opened the notebook we decided to take a more redundant but less time-intensive approach. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "zCzQpgOkTRZ5",
        "outputId": "6ab47148-54d8-4400-978f-d416181eda0f"
      },
      "source": [
        "# grab doc vectors from the textdata df and place them in a lst\n",
        "vectorlist = uniqueNotes['DOC_VECTORS'].tolist()\n",
        "\n",
        "# process the first vector separately -- this is just to initialize a df that we can append to later\n",
        "\n",
        "# split by \" \"\n",
        "splitvector = vectorlist[0].split(' ')\n",
        "\n",
        "# remove \\n, [ and ]\n",
        "sv = [s.strip('\\n') for s in splitvector] \n",
        "sv = [s.strip('[') for s in sv] \n",
        "sv = [s.strip(']') for s in sv]\n",
        "\n",
        "# remove ''\n",
        "sv = list(filter(None, sv))\n",
        "\n",
        "# convert into floats\n",
        "sv = [float(i) for i in sv]\n",
        "\n",
        "# add subjectid for row 0\n",
        "subid = uniqueNotes.loc[0,'SUBJECT_ID']\n",
        "\n",
        "# insert subjectid at the beginning of sv\n",
        "sv.insert(0,subid)\n",
        "\n",
        "# convert into a df -- we have to transpose so each row represents a subjectID\n",
        "docMatrix = pd.DataFrame(sv).T\n",
        "\n",
        "# we want that first column to be named SUBJECT_ID\n",
        "docMatrix.rename(columns={0: 'SUBJECT_ID'}, inplace=True)\n",
        "\n",
        "# now we can do it for the rest of the matrices\n",
        "\n",
        "for i in range(1,len(vectorlist)):\n",
        "\n",
        "  # split by \" \"\n",
        "  splitvector = vectorlist[i].split(' ')\n",
        "\n",
        "  # remove \\n, [ and ]\n",
        "  sv = [s.strip('\\n') for s in splitvector] \n",
        "  sv = [s.strip('[') for s in sv] \n",
        "  sv = [s.strip(']') for s in sv]\n",
        "\n",
        "  # remove ''\n",
        "  sv = list(filter(None, sv))\n",
        "\n",
        "  # convert into floats\n",
        "  sv = [float(i) for i in sv]\n",
        "\n",
        "  # add subjectid for row i\n",
        "  subid = uniqueNotes.loc[i,'SUBJECT_ID']\n",
        "\n",
        "  # insert subjectid at the beginning of sv\n",
        "  sv.insert(0,subid)\n",
        "\n",
        "  # convert into a df -- we have to transpose so each row represents a subjectID\n",
        "  docvectordf = pd.DataFrame(sv).T\n",
        "\n",
        "  # we want that first column to be named SUBJECT_ID\n",
        "  docvectordf.rename(columns={0: 'SUBJECT_ID'}, inplace=True)\n",
        "\n",
        "  # concatenate with docMatrix\n",
        "  docMatrix = pd.concat([docMatrix, docvectordf])\n",
        "\n",
        "\n",
        "# add in icd9 codes--we only want subject_id and icd9 code\n",
        "subIcd = uniqueNotes[['SUBJECT_ID','ICD9_CODE']]\n",
        "\n",
        "textVectorMat = pd.merge(docMatrix, subIcd, on='SUBJECT_ID')\n",
        "textVectorMat.head()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SUBJECT_ID</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>400</th>\n",
              "      <th>401</th>\n",
              "      <th>402</th>\n",
              "      <th>403</th>\n",
              "      <th>404</th>\n",
              "      <th>405</th>\n",
              "      <th>406</th>\n",
              "      <th>407</th>\n",
              "      <th>408</th>\n",
              "      <th>409</th>\n",
              "      <th>410</th>\n",
              "      <th>411</th>\n",
              "      <th>412</th>\n",
              "      <th>413</th>\n",
              "      <th>414</th>\n",
              "      <th>415</th>\n",
              "      <th>416</th>\n",
              "      <th>417</th>\n",
              "      <th>418</th>\n",
              "      <th>419</th>\n",
              "      <th>420</th>\n",
              "      <th>421</th>\n",
              "      <th>422</th>\n",
              "      <th>423</th>\n",
              "      <th>424</th>\n",
              "      <th>425</th>\n",
              "      <th>426</th>\n",
              "      <th>427</th>\n",
              "      <th>428</th>\n",
              "      <th>429</th>\n",
              "      <th>430</th>\n",
              "      <th>431</th>\n",
              "      <th>432</th>\n",
              "      <th>433</th>\n",
              "      <th>434</th>\n",
              "      <th>435</th>\n",
              "      <th>436</th>\n",
              "      <th>437</th>\n",
              "      <th>438</th>\n",
              "      <th>ICD9_CODE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.089619</td>\n",
              "      <td>0.052252</td>\n",
              "      <td>-0.021826</td>\n",
              "      <td>-0.132506</td>\n",
              "      <td>-0.042356</td>\n",
              "      <td>0.020319</td>\n",
              "      <td>-0.084637</td>\n",
              "      <td>0.043567</td>\n",
              "      <td>0.085690</td>\n",
              "      <td>0.104131</td>\n",
              "      <td>-0.219261</td>\n",
              "      <td>-0.006841</td>\n",
              "      <td>-0.014735</td>\n",
              "      <td>-0.139518</td>\n",
              "      <td>-0.126344</td>\n",
              "      <td>-0.033304</td>\n",
              "      <td>-0.143157</td>\n",
              "      <td>0.069089</td>\n",
              "      <td>0.030358</td>\n",
              "      <td>-0.045158</td>\n",
              "      <td>-0.019508</td>\n",
              "      <td>0.108177</td>\n",
              "      <td>-0.038788</td>\n",
              "      <td>0.039120</td>\n",
              "      <td>-0.099599</td>\n",
              "      <td>0.036201</td>\n",
              "      <td>0.063405</td>\n",
              "      <td>0.127625</td>\n",
              "      <td>-0.119434</td>\n",
              "      <td>0.061013</td>\n",
              "      <td>0.061452</td>\n",
              "      <td>0.048295</td>\n",
              "      <td>-0.012672</td>\n",
              "      <td>0.107825</td>\n",
              "      <td>0.027430</td>\n",
              "      <td>-0.062734</td>\n",
              "      <td>-0.116579</td>\n",
              "      <td>-0.235131</td>\n",
              "      <td>0.187460</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.023470</td>\n",
              "      <td>-0.051412</td>\n",
              "      <td>-0.035115</td>\n",
              "      <td>-0.181673</td>\n",
              "      <td>-0.334576</td>\n",
              "      <td>0.054168</td>\n",
              "      <td>0.277603</td>\n",
              "      <td>0.044134</td>\n",
              "      <td>0.067676</td>\n",
              "      <td>0.012570</td>\n",
              "      <td>-0.021545</td>\n",
              "      <td>-0.094227</td>\n",
              "      <td>0.187627</td>\n",
              "      <td>-0.108871</td>\n",
              "      <td>0.392534</td>\n",
              "      <td>0.182751</td>\n",
              "      <td>-0.015711</td>\n",
              "      <td>0.028222</td>\n",
              "      <td>0.094229</td>\n",
              "      <td>-0.079046</td>\n",
              "      <td>-0.047044</td>\n",
              "      <td>-0.047643</td>\n",
              "      <td>-0.036384</td>\n",
              "      <td>-0.076661</td>\n",
              "      <td>-0.190593</td>\n",
              "      <td>-0.258645</td>\n",
              "      <td>-0.161754</td>\n",
              "      <td>-0.101886</td>\n",
              "      <td>0.247619</td>\n",
              "      <td>0.148518</td>\n",
              "      <td>-0.272157</td>\n",
              "      <td>0.377851</td>\n",
              "      <td>0.044359</td>\n",
              "      <td>-0.028589</td>\n",
              "      <td>-0.044379</td>\n",
              "      <td>-0.251394</td>\n",
              "      <td>-0.058248</td>\n",
              "      <td>0.026036</td>\n",
              "      <td>0.066354</td>\n",
              "      <td>4254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>32773.0</td>\n",
              "      <td>0.037900</td>\n",
              "      <td>1.280599</td>\n",
              "      <td>-1.198802</td>\n",
              "      <td>0.236180</td>\n",
              "      <td>0.036370</td>\n",
              "      <td>0.675872</td>\n",
              "      <td>0.629112</td>\n",
              "      <td>-0.130225</td>\n",
              "      <td>-0.412718</td>\n",
              "      <td>-0.481339</td>\n",
              "      <td>-0.866408</td>\n",
              "      <td>-1.255346</td>\n",
              "      <td>-0.127753</td>\n",
              "      <td>-0.838678</td>\n",
              "      <td>-0.183744</td>\n",
              "      <td>0.261498</td>\n",
              "      <td>-0.780474</td>\n",
              "      <td>0.100076</td>\n",
              "      <td>-1.211127</td>\n",
              "      <td>-0.110204</td>\n",
              "      <td>0.907868</td>\n",
              "      <td>-0.535597</td>\n",
              "      <td>0.010343</td>\n",
              "      <td>0.583626</td>\n",
              "      <td>-1.014816</td>\n",
              "      <td>-0.214748</td>\n",
              "      <td>-0.694396</td>\n",
              "      <td>0.450970</td>\n",
              "      <td>-1.105321</td>\n",
              "      <td>0.560375</td>\n",
              "      <td>0.917860</td>\n",
              "      <td>1.386539</td>\n",
              "      <td>0.841052</td>\n",
              "      <td>-0.044471</td>\n",
              "      <td>-0.230938</td>\n",
              "      <td>-0.304300</td>\n",
              "      <td>-1.274919</td>\n",
              "      <td>0.285135</td>\n",
              "      <td>1.499454</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.880116</td>\n",
              "      <td>-0.234189</td>\n",
              "      <td>-0.507989</td>\n",
              "      <td>-0.867311</td>\n",
              "      <td>-1.063261</td>\n",
              "      <td>0.387865</td>\n",
              "      <td>1.047666</td>\n",
              "      <td>0.363738</td>\n",
              "      <td>0.101880</td>\n",
              "      <td>0.575647</td>\n",
              "      <td>-0.150271</td>\n",
              "      <td>0.270632</td>\n",
              "      <td>0.647120</td>\n",
              "      <td>0.150353</td>\n",
              "      <td>0.999139</td>\n",
              "      <td>0.207273</td>\n",
              "      <td>-0.243467</td>\n",
              "      <td>-0.224171</td>\n",
              "      <td>0.292777</td>\n",
              "      <td>0.291311</td>\n",
              "      <td>0.034713</td>\n",
              "      <td>-0.605638</td>\n",
              "      <td>-0.187541</td>\n",
              "      <td>-0.205559</td>\n",
              "      <td>-0.162911</td>\n",
              "      <td>-0.432236</td>\n",
              "      <td>-1.193741</td>\n",
              "      <td>-0.078325</td>\n",
              "      <td>1.012262</td>\n",
              "      <td>0.142294</td>\n",
              "      <td>-0.799972</td>\n",
              "      <td>0.801669</td>\n",
              "      <td>0.229057</td>\n",
              "      <td>0.770976</td>\n",
              "      <td>0.118697</td>\n",
              "      <td>-1.098328</td>\n",
              "      <td>0.145760</td>\n",
              "      <td>-0.352915</td>\n",
              "      <td>-0.075452</td>\n",
              "      <td>41401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>98310.0</td>\n",
              "      <td>0.024405</td>\n",
              "      <td>0.060916</td>\n",
              "      <td>-0.026240</td>\n",
              "      <td>0.021904</td>\n",
              "      <td>0.080968</td>\n",
              "      <td>0.030698</td>\n",
              "      <td>0.032310</td>\n",
              "      <td>0.059482</td>\n",
              "      <td>0.101521</td>\n",
              "      <td>-0.012271</td>\n",
              "      <td>-0.015543</td>\n",
              "      <td>-0.016276</td>\n",
              "      <td>-0.039184</td>\n",
              "      <td>-0.092102</td>\n",
              "      <td>-0.005182</td>\n",
              "      <td>0.027718</td>\n",
              "      <td>-0.018830</td>\n",
              "      <td>0.103265</td>\n",
              "      <td>-0.021820</td>\n",
              "      <td>0.013832</td>\n",
              "      <td>0.071203</td>\n",
              "      <td>-0.038152</td>\n",
              "      <td>0.025562</td>\n",
              "      <td>0.082105</td>\n",
              "      <td>-0.059190</td>\n",
              "      <td>0.031065</td>\n",
              "      <td>-0.050113</td>\n",
              "      <td>-0.014605</td>\n",
              "      <td>-0.144139</td>\n",
              "      <td>0.020603</td>\n",
              "      <td>0.064529</td>\n",
              "      <td>0.017136</td>\n",
              "      <td>0.052589</td>\n",
              "      <td>0.030546</td>\n",
              "      <td>0.161288</td>\n",
              "      <td>-0.000127</td>\n",
              "      <td>-0.034574</td>\n",
              "      <td>-0.058918</td>\n",
              "      <td>0.058101</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.121251</td>\n",
              "      <td>-0.023908</td>\n",
              "      <td>0.015479</td>\n",
              "      <td>-0.005277</td>\n",
              "      <td>-0.062926</td>\n",
              "      <td>0.087246</td>\n",
              "      <td>-0.041578</td>\n",
              "      <td>0.008861</td>\n",
              "      <td>-0.059243</td>\n",
              "      <td>-0.035365</td>\n",
              "      <td>0.000223</td>\n",
              "      <td>-0.003414</td>\n",
              "      <td>0.027112</td>\n",
              "      <td>-0.077598</td>\n",
              "      <td>0.064644</td>\n",
              "      <td>0.067172</td>\n",
              "      <td>-0.007209</td>\n",
              "      <td>0.035055</td>\n",
              "      <td>0.043486</td>\n",
              "      <td>-0.038148</td>\n",
              "      <td>0.024376</td>\n",
              "      <td>0.053638</td>\n",
              "      <td>0.004943</td>\n",
              "      <td>-0.008121</td>\n",
              "      <td>-0.056503</td>\n",
              "      <td>0.027724</td>\n",
              "      <td>-0.079598</td>\n",
              "      <td>-0.091641</td>\n",
              "      <td>0.043461</td>\n",
              "      <td>0.006822</td>\n",
              "      <td>-0.038066</td>\n",
              "      <td>0.057238</td>\n",
              "      <td>-0.003774</td>\n",
              "      <td>0.048262</td>\n",
              "      <td>0.063009</td>\n",
              "      <td>-0.079670</td>\n",
              "      <td>0.025437</td>\n",
              "      <td>-0.064908</td>\n",
              "      <td>-0.031608</td>\n",
              "      <td>41401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>32777.0</td>\n",
              "      <td>-0.058894</td>\n",
              "      <td>0.125515</td>\n",
              "      <td>-0.179003</td>\n",
              "      <td>-0.047523</td>\n",
              "      <td>0.103142</td>\n",
              "      <td>0.034124</td>\n",
              "      <td>0.132231</td>\n",
              "      <td>0.001654</td>\n",
              "      <td>0.015504</td>\n",
              "      <td>0.021795</td>\n",
              "      <td>-0.049052</td>\n",
              "      <td>-0.045138</td>\n",
              "      <td>-0.053557</td>\n",
              "      <td>-0.013687</td>\n",
              "      <td>-0.074895</td>\n",
              "      <td>0.009845</td>\n",
              "      <td>-0.089473</td>\n",
              "      <td>0.105494</td>\n",
              "      <td>-0.091908</td>\n",
              "      <td>0.024627</td>\n",
              "      <td>0.140748</td>\n",
              "      <td>-0.070351</td>\n",
              "      <td>0.037351</td>\n",
              "      <td>0.080342</td>\n",
              "      <td>-0.041521</td>\n",
              "      <td>-0.077045</td>\n",
              "      <td>-0.019391</td>\n",
              "      <td>0.137661</td>\n",
              "      <td>-0.091484</td>\n",
              "      <td>-0.001705</td>\n",
              "      <td>0.088464</td>\n",
              "      <td>0.063729</td>\n",
              "      <td>0.093147</td>\n",
              "      <td>-0.015200</td>\n",
              "      <td>0.032918</td>\n",
              "      <td>-0.033387</td>\n",
              "      <td>-0.048630</td>\n",
              "      <td>-0.008626</td>\n",
              "      <td>0.092127</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.061280</td>\n",
              "      <td>0.015258</td>\n",
              "      <td>0.020543</td>\n",
              "      <td>-0.043562</td>\n",
              "      <td>-0.075734</td>\n",
              "      <td>0.036938</td>\n",
              "      <td>0.034117</td>\n",
              "      <td>0.020122</td>\n",
              "      <td>0.007017</td>\n",
              "      <td>0.069206</td>\n",
              "      <td>-0.162044</td>\n",
              "      <td>0.015379</td>\n",
              "      <td>0.043651</td>\n",
              "      <td>-0.106714</td>\n",
              "      <td>0.169721</td>\n",
              "      <td>-0.009709</td>\n",
              "      <td>-0.113976</td>\n",
              "      <td>0.002924</td>\n",
              "      <td>0.025379</td>\n",
              "      <td>-0.022767</td>\n",
              "      <td>-0.006232</td>\n",
              "      <td>0.014361</td>\n",
              "      <td>-0.052238</td>\n",
              "      <td>-0.043810</td>\n",
              "      <td>0.016134</td>\n",
              "      <td>0.062307</td>\n",
              "      <td>-0.125156</td>\n",
              "      <td>-0.083779</td>\n",
              "      <td>0.115005</td>\n",
              "      <td>0.022858</td>\n",
              "      <td>-0.073753</td>\n",
              "      <td>0.005794</td>\n",
              "      <td>0.019102</td>\n",
              "      <td>0.069506</td>\n",
              "      <td>0.005619</td>\n",
              "      <td>-0.125494</td>\n",
              "      <td>0.032053</td>\n",
              "      <td>0.001871</td>\n",
              "      <td>-0.059025</td>\n",
              "      <td>41401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32779.0</td>\n",
              "      <td>0.297727</td>\n",
              "      <td>0.764129</td>\n",
              "      <td>-0.795565</td>\n",
              "      <td>0.136611</td>\n",
              "      <td>0.338586</td>\n",
              "      <td>0.258101</td>\n",
              "      <td>0.461119</td>\n",
              "      <td>-0.199550</td>\n",
              "      <td>-0.159668</td>\n",
              "      <td>-0.013619</td>\n",
              "      <td>-0.318710</td>\n",
              "      <td>-0.561159</td>\n",
              "      <td>0.275471</td>\n",
              "      <td>-0.868465</td>\n",
              "      <td>-0.381168</td>\n",
              "      <td>0.197238</td>\n",
              "      <td>-0.805438</td>\n",
              "      <td>0.215284</td>\n",
              "      <td>-0.492362</td>\n",
              "      <td>-0.644972</td>\n",
              "      <td>0.410759</td>\n",
              "      <td>-0.390505</td>\n",
              "      <td>0.617100</td>\n",
              "      <td>1.397771</td>\n",
              "      <td>-1.371298</td>\n",
              "      <td>-0.072344</td>\n",
              "      <td>-0.981251</td>\n",
              "      <td>0.457815</td>\n",
              "      <td>-0.734514</td>\n",
              "      <td>0.033783</td>\n",
              "      <td>1.371656</td>\n",
              "      <td>1.306443</td>\n",
              "      <td>-0.337575</td>\n",
              "      <td>0.030454</td>\n",
              "      <td>0.217532</td>\n",
              "      <td>-0.695523</td>\n",
              "      <td>-0.639070</td>\n",
              "      <td>-0.159521</td>\n",
              "      <td>1.796250</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.223333</td>\n",
              "      <td>-0.102898</td>\n",
              "      <td>-0.321918</td>\n",
              "      <td>-0.844629</td>\n",
              "      <td>-1.359950</td>\n",
              "      <td>0.072841</td>\n",
              "      <td>0.682491</td>\n",
              "      <td>1.163793</td>\n",
              "      <td>0.115487</td>\n",
              "      <td>0.073396</td>\n",
              "      <td>-0.270292</td>\n",
              "      <td>-0.365514</td>\n",
              "      <td>0.854433</td>\n",
              "      <td>-0.638507</td>\n",
              "      <td>1.158583</td>\n",
              "      <td>0.311549</td>\n",
              "      <td>-0.837496</td>\n",
              "      <td>0.109987</td>\n",
              "      <td>0.273512</td>\n",
              "      <td>0.475889</td>\n",
              "      <td>-0.049502</td>\n",
              "      <td>-0.349155</td>\n",
              "      <td>0.041931</td>\n",
              "      <td>0.315722</td>\n",
              "      <td>-0.038122</td>\n",
              "      <td>-0.252612</td>\n",
              "      <td>-1.540189</td>\n",
              "      <td>-0.054510</td>\n",
              "      <td>0.589823</td>\n",
              "      <td>0.098843</td>\n",
              "      <td>-1.072189</td>\n",
              "      <td>1.416626</td>\n",
              "      <td>0.030241</td>\n",
              "      <td>0.601647</td>\n",
              "      <td>0.435277</td>\n",
              "      <td>-1.460064</td>\n",
              "      <td>-0.345699</td>\n",
              "      <td>-0.189441</td>\n",
              "      <td>0.270539</td>\n",
              "      <td>41401</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  440 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   SUBJECT_ID         1         2  ...       437       438  ICD9_CODE\n",
              "0         3.0  0.089619  0.052252  ...  0.026036  0.066354       4254\n",
              "1     32773.0  0.037900  1.280599  ... -0.352915 -0.075452      41401\n",
              "2     98310.0  0.024405  0.060916  ... -0.064908 -0.031608      41401\n",
              "3     32777.0 -0.058894  0.125515  ...  0.001871 -0.059025      41401\n",
              "4     32779.0  0.297727  0.764129  ... -0.189441  0.270539      41401\n",
              "\n",
              "[5 rows x 440 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLNmyxD_zomy"
      },
      "source": [
        "### Labeling the text data\n",
        "\n",
        "Now that we have ICD9 codes linked to subject ids, we can generate labels. We group codes into cardiomyopathy [cm] v. coronary artery disease [cad] and assign a binary label. 0=CM, 1=CAD. \n",
        "\n",
        "Yes -- this is the same approach we took when tagging our documents for doc2vec based on labels.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "NiBnZMgiQozg",
        "outputId": "0d536592-cc04-45d0-91b2-5fadd96e5847"
      },
      "source": [
        "# let's make the labels--basically we want to separate out by icd code\n",
        "# we'll make 0=cardiomyopathy, 1=CAD\n",
        "cm = [42511, 42518, 4254]\n",
        "cad = [44029, 4409, 41401, 4143]\n",
        "\n",
        "# this array contains all the ICD codes in order\n",
        "codes = textVectorMat['ICD9_CODE'].tolist()\n",
        "\n",
        "# this array will contain all the data labels in order\n",
        "text_labels = []\n",
        "\n",
        "# iterate through the rows of textVectorMat and create labels \n",
        "for i in range(len(codes)):\n",
        "\n",
        "  # grab the icd code from row i\n",
        "  icd = codes[i]\n",
        "\n",
        "  # if the icd code is a CM one, append 0 to labels, else if it's CAD append 1\n",
        "  if icd in cm: \n",
        "    text_labels.append(0)\n",
        "  else: \n",
        "    text_labels.append(1)\n",
        "\n",
        "# ensure that the length of the list of labels is the same as the length of codes\n",
        "print(\"labels:\", len(text_labels))\n",
        "print(\"codes:\", len(codes))\n",
        "\n",
        "# let's get rid of the icd9 codes column now oso it doesn't confound our results--axis=1 tells it to drop a column\n",
        "textDataMat = textVectorMat.drop('ICD9_CODE', axis=1)\n",
        "\n",
        "# check our work\n",
        "textDataMat.head()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labels: 11572\n",
            "codes: 11572\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SUBJECT_ID</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>399</th>\n",
              "      <th>400</th>\n",
              "      <th>401</th>\n",
              "      <th>402</th>\n",
              "      <th>403</th>\n",
              "      <th>404</th>\n",
              "      <th>405</th>\n",
              "      <th>406</th>\n",
              "      <th>407</th>\n",
              "      <th>408</th>\n",
              "      <th>409</th>\n",
              "      <th>410</th>\n",
              "      <th>411</th>\n",
              "      <th>412</th>\n",
              "      <th>413</th>\n",
              "      <th>414</th>\n",
              "      <th>415</th>\n",
              "      <th>416</th>\n",
              "      <th>417</th>\n",
              "      <th>418</th>\n",
              "      <th>419</th>\n",
              "      <th>420</th>\n",
              "      <th>421</th>\n",
              "      <th>422</th>\n",
              "      <th>423</th>\n",
              "      <th>424</th>\n",
              "      <th>425</th>\n",
              "      <th>426</th>\n",
              "      <th>427</th>\n",
              "      <th>428</th>\n",
              "      <th>429</th>\n",
              "      <th>430</th>\n",
              "      <th>431</th>\n",
              "      <th>432</th>\n",
              "      <th>433</th>\n",
              "      <th>434</th>\n",
              "      <th>435</th>\n",
              "      <th>436</th>\n",
              "      <th>437</th>\n",
              "      <th>438</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.089619</td>\n",
              "      <td>0.052252</td>\n",
              "      <td>-0.021826</td>\n",
              "      <td>-0.132506</td>\n",
              "      <td>-0.042356</td>\n",
              "      <td>0.020319</td>\n",
              "      <td>-0.084637</td>\n",
              "      <td>0.043567</td>\n",
              "      <td>0.085690</td>\n",
              "      <td>0.104131</td>\n",
              "      <td>-0.219261</td>\n",
              "      <td>-0.006841</td>\n",
              "      <td>-0.014735</td>\n",
              "      <td>-0.139518</td>\n",
              "      <td>-0.126344</td>\n",
              "      <td>-0.033304</td>\n",
              "      <td>-0.143157</td>\n",
              "      <td>0.069089</td>\n",
              "      <td>0.030358</td>\n",
              "      <td>-0.045158</td>\n",
              "      <td>-0.019508</td>\n",
              "      <td>0.108177</td>\n",
              "      <td>-0.038788</td>\n",
              "      <td>0.039120</td>\n",
              "      <td>-0.099599</td>\n",
              "      <td>0.036201</td>\n",
              "      <td>0.063405</td>\n",
              "      <td>0.127625</td>\n",
              "      <td>-0.119434</td>\n",
              "      <td>0.061013</td>\n",
              "      <td>0.061452</td>\n",
              "      <td>0.048295</td>\n",
              "      <td>-0.012672</td>\n",
              "      <td>0.107825</td>\n",
              "      <td>0.027430</td>\n",
              "      <td>-0.062734</td>\n",
              "      <td>-0.116579</td>\n",
              "      <td>-0.235131</td>\n",
              "      <td>0.187460</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.112999</td>\n",
              "      <td>-0.023470</td>\n",
              "      <td>-0.051412</td>\n",
              "      <td>-0.035115</td>\n",
              "      <td>-0.181673</td>\n",
              "      <td>-0.334576</td>\n",
              "      <td>0.054168</td>\n",
              "      <td>0.277603</td>\n",
              "      <td>0.044134</td>\n",
              "      <td>0.067676</td>\n",
              "      <td>0.012570</td>\n",
              "      <td>-0.021545</td>\n",
              "      <td>-0.094227</td>\n",
              "      <td>0.187627</td>\n",
              "      <td>-0.108871</td>\n",
              "      <td>0.392534</td>\n",
              "      <td>0.182751</td>\n",
              "      <td>-0.015711</td>\n",
              "      <td>0.028222</td>\n",
              "      <td>0.094229</td>\n",
              "      <td>-0.079046</td>\n",
              "      <td>-0.047044</td>\n",
              "      <td>-0.047643</td>\n",
              "      <td>-0.036384</td>\n",
              "      <td>-0.076661</td>\n",
              "      <td>-0.190593</td>\n",
              "      <td>-0.258645</td>\n",
              "      <td>-0.161754</td>\n",
              "      <td>-0.101886</td>\n",
              "      <td>0.247619</td>\n",
              "      <td>0.148518</td>\n",
              "      <td>-0.272157</td>\n",
              "      <td>0.377851</td>\n",
              "      <td>0.044359</td>\n",
              "      <td>-0.028589</td>\n",
              "      <td>-0.044379</td>\n",
              "      <td>-0.251394</td>\n",
              "      <td>-0.058248</td>\n",
              "      <td>0.026036</td>\n",
              "      <td>0.066354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>32773.0</td>\n",
              "      <td>0.037900</td>\n",
              "      <td>1.280599</td>\n",
              "      <td>-1.198802</td>\n",
              "      <td>0.236180</td>\n",
              "      <td>0.036370</td>\n",
              "      <td>0.675872</td>\n",
              "      <td>0.629112</td>\n",
              "      <td>-0.130225</td>\n",
              "      <td>-0.412718</td>\n",
              "      <td>-0.481339</td>\n",
              "      <td>-0.866408</td>\n",
              "      <td>-1.255346</td>\n",
              "      <td>-0.127753</td>\n",
              "      <td>-0.838678</td>\n",
              "      <td>-0.183744</td>\n",
              "      <td>0.261498</td>\n",
              "      <td>-0.780474</td>\n",
              "      <td>0.100076</td>\n",
              "      <td>-1.211127</td>\n",
              "      <td>-0.110204</td>\n",
              "      <td>0.907868</td>\n",
              "      <td>-0.535597</td>\n",
              "      <td>0.010343</td>\n",
              "      <td>0.583626</td>\n",
              "      <td>-1.014816</td>\n",
              "      <td>-0.214748</td>\n",
              "      <td>-0.694396</td>\n",
              "      <td>0.450970</td>\n",
              "      <td>-1.105321</td>\n",
              "      <td>0.560375</td>\n",
              "      <td>0.917860</td>\n",
              "      <td>1.386539</td>\n",
              "      <td>0.841052</td>\n",
              "      <td>-0.044471</td>\n",
              "      <td>-0.230938</td>\n",
              "      <td>-0.304300</td>\n",
              "      <td>-1.274919</td>\n",
              "      <td>0.285135</td>\n",
              "      <td>1.499454</td>\n",
              "      <td>...</td>\n",
              "      <td>0.861901</td>\n",
              "      <td>-1.880116</td>\n",
              "      <td>-0.234189</td>\n",
              "      <td>-0.507989</td>\n",
              "      <td>-0.867311</td>\n",
              "      <td>-1.063261</td>\n",
              "      <td>0.387865</td>\n",
              "      <td>1.047666</td>\n",
              "      <td>0.363738</td>\n",
              "      <td>0.101880</td>\n",
              "      <td>0.575647</td>\n",
              "      <td>-0.150271</td>\n",
              "      <td>0.270632</td>\n",
              "      <td>0.647120</td>\n",
              "      <td>0.150353</td>\n",
              "      <td>0.999139</td>\n",
              "      <td>0.207273</td>\n",
              "      <td>-0.243467</td>\n",
              "      <td>-0.224171</td>\n",
              "      <td>0.292777</td>\n",
              "      <td>0.291311</td>\n",
              "      <td>0.034713</td>\n",
              "      <td>-0.605638</td>\n",
              "      <td>-0.187541</td>\n",
              "      <td>-0.205559</td>\n",
              "      <td>-0.162911</td>\n",
              "      <td>-0.432236</td>\n",
              "      <td>-1.193741</td>\n",
              "      <td>-0.078325</td>\n",
              "      <td>1.012262</td>\n",
              "      <td>0.142294</td>\n",
              "      <td>-0.799972</td>\n",
              "      <td>0.801669</td>\n",
              "      <td>0.229057</td>\n",
              "      <td>0.770976</td>\n",
              "      <td>0.118697</td>\n",
              "      <td>-1.098328</td>\n",
              "      <td>0.145760</td>\n",
              "      <td>-0.352915</td>\n",
              "      <td>-0.075452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>98310.0</td>\n",
              "      <td>0.024405</td>\n",
              "      <td>0.060916</td>\n",
              "      <td>-0.026240</td>\n",
              "      <td>0.021904</td>\n",
              "      <td>0.080968</td>\n",
              "      <td>0.030698</td>\n",
              "      <td>0.032310</td>\n",
              "      <td>0.059482</td>\n",
              "      <td>0.101521</td>\n",
              "      <td>-0.012271</td>\n",
              "      <td>-0.015543</td>\n",
              "      <td>-0.016276</td>\n",
              "      <td>-0.039184</td>\n",
              "      <td>-0.092102</td>\n",
              "      <td>-0.005182</td>\n",
              "      <td>0.027718</td>\n",
              "      <td>-0.018830</td>\n",
              "      <td>0.103265</td>\n",
              "      <td>-0.021820</td>\n",
              "      <td>0.013832</td>\n",
              "      <td>0.071203</td>\n",
              "      <td>-0.038152</td>\n",
              "      <td>0.025562</td>\n",
              "      <td>0.082105</td>\n",
              "      <td>-0.059190</td>\n",
              "      <td>0.031065</td>\n",
              "      <td>-0.050113</td>\n",
              "      <td>-0.014605</td>\n",
              "      <td>-0.144139</td>\n",
              "      <td>0.020603</td>\n",
              "      <td>0.064529</td>\n",
              "      <td>0.017136</td>\n",
              "      <td>0.052589</td>\n",
              "      <td>0.030546</td>\n",
              "      <td>0.161288</td>\n",
              "      <td>-0.000127</td>\n",
              "      <td>-0.034574</td>\n",
              "      <td>-0.058918</td>\n",
              "      <td>0.058101</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008253</td>\n",
              "      <td>-0.121251</td>\n",
              "      <td>-0.023908</td>\n",
              "      <td>0.015479</td>\n",
              "      <td>-0.005277</td>\n",
              "      <td>-0.062926</td>\n",
              "      <td>0.087246</td>\n",
              "      <td>-0.041578</td>\n",
              "      <td>0.008861</td>\n",
              "      <td>-0.059243</td>\n",
              "      <td>-0.035365</td>\n",
              "      <td>0.000223</td>\n",
              "      <td>-0.003414</td>\n",
              "      <td>0.027112</td>\n",
              "      <td>-0.077598</td>\n",
              "      <td>0.064644</td>\n",
              "      <td>0.067172</td>\n",
              "      <td>-0.007209</td>\n",
              "      <td>0.035055</td>\n",
              "      <td>0.043486</td>\n",
              "      <td>-0.038148</td>\n",
              "      <td>0.024376</td>\n",
              "      <td>0.053638</td>\n",
              "      <td>0.004943</td>\n",
              "      <td>-0.008121</td>\n",
              "      <td>-0.056503</td>\n",
              "      <td>0.027724</td>\n",
              "      <td>-0.079598</td>\n",
              "      <td>-0.091641</td>\n",
              "      <td>0.043461</td>\n",
              "      <td>0.006822</td>\n",
              "      <td>-0.038066</td>\n",
              "      <td>0.057238</td>\n",
              "      <td>-0.003774</td>\n",
              "      <td>0.048262</td>\n",
              "      <td>0.063009</td>\n",
              "      <td>-0.079670</td>\n",
              "      <td>0.025437</td>\n",
              "      <td>-0.064908</td>\n",
              "      <td>-0.031608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>32777.0</td>\n",
              "      <td>-0.058894</td>\n",
              "      <td>0.125515</td>\n",
              "      <td>-0.179003</td>\n",
              "      <td>-0.047523</td>\n",
              "      <td>0.103142</td>\n",
              "      <td>0.034124</td>\n",
              "      <td>0.132231</td>\n",
              "      <td>0.001654</td>\n",
              "      <td>0.015504</td>\n",
              "      <td>0.021795</td>\n",
              "      <td>-0.049052</td>\n",
              "      <td>-0.045138</td>\n",
              "      <td>-0.053557</td>\n",
              "      <td>-0.013687</td>\n",
              "      <td>-0.074895</td>\n",
              "      <td>0.009845</td>\n",
              "      <td>-0.089473</td>\n",
              "      <td>0.105494</td>\n",
              "      <td>-0.091908</td>\n",
              "      <td>0.024627</td>\n",
              "      <td>0.140748</td>\n",
              "      <td>-0.070351</td>\n",
              "      <td>0.037351</td>\n",
              "      <td>0.080342</td>\n",
              "      <td>-0.041521</td>\n",
              "      <td>-0.077045</td>\n",
              "      <td>-0.019391</td>\n",
              "      <td>0.137661</td>\n",
              "      <td>-0.091484</td>\n",
              "      <td>-0.001705</td>\n",
              "      <td>0.088464</td>\n",
              "      <td>0.063729</td>\n",
              "      <td>0.093147</td>\n",
              "      <td>-0.015200</td>\n",
              "      <td>0.032918</td>\n",
              "      <td>-0.033387</td>\n",
              "      <td>-0.048630</td>\n",
              "      <td>-0.008626</td>\n",
              "      <td>0.092127</td>\n",
              "      <td>...</td>\n",
              "      <td>0.018882</td>\n",
              "      <td>-0.061280</td>\n",
              "      <td>0.015258</td>\n",
              "      <td>0.020543</td>\n",
              "      <td>-0.043562</td>\n",
              "      <td>-0.075734</td>\n",
              "      <td>0.036938</td>\n",
              "      <td>0.034117</td>\n",
              "      <td>0.020122</td>\n",
              "      <td>0.007017</td>\n",
              "      <td>0.069206</td>\n",
              "      <td>-0.162044</td>\n",
              "      <td>0.015379</td>\n",
              "      <td>0.043651</td>\n",
              "      <td>-0.106714</td>\n",
              "      <td>0.169721</td>\n",
              "      <td>-0.009709</td>\n",
              "      <td>-0.113976</td>\n",
              "      <td>0.002924</td>\n",
              "      <td>0.025379</td>\n",
              "      <td>-0.022767</td>\n",
              "      <td>-0.006232</td>\n",
              "      <td>0.014361</td>\n",
              "      <td>-0.052238</td>\n",
              "      <td>-0.043810</td>\n",
              "      <td>0.016134</td>\n",
              "      <td>0.062307</td>\n",
              "      <td>-0.125156</td>\n",
              "      <td>-0.083779</td>\n",
              "      <td>0.115005</td>\n",
              "      <td>0.022858</td>\n",
              "      <td>-0.073753</td>\n",
              "      <td>0.005794</td>\n",
              "      <td>0.019102</td>\n",
              "      <td>0.069506</td>\n",
              "      <td>0.005619</td>\n",
              "      <td>-0.125494</td>\n",
              "      <td>0.032053</td>\n",
              "      <td>0.001871</td>\n",
              "      <td>-0.059025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32779.0</td>\n",
              "      <td>0.297727</td>\n",
              "      <td>0.764129</td>\n",
              "      <td>-0.795565</td>\n",
              "      <td>0.136611</td>\n",
              "      <td>0.338586</td>\n",
              "      <td>0.258101</td>\n",
              "      <td>0.461119</td>\n",
              "      <td>-0.199550</td>\n",
              "      <td>-0.159668</td>\n",
              "      <td>-0.013619</td>\n",
              "      <td>-0.318710</td>\n",
              "      <td>-0.561159</td>\n",
              "      <td>0.275471</td>\n",
              "      <td>-0.868465</td>\n",
              "      <td>-0.381168</td>\n",
              "      <td>0.197238</td>\n",
              "      <td>-0.805438</td>\n",
              "      <td>0.215284</td>\n",
              "      <td>-0.492362</td>\n",
              "      <td>-0.644972</td>\n",
              "      <td>0.410759</td>\n",
              "      <td>-0.390505</td>\n",
              "      <td>0.617100</td>\n",
              "      <td>1.397771</td>\n",
              "      <td>-1.371298</td>\n",
              "      <td>-0.072344</td>\n",
              "      <td>-0.981251</td>\n",
              "      <td>0.457815</td>\n",
              "      <td>-0.734514</td>\n",
              "      <td>0.033783</td>\n",
              "      <td>1.371656</td>\n",
              "      <td>1.306443</td>\n",
              "      <td>-0.337575</td>\n",
              "      <td>0.030454</td>\n",
              "      <td>0.217532</td>\n",
              "      <td>-0.695523</td>\n",
              "      <td>-0.639070</td>\n",
              "      <td>-0.159521</td>\n",
              "      <td>1.796250</td>\n",
              "      <td>...</td>\n",
              "      <td>0.920486</td>\n",
              "      <td>-1.223333</td>\n",
              "      <td>-0.102898</td>\n",
              "      <td>-0.321918</td>\n",
              "      <td>-0.844629</td>\n",
              "      <td>-1.359950</td>\n",
              "      <td>0.072841</td>\n",
              "      <td>0.682491</td>\n",
              "      <td>1.163793</td>\n",
              "      <td>0.115487</td>\n",
              "      <td>0.073396</td>\n",
              "      <td>-0.270292</td>\n",
              "      <td>-0.365514</td>\n",
              "      <td>0.854433</td>\n",
              "      <td>-0.638507</td>\n",
              "      <td>1.158583</td>\n",
              "      <td>0.311549</td>\n",
              "      <td>-0.837496</td>\n",
              "      <td>0.109987</td>\n",
              "      <td>0.273512</td>\n",
              "      <td>0.475889</td>\n",
              "      <td>-0.049502</td>\n",
              "      <td>-0.349155</td>\n",
              "      <td>0.041931</td>\n",
              "      <td>0.315722</td>\n",
              "      <td>-0.038122</td>\n",
              "      <td>-0.252612</td>\n",
              "      <td>-1.540189</td>\n",
              "      <td>-0.054510</td>\n",
              "      <td>0.589823</td>\n",
              "      <td>0.098843</td>\n",
              "      <td>-1.072189</td>\n",
              "      <td>1.416626</td>\n",
              "      <td>0.030241</td>\n",
              "      <td>0.601647</td>\n",
              "      <td>0.435277</td>\n",
              "      <td>-1.460064</td>\n",
              "      <td>-0.345699</td>\n",
              "      <td>-0.189441</td>\n",
              "      <td>0.270539</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  439 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   SUBJECT_ID         1         2  ...       436       437       438\n",
              "0         3.0  0.089619  0.052252  ... -0.058248  0.026036  0.066354\n",
              "1     32773.0  0.037900  1.280599  ...  0.145760 -0.352915 -0.075452\n",
              "2     98310.0  0.024405  0.060916  ...  0.025437 -0.064908 -0.031608\n",
              "3     32777.0 -0.058894  0.125515  ...  0.032053  0.001871 -0.059025\n",
              "4     32779.0  0.297727  0.764129  ... -0.345699 -0.189441  0.270539\n",
              "\n",
              "[5 rows x 439 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_Ay2cfR8FaO"
      },
      "source": [
        "Let's save ```textDataMat``` as a csv."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6yKYFX_8LI1"
      },
      "source": [
        "textDataMat.to_csv(\"/content/drive/MyDrive/cbb 750 final/textdatamat.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dw-WENkk7qZ"
      },
      "source": [
        "### Extracting labels from non-text matrix\n",
        "\n",
        "We're doing something different here. We'll perform some imputation, i.e. fill in the NA values of the matrix. We've used a naive approach here:\n",
        "  * If a column has a NA value in a given cell we replace the NA with the mean value for the column. \n",
        "  * If a column has only NA values we get rid of it as it will do nothing to aid classification. \n",
        "\n",
        "We also make sure that the ```SUBJECT_ID``` column is labeled as such and remove rows with duplicate ```SUBJECT_ID``` [We want one classification per patient--since we have already selected for the most recent lab readings we expect any duplicate ```SUBJECT_ID```s to be the result of error/row duplication]. \n",
        "\n",
        "After imputation we grab ICD9 codes for each patient and make labels using the same approach as for the text data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "-Ggpexhkk-TX",
        "outputId": "63e5ff58-54ca-4882-f404-ffe1100afaf9"
      },
      "source": [
        "# fill the na values with the mean of each column, idea from here https://stackoverflow.com/questions/18689823/pandas-dataframe-replace-nan-values-with-average-of-columns\n",
        "filledna_nontext = nontext.fillna(nontext.mean())\n",
        "\n",
        "# what if we get rid of all columns with only NA values? from https://stackoverflow.com/questions/45147100/pandas-drop-columns-with-all-nans\n",
        "filledna_processed_nontext = filledna_nontext.dropna(axis=1, how='all')\n",
        "\n",
        "# change \"Unnamed: 0\" column to SUBJECT_ID to match Saejeong's data\n",
        "# from https://stackoverflow.com/questions/11346283/renaming-columns-in-pandas\n",
        "filledna_processed_nontext.rename(columns={'Unnamed: 0': 'SUBJECT_ID'}, inplace=True)\n",
        "\n",
        "# we need to do a bit of processing on this. \n",
        "# get rid of duplicate subject id\n",
        "filledna_processed_nontext = filledna_processed_nontext.drop_duplicates(subset='SUBJECT_ID', keep='first')\n",
        "\n",
        "# merge with Saejeong's data to get icd codes for each patient\n",
        "nontext_with_icd = pd.merge(data, filledna_processed_nontext, on=\"SUBJECT_ID\")\n",
        "\n",
        "# let's make the labels--basically we want to separate out by icd code\n",
        "# we'll make 0=cardiomyopathy, 1=CAD\n",
        "cm = [42511, 42518, 4254]\n",
        "cad = [44029, 4409, 41401, 4143]\n",
        "\n",
        "# this array will contain all the data labels in order\n",
        "nontext_labels = []\n",
        "\n",
        "# iterate through the rows of nontext_with_icd and create labels for filledna_processed_nontext\n",
        "# we can't feed nontext_with_icd into the classifier because it contains [unprocessed] labels for everything!\n",
        "for i in range(len(nontext_with_icd)):\n",
        "\n",
        "  # grab the icd code from row i\n",
        "  icd = nontext_with_icd.loc[i,'ICD9_CODE']\n",
        "\n",
        "  # if the icd code is a CM one, append 0 to labels, else if it's CAD append 1\n",
        "  if icd in cm: \n",
        "    nontext_labels.append(0)\n",
        "  elif icd in cad: \n",
        "    nontext_labels.append(1)\n",
        "  else: # this is a value which we need to filter out\n",
        "    print(nontext_with_icd.loc[i])\n",
        "\n",
        "filledna_processed_nontext.head()\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SUBJECT_ID</th>\n",
              "      <th>Base Excess</th>\n",
              "      <th>Calculated Total CO2</th>\n",
              "      <th>Free Calcium</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>Hematocrit</th>\n",
              "      <th>Calculated</th>\n",
              "      <th>Hemoglobin</th>\n",
              "      <th>Lactate</th>\n",
              "      <th>O2 Flow</th>\n",
              "      <th>Oxygen</th>\n",
              "      <th>pCO2</th>\n",
              "      <th>PEEP</th>\n",
              "      <th>pH</th>\n",
              "      <th>pO2</th>\n",
              "      <th>Potassium</th>\n",
              "      <th>Whole Blood</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Tidal Volume</th>\n",
              "      <th>% Hemoglobin A1c</th>\n",
              "      <th>Alanine Aminotransferase (ALT)</th>\n",
              "      <th>Albumin</th>\n",
              "      <th>Alkaline Phosphatase</th>\n",
              "      <th>Amylase</th>\n",
              "      <th>Anion Gap</th>\n",
              "      <th>Asparate Aminotransferase (AST)</th>\n",
              "      <th>Bicarbonate</th>\n",
              "      <th>Bilirubin</th>\n",
              "      <th>Total</th>\n",
              "      <th>Calcium</th>\n",
              "      <th>Total.1</th>\n",
              "      <th>Chloride</th>\n",
              "      <th>Creatine Kinase (CK)</th>\n",
              "      <th>Creatinine</th>\n",
              "      <th>Ethanol</th>\n",
              "      <th>Glucose.1</th>\n",
              "      <th>Lactate Dehydrogenase (LD)</th>\n",
              "      <th>Lipase</th>\n",
              "      <th>Magnesium</th>\n",
              "      <th>Phenytoin</th>\n",
              "      <th>...</th>\n",
              "      <th>Bicarbonate.1</th>\n",
              "      <th>Other Fluid.3</th>\n",
              "      <th>Chloride.3</th>\n",
              "      <th>Body Fluid.7</th>\n",
              "      <th>Sodium.3</th>\n",
              "      <th>Body Fluid.8</th>\n",
              "      <th>Thyroglobulin</th>\n",
              "      <th>Hematocrit.5</th>\n",
              "      <th>Pleural.9</th>\n",
              "      <th>Leukocyte Alkaline Phosphatase</th>\n",
              "      <th>Basophils.3</th>\n",
              "      <th>CA-125</th>\n",
              "      <th>NRBC</th>\n",
              "      <th>Hematocrit.6</th>\n",
              "      <th>Joint Fluid.2</th>\n",
              "      <th>Anti-Thyroglobulin Antibodies</th>\n",
              "      <th>Bands.5</th>\n",
              "      <th>Cellular Cast</th>\n",
              "      <th>Human Chorionic Gonadotropin</th>\n",
              "      <th>Fetal Hemoglobin</th>\n",
              "      <th>WBC Casts</th>\n",
              "      <th>Creatinine.6</th>\n",
              "      <th>Joint Fluid.3</th>\n",
              "      <th>CD19</th>\n",
              "      <th>CD3</th>\n",
              "      <th>CD34</th>\n",
              "      <th>Cancer Antigen 27.29</th>\n",
              "      <th>Carbamazepine</th>\n",
              "      <th>Phenobarbital</th>\n",
              "      <th>Glucose.7</th>\n",
              "      <th>Joint Fluid.4</th>\n",
              "      <th>LD.1</th>\n",
              "      <th>Joint Fluid.5</th>\n",
              "      <th>Heparin.1</th>\n",
              "      <th>Cholesterol.4</th>\n",
              "      <th>Pleural.10</th>\n",
              "      <th>Bleeding Time</th>\n",
              "      <th>CD10</th>\n",
              "      <th>CD19.1</th>\n",
              "      <th>CD20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10004</td>\n",
              "      <td>1.080000</td>\n",
              "      <td>25.680000</td>\n",
              "      <td>1.038571</td>\n",
              "      <td>216.666667</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>12.300</td>\n",
              "      <td>5.900000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>43.571429</td>\n",
              "      <td>35.840000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>7.438000</td>\n",
              "      <td>163.600000</td>\n",
              "      <td>4.550000</td>\n",
              "      <td>38.318750</td>\n",
              "      <td>478.454545</td>\n",
              "      <td>6.200000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>3.375000</td>\n",
              "      <td>58.0</td>\n",
              "      <td>109.500000</td>\n",
              "      <td>15.130435</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>24.26087</td>\n",
              "      <td>0.700</td>\n",
              "      <td>8.433333</td>\n",
              "      <td>104.130435</td>\n",
              "      <td>370.500000</td>\n",
              "      <td>0.978261</td>\n",
              "      <td>158.000000</td>\n",
              "      <td>157.086957</td>\n",
              "      <td>294.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>1.926316</td>\n",
              "      <td>8.233333</td>\n",
              "      <td>3.177778</td>\n",
              "      <td>4.382609</td>\n",
              "      <td>139.086957</td>\n",
              "      <td>21.375000</td>\n",
              "      <td>...</td>\n",
              "      <td>4.05</td>\n",
              "      <td>3.65</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.98</td>\n",
              "      <td>12.6</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>1.0</td>\n",
              "      <td>109.125</td>\n",
              "      <td>2.5</td>\n",
              "      <td>52.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>40.5</td>\n",
              "      <td>78.0</td>\n",
              "      <td>1.009</td>\n",
              "      <td>55.5</td>\n",
              "      <td>8.958525</td>\n",
              "      <td>269.0</td>\n",
              "      <td>13.8</td>\n",
              "      <td>72.65</td>\n",
              "      <td>1002.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>150.5</td>\n",
              "      <td>37.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>610.0</td>\n",
              "      <td>74.8</td>\n",
              "      <td>606.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10006</td>\n",
              "      <td>8.500000</td>\n",
              "      <td>33.500000</td>\n",
              "      <td>1.170000</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>7.100</td>\n",
              "      <td>3.344444</td>\n",
              "      <td>11.352035</td>\n",
              "      <td>65.170681</td>\n",
              "      <td>42.500000</td>\n",
              "      <td>6.384682</td>\n",
              "      <td>7.476667</td>\n",
              "      <td>97.500000</td>\n",
              "      <td>3.925000</td>\n",
              "      <td>38.700000</td>\n",
              "      <td>609.028904</td>\n",
              "      <td>5.500000</td>\n",
              "      <td>7.333333</td>\n",
              "      <td>2.709091</td>\n",
              "      <td>121.8</td>\n",
              "      <td>75.500000</td>\n",
              "      <td>15.754098</td>\n",
              "      <td>30.166667</td>\n",
              "      <td>26.95082</td>\n",
              "      <td>0.640</td>\n",
              "      <td>9.036364</td>\n",
              "      <td>100.475410</td>\n",
              "      <td>58.285714</td>\n",
              "      <td>5.417742</td>\n",
              "      <td>166.799014</td>\n",
              "      <td>126.819672</td>\n",
              "      <td>448.500000</td>\n",
              "      <td>35.666667</td>\n",
              "      <td>1.721053</td>\n",
              "      <td>9.679334</td>\n",
              "      <td>4.589474</td>\n",
              "      <td>3.938806</td>\n",
              "      <td>139.096774</td>\n",
              "      <td>22.245902</td>\n",
              "      <td>...</td>\n",
              "      <td>4.05</td>\n",
              "      <td>3.65</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.98</td>\n",
              "      <td>12.6</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>1.0</td>\n",
              "      <td>109.125</td>\n",
              "      <td>2.5</td>\n",
              "      <td>52.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>40.5</td>\n",
              "      <td>78.0</td>\n",
              "      <td>1.009</td>\n",
              "      <td>55.5</td>\n",
              "      <td>8.958525</td>\n",
              "      <td>269.0</td>\n",
              "      <td>13.8</td>\n",
              "      <td>72.65</td>\n",
              "      <td>1002.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>150.5</td>\n",
              "      <td>37.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>610.0</td>\n",
              "      <td>74.8</td>\n",
              "      <td>606.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10012</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>27.571429</td>\n",
              "      <td>1.140000</td>\n",
              "      <td>147.666667</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>11.025</td>\n",
              "      <td>2.166611</td>\n",
              "      <td>11.352035</td>\n",
              "      <td>65.170681</td>\n",
              "      <td>45.571429</td>\n",
              "      <td>6.384682</td>\n",
              "      <td>7.381111</td>\n",
              "      <td>283.000000</td>\n",
              "      <td>4.340000</td>\n",
              "      <td>37.021663</td>\n",
              "      <td>609.028904</td>\n",
              "      <td>7.400000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>4.100000</td>\n",
              "      <td>71.0</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>11.333333</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>26.25000</td>\n",
              "      <td>0.600</td>\n",
              "      <td>8.567173</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>446.854324</td>\n",
              "      <td>0.616667</td>\n",
              "      <td>166.799014</td>\n",
              "      <td>124.666667</td>\n",
              "      <td>360.441124</td>\n",
              "      <td>59.480840</td>\n",
              "      <td>2.250000</td>\n",
              "      <td>9.679334</td>\n",
              "      <td>3.507365</td>\n",
              "      <td>4.133333</td>\n",
              "      <td>136.666667</td>\n",
              "      <td>10.800000</td>\n",
              "      <td>...</td>\n",
              "      <td>4.05</td>\n",
              "      <td>3.65</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.98</td>\n",
              "      <td>12.6</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>1.0</td>\n",
              "      <td>109.125</td>\n",
              "      <td>2.5</td>\n",
              "      <td>52.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>40.5</td>\n",
              "      <td>78.0</td>\n",
              "      <td>1.009</td>\n",
              "      <td>55.5</td>\n",
              "      <td>8.958525</td>\n",
              "      <td>269.0</td>\n",
              "      <td>13.8</td>\n",
              "      <td>72.65</td>\n",
              "      <td>1002.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>150.5</td>\n",
              "      <td>37.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>610.0</td>\n",
              "      <td>74.8</td>\n",
              "      <td>606.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10027</td>\n",
              "      <td>-0.764706</td>\n",
              "      <td>22.323529</td>\n",
              "      <td>1.151667</td>\n",
              "      <td>126.696970</td>\n",
              "      <td>24.833333</td>\n",
              "      <td>8.300</td>\n",
              "      <td>2.166611</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>65.170681</td>\n",
              "      <td>31.411765</td>\n",
              "      <td>6.384682</td>\n",
              "      <td>7.449459</td>\n",
              "      <td>183.323529</td>\n",
              "      <td>4.461765</td>\n",
              "      <td>36.300000</td>\n",
              "      <td>609.028904</td>\n",
              "      <td>8.400000</td>\n",
              "      <td>74.200000</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>72.0</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>15.333333</td>\n",
              "      <td>109.000000</td>\n",
              "      <td>24.18750</td>\n",
              "      <td>2.175</td>\n",
              "      <td>8.500000</td>\n",
              "      <td>106.437500</td>\n",
              "      <td>446.854324</td>\n",
              "      <td>2.252632</td>\n",
              "      <td>166.799014</td>\n",
              "      <td>179.769231</td>\n",
              "      <td>360.441124</td>\n",
              "      <td>59.480840</td>\n",
              "      <td>2.812500</td>\n",
              "      <td>9.679334</td>\n",
              "      <td>4.657143</td>\n",
              "      <td>4.292308</td>\n",
              "      <td>142.266667</td>\n",
              "      <td>55.526316</td>\n",
              "      <td>...</td>\n",
              "      <td>4.05</td>\n",
              "      <td>3.65</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.98</td>\n",
              "      <td>12.6</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>1.0</td>\n",
              "      <td>109.125</td>\n",
              "      <td>2.5</td>\n",
              "      <td>52.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>40.5</td>\n",
              "      <td>78.0</td>\n",
              "      <td>1.009</td>\n",
              "      <td>55.5</td>\n",
              "      <td>8.958525</td>\n",
              "      <td>269.0</td>\n",
              "      <td>13.8</td>\n",
              "      <td>72.65</td>\n",
              "      <td>1002.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>150.5</td>\n",
              "      <td>37.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>610.0</td>\n",
              "      <td>74.8</td>\n",
              "      <td>606.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10028</td>\n",
              "      <td>-2.272727</td>\n",
              "      <td>24.090909</td>\n",
              "      <td>1.189000</td>\n",
              "      <td>132.928571</td>\n",
              "      <td>28.600000</td>\n",
              "      <td>9.560</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>11.352035</td>\n",
              "      <td>65.170681</td>\n",
              "      <td>40.545455</td>\n",
              "      <td>6.384682</td>\n",
              "      <td>7.354286</td>\n",
              "      <td>271.272727</td>\n",
              "      <td>4.466667</td>\n",
              "      <td>37.800000</td>\n",
              "      <td>609.028904</td>\n",
              "      <td>6.504683</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>3.900000</td>\n",
              "      <td>92.5</td>\n",
              "      <td>74.461687</td>\n",
              "      <td>13.500000</td>\n",
              "      <td>21.500000</td>\n",
              "      <td>22.40000</td>\n",
              "      <td>0.100</td>\n",
              "      <td>7.900000</td>\n",
              "      <td>106.600000</td>\n",
              "      <td>446.854324</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>166.799014</td>\n",
              "      <td>112.750000</td>\n",
              "      <td>162.000000</td>\n",
              "      <td>59.480840</td>\n",
              "      <td>1.833333</td>\n",
              "      <td>9.679334</td>\n",
              "      <td>5.200000</td>\n",
              "      <td>4.175000</td>\n",
              "      <td>139.000000</td>\n",
              "      <td>14.600000</td>\n",
              "      <td>...</td>\n",
              "      <td>4.05</td>\n",
              "      <td>3.65</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.98</td>\n",
              "      <td>12.6</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>1.0</td>\n",
              "      <td>109.125</td>\n",
              "      <td>2.5</td>\n",
              "      <td>52.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>40.5</td>\n",
              "      <td>78.0</td>\n",
              "      <td>1.009</td>\n",
              "      <td>55.5</td>\n",
              "      <td>8.958525</td>\n",
              "      <td>269.0</td>\n",
              "      <td>13.8</td>\n",
              "      <td>72.65</td>\n",
              "      <td>1002.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>150.5</td>\n",
              "      <td>37.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>610.0</td>\n",
              "      <td>74.8</td>\n",
              "      <td>606.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  439 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   SUBJECT_ID  Base Excess  Calculated Total CO2  ...  CD10  CD19.1  CD20\n",
              "0       10004     1.080000             25.680000  ...  74.8   606.0   2.0\n",
              "1       10006     8.500000             33.500000  ...  74.8   606.0   2.0\n",
              "2       10012     0.857143             27.571429  ...  74.8   606.0   2.0\n",
              "3       10027    -0.764706             22.323529  ...  74.8   606.0   2.0\n",
              "4       10028    -2.272727             24.090909  ...  74.8   606.0   2.0\n",
              "\n",
              "[5 rows x 439 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-eRO5jK8l4E"
      },
      "source": [
        "Let's save ```filledna_processed_nontext``` as a csv. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDLvC8q38pP7"
      },
      "source": [
        "filledna_processed_nontext.to_csv(\"/content/drive/MyDrive/cbb 750 final/filledna_processed_nontext.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgTXWvNmiJOt"
      },
      "source": [
        "### Create a merged text-nontext df and generate labels\n",
        "\n",
        "We're merging ```filledna_processed_nontext``` and ```textVectorMat``` on ```SUBJECT_ID.``` Just to be extra cautious, in case the row order got messed up in the merge, we'll regenerate the labels. \n",
        "\n",
        "You'll also notice I'm merging ```textVectorMat```, not ```textDataMat```. That's because I still need that ```ICD9_CODE``` column to make my labels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "tnOSgPJriMpT",
        "outputId": "7740eb08-8b89-47f9-a68c-a44848ef02fc"
      },
      "source": [
        "# merge the datasets\n",
        "textNontextMerge = pd.merge(textVectorMat, filledna_processed_nontext, on='SUBJECT_ID')\n",
        "\n",
        "# I know this is repetitive! Just leave it for now... these are the icd codes\n",
        "# we do cm=0, cad-1\n",
        "cm = [42511, 42518, 4254]\n",
        "cad = [44029, 4409, 41401, 4143]\n",
        "\n",
        "# this array contains all the ICD codes in order\n",
        "codes = textNontextMerge['ICD9_CODE'].tolist()\n",
        "\n",
        "# this array will contain all the data labels in order\n",
        "text_nontext_labels = []\n",
        "\n",
        "# iterate through the rows of textVectorMat and create labels \n",
        "for i in range(len(codes)):\n",
        "\n",
        "  # grab the icd code from row i\n",
        "  icd = codes[i]\n",
        "\n",
        "  # if the icd code is a CM one, append 0 to labels, else if it's CAD append 1\n",
        "  if icd in cm: \n",
        "    text_nontext_labels.append(0)\n",
        "  else: \n",
        "    text_nontext_labels.append(1)\n",
        "\n",
        "# ensure that the length of the list of labels is the same as the length of codes\n",
        "print(\"labels:\", len(text_nontext_labels))\n",
        "print(\"codes:\", len(codes))\n",
        "\n",
        "# let's get rid of the icd9 codes column now oso it doesn't confound our results--axis=1 tells it to drop a column\n",
        "textNontextData = textNontextMerge.drop('ICD9_CODE', axis=1)\n",
        "\n",
        "# check our work\n",
        "textNontextData.head()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labels: 11567\n",
            "codes: 11567\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SUBJECT_ID</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>Bicarbonate.1</th>\n",
              "      <th>Other Fluid.3</th>\n",
              "      <th>Chloride.3</th>\n",
              "      <th>Body Fluid.7</th>\n",
              "      <th>Sodium.3</th>\n",
              "      <th>Body Fluid.8</th>\n",
              "      <th>Thyroglobulin</th>\n",
              "      <th>Hematocrit.5</th>\n",
              "      <th>Pleural.9</th>\n",
              "      <th>Leukocyte Alkaline Phosphatase</th>\n",
              "      <th>Basophils.3</th>\n",
              "      <th>CA-125</th>\n",
              "      <th>NRBC</th>\n",
              "      <th>Hematocrit.6</th>\n",
              "      <th>Joint Fluid.2</th>\n",
              "      <th>Anti-Thyroglobulin Antibodies</th>\n",
              "      <th>Bands.5</th>\n",
              "      <th>Cellular Cast</th>\n",
              "      <th>Human Chorionic Gonadotropin</th>\n",
              "      <th>Fetal Hemoglobin</th>\n",
              "      <th>WBC Casts</th>\n",
              "      <th>Creatinine.6</th>\n",
              "      <th>Joint Fluid.3</th>\n",
              "      <th>CD19</th>\n",
              "      <th>CD3</th>\n",
              "      <th>CD34</th>\n",
              "      <th>Cancer Antigen 27.29</th>\n",
              "      <th>Carbamazepine</th>\n",
              "      <th>Phenobarbital</th>\n",
              "      <th>Glucose.7</th>\n",
              "      <th>Joint Fluid.4</th>\n",
              "      <th>LD.1</th>\n",
              "      <th>Joint Fluid.5</th>\n",
              "      <th>Heparin.1</th>\n",
              "      <th>Cholesterol.4</th>\n",
              "      <th>Pleural.10</th>\n",
              "      <th>Bleeding Time</th>\n",
              "      <th>CD10</th>\n",
              "      <th>CD19.1</th>\n",
              "      <th>CD20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.089619</td>\n",
              "      <td>0.052252</td>\n",
              "      <td>-0.021826</td>\n",
              "      <td>-0.132506</td>\n",
              "      <td>-0.042356</td>\n",
              "      <td>0.020319</td>\n",
              "      <td>-0.084637</td>\n",
              "      <td>0.043567</td>\n",
              "      <td>0.085690</td>\n",
              "      <td>0.104131</td>\n",
              "      <td>-0.219261</td>\n",
              "      <td>-0.006841</td>\n",
              "      <td>-0.014735</td>\n",
              "      <td>-0.139518</td>\n",
              "      <td>-0.126344</td>\n",
              "      <td>-0.033304</td>\n",
              "      <td>-0.143157</td>\n",
              "      <td>0.069089</td>\n",
              "      <td>0.030358</td>\n",
              "      <td>-0.045158</td>\n",
              "      <td>-0.019508</td>\n",
              "      <td>0.108177</td>\n",
              "      <td>-0.038788</td>\n",
              "      <td>0.039120</td>\n",
              "      <td>-0.099599</td>\n",
              "      <td>0.036201</td>\n",
              "      <td>0.063405</td>\n",
              "      <td>0.127625</td>\n",
              "      <td>-0.119434</td>\n",
              "      <td>0.061013</td>\n",
              "      <td>0.061452</td>\n",
              "      <td>0.048295</td>\n",
              "      <td>-0.012672</td>\n",
              "      <td>0.107825</td>\n",
              "      <td>0.027430</td>\n",
              "      <td>-0.062734</td>\n",
              "      <td>-0.116579</td>\n",
              "      <td>-0.235131</td>\n",
              "      <td>0.187460</td>\n",
              "      <td>...</td>\n",
              "      <td>4.05</td>\n",
              "      <td>3.65</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.98</td>\n",
              "      <td>12.6</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>1.0</td>\n",
              "      <td>109.125</td>\n",
              "      <td>2.5</td>\n",
              "      <td>52.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>40.5</td>\n",
              "      <td>78.0</td>\n",
              "      <td>1.009</td>\n",
              "      <td>55.5</td>\n",
              "      <td>8.958525</td>\n",
              "      <td>269.0</td>\n",
              "      <td>13.8</td>\n",
              "      <td>72.65</td>\n",
              "      <td>1002.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>150.5</td>\n",
              "      <td>37.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>610.0</td>\n",
              "      <td>74.8</td>\n",
              "      <td>606.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>32773.0</td>\n",
              "      <td>0.037900</td>\n",
              "      <td>1.280599</td>\n",
              "      <td>-1.198802</td>\n",
              "      <td>0.236180</td>\n",
              "      <td>0.036370</td>\n",
              "      <td>0.675872</td>\n",
              "      <td>0.629112</td>\n",
              "      <td>-0.130225</td>\n",
              "      <td>-0.412718</td>\n",
              "      <td>-0.481339</td>\n",
              "      <td>-0.866408</td>\n",
              "      <td>-1.255346</td>\n",
              "      <td>-0.127753</td>\n",
              "      <td>-0.838678</td>\n",
              "      <td>-0.183744</td>\n",
              "      <td>0.261498</td>\n",
              "      <td>-0.780474</td>\n",
              "      <td>0.100076</td>\n",
              "      <td>-1.211127</td>\n",
              "      <td>-0.110204</td>\n",
              "      <td>0.907868</td>\n",
              "      <td>-0.535597</td>\n",
              "      <td>0.010343</td>\n",
              "      <td>0.583626</td>\n",
              "      <td>-1.014816</td>\n",
              "      <td>-0.214748</td>\n",
              "      <td>-0.694396</td>\n",
              "      <td>0.450970</td>\n",
              "      <td>-1.105321</td>\n",
              "      <td>0.560375</td>\n",
              "      <td>0.917860</td>\n",
              "      <td>1.386539</td>\n",
              "      <td>0.841052</td>\n",
              "      <td>-0.044471</td>\n",
              "      <td>-0.230938</td>\n",
              "      <td>-0.304300</td>\n",
              "      <td>-1.274919</td>\n",
              "      <td>0.285135</td>\n",
              "      <td>1.499454</td>\n",
              "      <td>...</td>\n",
              "      <td>4.05</td>\n",
              "      <td>3.65</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.98</td>\n",
              "      <td>12.6</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>1.0</td>\n",
              "      <td>109.125</td>\n",
              "      <td>2.5</td>\n",
              "      <td>52.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>40.5</td>\n",
              "      <td>78.0</td>\n",
              "      <td>1.009</td>\n",
              "      <td>55.5</td>\n",
              "      <td>8.958525</td>\n",
              "      <td>269.0</td>\n",
              "      <td>13.8</td>\n",
              "      <td>72.65</td>\n",
              "      <td>1002.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>150.5</td>\n",
              "      <td>37.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>610.0</td>\n",
              "      <td>74.8</td>\n",
              "      <td>606.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>98310.0</td>\n",
              "      <td>0.024405</td>\n",
              "      <td>0.060916</td>\n",
              "      <td>-0.026240</td>\n",
              "      <td>0.021904</td>\n",
              "      <td>0.080968</td>\n",
              "      <td>0.030698</td>\n",
              "      <td>0.032310</td>\n",
              "      <td>0.059482</td>\n",
              "      <td>0.101521</td>\n",
              "      <td>-0.012271</td>\n",
              "      <td>-0.015543</td>\n",
              "      <td>-0.016276</td>\n",
              "      <td>-0.039184</td>\n",
              "      <td>-0.092102</td>\n",
              "      <td>-0.005182</td>\n",
              "      <td>0.027718</td>\n",
              "      <td>-0.018830</td>\n",
              "      <td>0.103265</td>\n",
              "      <td>-0.021820</td>\n",
              "      <td>0.013832</td>\n",
              "      <td>0.071203</td>\n",
              "      <td>-0.038152</td>\n",
              "      <td>0.025562</td>\n",
              "      <td>0.082105</td>\n",
              "      <td>-0.059190</td>\n",
              "      <td>0.031065</td>\n",
              "      <td>-0.050113</td>\n",
              "      <td>-0.014605</td>\n",
              "      <td>-0.144139</td>\n",
              "      <td>0.020603</td>\n",
              "      <td>0.064529</td>\n",
              "      <td>0.017136</td>\n",
              "      <td>0.052589</td>\n",
              "      <td>0.030546</td>\n",
              "      <td>0.161288</td>\n",
              "      <td>-0.000127</td>\n",
              "      <td>-0.034574</td>\n",
              "      <td>-0.058918</td>\n",
              "      <td>0.058101</td>\n",
              "      <td>...</td>\n",
              "      <td>4.05</td>\n",
              "      <td>3.65</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.98</td>\n",
              "      <td>12.6</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>1.0</td>\n",
              "      <td>109.125</td>\n",
              "      <td>2.5</td>\n",
              "      <td>52.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>40.5</td>\n",
              "      <td>78.0</td>\n",
              "      <td>1.009</td>\n",
              "      <td>55.5</td>\n",
              "      <td>8.958525</td>\n",
              "      <td>269.0</td>\n",
              "      <td>13.8</td>\n",
              "      <td>72.65</td>\n",
              "      <td>1002.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>150.5</td>\n",
              "      <td>37.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>610.0</td>\n",
              "      <td>74.8</td>\n",
              "      <td>606.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>32777.0</td>\n",
              "      <td>-0.058894</td>\n",
              "      <td>0.125515</td>\n",
              "      <td>-0.179003</td>\n",
              "      <td>-0.047523</td>\n",
              "      <td>0.103142</td>\n",
              "      <td>0.034124</td>\n",
              "      <td>0.132231</td>\n",
              "      <td>0.001654</td>\n",
              "      <td>0.015504</td>\n",
              "      <td>0.021795</td>\n",
              "      <td>-0.049052</td>\n",
              "      <td>-0.045138</td>\n",
              "      <td>-0.053557</td>\n",
              "      <td>-0.013687</td>\n",
              "      <td>-0.074895</td>\n",
              "      <td>0.009845</td>\n",
              "      <td>-0.089473</td>\n",
              "      <td>0.105494</td>\n",
              "      <td>-0.091908</td>\n",
              "      <td>0.024627</td>\n",
              "      <td>0.140748</td>\n",
              "      <td>-0.070351</td>\n",
              "      <td>0.037351</td>\n",
              "      <td>0.080342</td>\n",
              "      <td>-0.041521</td>\n",
              "      <td>-0.077045</td>\n",
              "      <td>-0.019391</td>\n",
              "      <td>0.137661</td>\n",
              "      <td>-0.091484</td>\n",
              "      <td>-0.001705</td>\n",
              "      <td>0.088464</td>\n",
              "      <td>0.063729</td>\n",
              "      <td>0.093147</td>\n",
              "      <td>-0.015200</td>\n",
              "      <td>0.032918</td>\n",
              "      <td>-0.033387</td>\n",
              "      <td>-0.048630</td>\n",
              "      <td>-0.008626</td>\n",
              "      <td>0.092127</td>\n",
              "      <td>...</td>\n",
              "      <td>4.05</td>\n",
              "      <td>3.65</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.98</td>\n",
              "      <td>12.6</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>1.0</td>\n",
              "      <td>109.125</td>\n",
              "      <td>2.5</td>\n",
              "      <td>52.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>40.5</td>\n",
              "      <td>78.0</td>\n",
              "      <td>1.009</td>\n",
              "      <td>55.5</td>\n",
              "      <td>8.958525</td>\n",
              "      <td>269.0</td>\n",
              "      <td>13.8</td>\n",
              "      <td>72.65</td>\n",
              "      <td>1002.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>150.5</td>\n",
              "      <td>37.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>610.0</td>\n",
              "      <td>74.8</td>\n",
              "      <td>606.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32779.0</td>\n",
              "      <td>0.297727</td>\n",
              "      <td>0.764129</td>\n",
              "      <td>-0.795565</td>\n",
              "      <td>0.136611</td>\n",
              "      <td>0.338586</td>\n",
              "      <td>0.258101</td>\n",
              "      <td>0.461119</td>\n",
              "      <td>-0.199550</td>\n",
              "      <td>-0.159668</td>\n",
              "      <td>-0.013619</td>\n",
              "      <td>-0.318710</td>\n",
              "      <td>-0.561159</td>\n",
              "      <td>0.275471</td>\n",
              "      <td>-0.868465</td>\n",
              "      <td>-0.381168</td>\n",
              "      <td>0.197238</td>\n",
              "      <td>-0.805438</td>\n",
              "      <td>0.215284</td>\n",
              "      <td>-0.492362</td>\n",
              "      <td>-0.644972</td>\n",
              "      <td>0.410759</td>\n",
              "      <td>-0.390505</td>\n",
              "      <td>0.617100</td>\n",
              "      <td>1.397771</td>\n",
              "      <td>-1.371298</td>\n",
              "      <td>-0.072344</td>\n",
              "      <td>-0.981251</td>\n",
              "      <td>0.457815</td>\n",
              "      <td>-0.734514</td>\n",
              "      <td>0.033783</td>\n",
              "      <td>1.371656</td>\n",
              "      <td>1.306443</td>\n",
              "      <td>-0.337575</td>\n",
              "      <td>0.030454</td>\n",
              "      <td>0.217532</td>\n",
              "      <td>-0.695523</td>\n",
              "      <td>-0.639070</td>\n",
              "      <td>-0.159521</td>\n",
              "      <td>1.796250</td>\n",
              "      <td>...</td>\n",
              "      <td>4.05</td>\n",
              "      <td>3.65</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.98</td>\n",
              "      <td>12.6</td>\n",
              "      <td>2.857143</td>\n",
              "      <td>1.0</td>\n",
              "      <td>109.125</td>\n",
              "      <td>2.5</td>\n",
              "      <td>52.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>40.5</td>\n",
              "      <td>78.0</td>\n",
              "      <td>1.009</td>\n",
              "      <td>55.5</td>\n",
              "      <td>8.958525</td>\n",
              "      <td>269.0</td>\n",
              "      <td>13.8</td>\n",
              "      <td>72.65</td>\n",
              "      <td>1002.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.9</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>150.5</td>\n",
              "      <td>37.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>610.0</td>\n",
              "      <td>74.8</td>\n",
              "      <td>606.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  877 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   SUBJECT_ID         1         2         3  ...  Bleeding Time  CD10  CD19.1  CD20\n",
              "0         3.0  0.089619  0.052252 -0.021826  ...          610.0  74.8   606.0   2.0\n",
              "1     32773.0  0.037900  1.280599 -1.198802  ...          610.0  74.8   606.0   2.0\n",
              "2     98310.0  0.024405  0.060916 -0.026240  ...          610.0  74.8   606.0   2.0\n",
              "3     32777.0 -0.058894  0.125515 -0.179003  ...          610.0  74.8   606.0   2.0\n",
              "4     32779.0  0.297727  0.764129 -0.795565  ...          610.0  74.8   606.0   2.0\n",
              "\n",
              "[5 rows x 877 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwW4iNLa9JUn"
      },
      "source": [
        "Let's create a csv from ```textNontextData```. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctbY7DF39N_c"
      },
      "source": [
        "textNontextData.to_csv(\"/content/drive/MyDrive/cbb 750 final/text_nontext_data.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPRlpqm0X07K"
      },
      "source": [
        "## From here we can start classifying our data. \n",
        "\n",
        "To reiterate from the beginning of the script, we'll be using the following classification approaches: \n",
        "\n",
        "* We classify using GLM [logistic regression], decision tree, SVM, random forest and majority vote\n",
        "  * We run GLM and decision tree with [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) to see if this will improve performance\n",
        "  * We run majority vote to see if a consensus approach will improve performance. We use all other classifiers for the vote, namely:\n",
        "    * GLM \n",
        "    * GLM with boosting\n",
        "    * Decision tree\n",
        "    * Decision tree with boosting\n",
        "    * SVM\n",
        "    * Random forest\n",
        "* We run k-fold cross validation [k=10] to more robustly assess classifier accuracy beyond counting misclassified points\n",
        "* We generate ROC curves/AUC for each classifier to provide another estimate of performance beyond accuracy \n",
        "* We check feature importance [when possible, not all models, like SVM with nonlinear kernel, allow] to better understand why our model performance is often not great "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ick1RkWCMKjx"
      },
      "source": [
        "### Splitting data into train/test\n",
        "\n",
        "First we need to split the dataset into train/test. \n",
        "\n",
        "We'll use the same train/test sets for each classifier to ensure that our results are comparable and keep the partition size [70-30 train-test] the same across classification tasks [if I changed the train/test split in each iteration, we can't tell if performance is increased/decreased because of the train/test split or the model]. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YquZ1dNRMNwX"
      },
      "source": [
        "# first split the dataset into train/test/split\n",
        "\n",
        "# this contains all the datasets/their associated labels, e.g. the label for dataset[0] is labels[0]\n",
        "# yes--if I were running this in a regular script I would loop over these instead of working on them one at a time\n",
        "datasets = [filledna_processed_nontext, textDataMat, textNontextData]\n",
        "labels = [nontext_labels, text_labels, text_nontext_labels]\n",
        "\n",
        "# split into train/test sets\n",
        "\n",
        "# select the task index, e.g. datasets[taskind] = \"textDataMat\" for taskind = 1\n",
        "# the three \"tasks\" would be non-text-based classification, text-based classification and text+non-text-based classification\n",
        "taskind = 2\n",
        "\n",
        "# run a train-test split\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(datasets[taskind],labels[taskind],train_size=0.7,random_state=3) #prev filledna_processed_nontext"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AR-s-sqgQyO"
      },
      "source": [
        "## Non-ensemble classification approaches\n",
        "\n",
        "We'll be running the following approaches: \n",
        "\n",
        "\n",
        "\n",
        "*   GLM [logistic regression]\n",
        "*   GLM with AdaBoost\n",
        "*   Decision tree\n",
        "*   Decision tree with AdaBoost\n",
        "*   SVM\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0sZpx54Yboc"
      },
      "source": [
        "### GLM classification\n",
        "\n",
        "We're going to just run logistic regression here since that's pretty standard for a GLM. For a deeper look into logistic regression for machine learning, [this](https://kambria.io/blog/logistic-regression-for-machine-learning/) site can help. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdkpFIQCJmhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b470886b-f915-43f9-cc6c-c9974186fa5b"
      },
      "source": [
        "# initialize the regression --random_state just makes these results reproducible\n",
        "# the 'ovr' parameter makes this into a binary classification problem\n",
        "# liblinear is supposedly \"a good choice for smaller datasets\" https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "# lbfgs runs way faster for adaboost than liblinear, possibly because it doesn't shuffle the data\n",
        "LR = LogisticRegression(random_state = 0, solver='lbfgs', multi_class='ovr')\n",
        "\n",
        "# predict the test data's labels\n",
        "LRPred = LR.fit(xtrain, ytrain).predict(xtest)\n",
        "\n",
        "# compute the numerical error\n",
        "numLRError = (LRPred != ytest).sum()\n",
        "\n",
        "# calculate the percent error--errors/(size of test set)*100\n",
        "LRError = float(numLRError/len(xtest))*100"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGUApH_RAQBA"
      },
      "source": [
        "What's the error rate [running outside the previous block for legibility]?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDIwPot9AW1S",
        "outputId": "0d586d46-2253-4b5e-c562-f8f8a352be40"
      },
      "source": [
        "# What's the error rate?\n",
        "print(\"Out of \"+str(len(xtest))+\" points the GLM produced \"+str(numLRError)+\" errors, resulting in an error rate of \" + str(LRError)+\"%.\")"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Out of 3471 points the GLM produced 404 errors, resulting in an error rate of 11.63929703255546%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f4-Eafi_LXm"
      },
      "source": [
        "#### K-fold cross validation for GLM\n",
        "\n",
        "We'll use this to provide a more robust estimation of our model's accuracy beyond counting the number of misclassified points in our test run above and to mitigate any biases introduced by the train-test split we chose for our data. \n",
        "\n",
        "We use 10 folds as that is fairly standard. Code adapted from [here](https://machinelearningmastery.com/repeated-k-fold-cross-validation-with-python/). Additionally, I think k-fold is a confusing concept to understand without graphics. There are some nice ones [here](https://towardsdatascience.com/why-and-how-to-cross-validate-a-model-d6424b45261f) that I used to get a better sense of how it works. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z35pV05D_PP_",
        "outputId": "a9012c7a-649b-48ee-a7d0-35ce7648091c"
      },
      "source": [
        "# prepare the cross-validation procedure\n",
        "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "\n",
        "# get the task and associated labels\n",
        "task = datasets[taskind]\n",
        "lab = labels[taskind]\n",
        "\n",
        "# evaluate model--n_jobs = -1 means to use all processors\n",
        "# see https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html \n",
        "LRscores = cross_val_score(LR, task, lab, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\n",
        "# report performance--we take the average accuracy over all folds. 1- just gives us the error rate\n",
        "print(\"The k-fold cross-validated error rate is \" + str((1-np.mean(LRscores))*100)+ \"%.\")"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The k-fold cross-validated error rate is 11.662417420066816%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJFfNkYMvnqL"
      },
      "source": [
        "#### ROC/AUC measurements for GLM\n",
        "This can provide us with a [more reliable estimate](https://datascience.stackexchange.com/questions/806/advantages-of-auc-vs-standard-accuracy) of model performance compared to accuracy. Code adapted from [here](https://stackoverflow.com/questions/25009284/how-to-plot-roc-curve-in-python). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "imW9amBItDCL",
        "outputId": "bc411612-f0ed-4252-c682-37d69021af85"
      },
      "source": [
        "# get false positive/true positive rates\n",
        "fpr, tpr, threshold = metrics.roc_curve(ytest, LRPred)\n",
        "\n",
        "# get roc/auc measurements\n",
        "glm_auc = roc_auc_score(ytest, LRPred)\n",
        "print('GLM ROC AUC=%.3f' % (glm_auc))\n",
        "\n",
        "# plot ROC/AUC\n",
        "plt.title('ROC for GLM')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % glm_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "\n",
        "# plot a dotted line for the threshold\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "\n",
        "# set axes limits and labels\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GLM ROC AUC=0.500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T96FrjRQmO_m"
      },
      "source": [
        "##### Feature importance for GLM\n",
        "\n",
        "To what degree did each column [feature] contribute to the final output? Let me check feature importance [code adapted from [here](https://machinelearningmastery.com/calculate-feature-importance-with-python/)]. \n",
        "\n",
        "In this case, the positive features are those that predict class 1 [CAD] whereas the negative ones predict feature 0 [CM]. Logistic regression feature importance plots are the only ones that look like this [the rest only have positive values]. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Ndp-5sofm4RR",
        "outputId": "bc8e0202-7061-4ce4-e853-7c0a2e74b32a"
      },
      "source": [
        "# get feature importance for GLM--i have to include the [0] because it's formatted as [[importance]]\n",
        "importance = LR.coef_[0]\n",
        " \n",
        "# visualize with bar plot\n",
        "plt.bar([x for x in range(len(importance))], importance)\n",
        "plt.title(\"Feature importance for GLM\")\n",
        "plt.xlabel(\"Feature\")\n",
        "plt.ylabel(\"Relative importance\")\n",
        "plt.show()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRddC74WO72A"
      },
      "source": [
        "### GLM with boosting\n",
        "\n",
        "We'll be using AdaBoost to potentially improve the performance of our GLM. We'll consider it to be a fairly weak classifier especially given the complexity of the data. The hope is that, by boosting, we'll be able to target points likely to have been misclassified by our non-boosting GLM and improve prediction accuracy. There's a nice description of AdaBoost [here](https://blog.paperspace.com/adaboost-optimizer/) as well as [here](https://codesachin.wordpress.com/tag/adaboost/). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoVXh41vO90C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5bcc5fa-a4c9-4732-9d92-d76870f84576"
      },
      "source": [
        "# set up the booster on the GLM classifier you previously made\n",
        "LRAda = AdaBoostClassifier(LR)\n",
        "\n",
        "# train the booster\n",
        "LRAdaPred = LRAda.fit(xtrain, ytrain).predict(xtest)\n",
        "\n",
        "# calculate the percent error--errors/(size of test set)*100\n",
        "LRAdaerror = float(((LRAdaPred != ytest).sum())/len(xtest))*100"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRD1n-Z9QxEb"
      },
      "source": [
        "What was our error rate? [I'm printing this outside the previous code block because of all the \"failed to converge\" warnings]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WSWTPnQQDGu",
        "outputId": "f8a4317a-2be3-4395-bbe7-b3e4b1c60366"
      },
      "source": [
        "print(\"With AdaBoost, we get an GLM error rate of {}%.\".format(LRAdaerror))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With AdaBoost, we get an GLM error rate of 11.81215787957361%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJvG8cb_A52T"
      },
      "source": [
        "#### K-fold cross validation for GLM with boosting\n",
        "\n",
        "This code is nearly identical to our previous k-fold runs. Yes -- one way to avoid this redundancy would have been to loop over the model names -- so in this case instead of hard-coding ```LRAda``` in ```cross_val_score(LRAda, model, lab, scoring='accuracy', cv=cv, n_jobs=-1)``` we could generate scores for each classifier and print them out next to their associated model name. \n",
        "\n",
        "One benefit of this approach is that a loop would rely on us having run each model beforehand, whereas here we can run each model to completion mostly independent of the others. This is helpful to save on runtime--of course boosting/majority vote rely on running other models, but if I just wanted to run the GLM and gather all its performance metrics I can do so here. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sybQxpUnA8jT",
        "outputId": "f8543c58-cfb2-442e-89c8-4cba66088aa2"
      },
      "source": [
        "# prepare the cross-validation procedure\n",
        "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "\n",
        "# get the task and associated labels\n",
        "task = datasets[taskind]\n",
        "lab = labels[taskind]\n",
        "\n",
        "# evaluate model--n_jobs = -1 means to use all processors\n",
        "# see https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html \n",
        "LRAdascores = cross_val_score(LRAda, task, lab, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\n",
        "# report performance--we take the average accuracy over all folds. 1- just gives us the error rate\n",
        "print(\"The k-fold cross-validated error rate is \" + str((1-np.mean(LRAdascores))*100)+ \"%.\")"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The k-fold cross-validated error rate is 11.86990277325023%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7daW7W0Xv0Dh"
      },
      "source": [
        "#### ROC/AUC measurements for GLM with boosting\n",
        "\n",
        "Same code as previously. Again we could've looped over each trained model to avoid this redundancy, e.g. loop over ```LRAdaPred``` in ```metrics.roc_curve(ytest, LRAdaPred)``` and ```roc_auc_score(ytest, LRAdaPred)```. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "C8rK94YkuBSS",
        "outputId": "460e3540-12d2-41a5-e4e4-09b6c5162bdc"
      },
      "source": [
        "# get false positive/true positive rates\n",
        "fpr, tpr, threshold = metrics.roc_curve(ytest, LRAdaPred)\n",
        "\n",
        "# get roc/auc measurements\n",
        "glm_ada_auc = roc_auc_score(ytest, LRAdaPred)\n",
        "print('GLM with adaboost ROC AUC=%.3f' % (glm_ada_auc))\n",
        "\n",
        "# plot ROC/AUC\n",
        "plt.title('ROC for GLM with boosting')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % glm_ada_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "\n",
        "# plot a dotted line for the threshold\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "\n",
        "# set axes limits and labels\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GLM with adaboost ROC AUC=0.504\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ml8h6m4wmTXc"
      },
      "source": [
        "##### Feature importance for GLM with boosting\n",
        "\n",
        "We have not found a way to get this to work. Feature importance can be calculated for AdaBoost with a decision tree but we could not find an attribute of this classifier that displayed feature importance for us. The parameter we used to calculate feature importance for the GLM [```coef_```] is not present in the AdaBoostClassifier model type and the feature importance parameter it does have [```feature_importances_```] is not present in LogisticRegression model types. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xqT95gRWiop"
      },
      "source": [
        "### Decision tree classification\n",
        "\n",
        "This is a common approach used for binary classification so we'll try it out. Now, effective classification here is contingent on our model being able to identify high-quality rules it can use to split/classify our data. For a nice graphical description of decision trees in machine learning, I found [this](https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052) site to be useful. \n",
        "\n",
        "You'll note that this code block looks very similar to the GLM code block. That will be the case for all non-boosting classifiers with the exception of majority vote [additionally the boosting code blocks looks nearly identical to one another]. As a result we won't be commenting too much on each individual code block. In terms of setup/implementation, they are all slightly different variations of the same general theme. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHf-QmMEWlts",
        "outputId": "a85f373c-8f24-4bbc-eaf1-5f8f42994973"
      },
      "source": [
        "# set up your decision tree \n",
        "dectree = tree.DecisionTreeClassifier()\n",
        "\n",
        "# predict the test data's labels\n",
        "decpred = dectree.fit(xtrain, ytrain).predict(xtest)\n",
        "\n",
        "# compute the error\n",
        "# number of errors\n",
        "numDecError = (decpred != ytest).sum()\n",
        "\n",
        "# calculate the percent error--errors/(size of test set)*100\n",
        "decerror = float(numDecError/len(xtest))*100\n",
        "\n",
        "# How many errors did we get?\n",
        "print(\"Out of \"+str(len(xtest))+\" points, the decision tree produced \"+str(numDecError)+\" errors, resulting in an error rate of \" + str(decerror)+\"%.\")"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Out of 3471 points, the decision tree produced 642 errors, resulting in an error rate of 18.49611063094209%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gE7qSUC1BiBJ"
      },
      "source": [
        "#### K-fold cross validation for decision tree\n",
        "\n",
        "This code is nearly identical to our previous k-fold runs. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iE10ykfBkc8",
        "outputId": "26252e4e-5bb8-4184-bc53-122f5f31d64d"
      },
      "source": [
        "# prepare the cross-validation procedure\n",
        "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "\n",
        "# get the task and associated labels\n",
        "task = datasets[taskind]\n",
        "lab = labels[taskind]\n",
        "\n",
        "# evaluate model--n_jobs = -1 means to use all processors\n",
        "# see https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html \n",
        "decTreeScores = cross_val_score(dectree, task, lab, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\n",
        "# report performance--we take the average accuracy over all folds. 1- just gives us the error rate\n",
        "print(\"The k-fold cross-validated error rate is \" + str((1-np.mean(decTreeScores))*100)+ \"%.\")"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The k-fold cross-validated error rate is 17.947598938909547%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mpsOggQnjzP"
      },
      "source": [
        "#### ROC/AUC measurements for decision tree\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "9DWQvDxknjHf",
        "outputId": "f7bcb8d6-0d2b-4f6e-d79a-aa638ab2a6a3"
      },
      "source": [
        "# get false positive/true positive rates\n",
        "fpr, tpr, threshold = metrics.roc_curve(ytest, decpred)\n",
        "\n",
        "# get roc/auc measurements\n",
        "dectree_auc = roc_auc_score(ytest, decpred)\n",
        "print('Decision tree ROC AUC=%.3f' % (dectree_auc))\n",
        "\n",
        "# plot ROC/AUC\n",
        "plt.title('ROC for decision tree')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % dectree_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "\n",
        "# plot a dotted line for the threshold\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "\n",
        "# set axes limits and labels\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decision tree ROC AUC=0.572\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZzVcxfA8c8pqbShsrWQvSKpIWRfUkQoyV4iW8STHutje5AU4VFUImskpGixlZTSrr0kqmnRntI6zXn+OL/RNWa5M3N/996ZOe/Xa15zl9/9/c69Mud+t/MVVcU555zLTolEB+Cccy65eaJwzjmXI08UzjnncuSJwjnnXI48UTjnnMuRJwrnnHM58kThigwRaSwiP4vIFhG5LITztxWRcQU8R80gvpK5HHetiHxZkGs5FyueKFzMichvIrIt+IO4SkQGiEj5TMecJiLfishmEdkkIsNEpE6mYyqKyIsisjQ41y/B/SrZXPpJ4BVVLa+qQ8J6fwWhqkuD+Hbnctx7qtok1tcXkbNFJDXW53VFmycKF5ZLVLU8UB84EXgw4wkRORX4EvgMOASoBfwEjBeRw4Nj9ga+AeoCTYGKwKnAOuDkbK55KDAnP8GKyF75eV1R5J+Fy8wThQuVqq4CRmEJI8NzwNuq+pKqblbV9ar6CDAReDw45gagJnC5qs5V1XRVXa2q/1XV4ZmvIyK/AIcDw4LWR2kROUREhorIehFZJCK3RBz/uIgMFpF3ReQPoG0W56wcvP4PEZkEHJHp+WNF5Kvg/AtEpHXEc2VF5HkRWRK0mMYFjx0mIprxxzjozloctKx+FZFrIx4fF3G+00RkcnCuySJyWsRzY0TkvyIyPjjPl1m1ukSkHDACOCT4jLYEn9E/PgsRqSQi/UVkpYgsF5GnIrvLROQmEZknIhtEZJSIHJr5eq7o8EThQiUi1YFmwKLg/j7AacBHWRw+CLgguH0+MFJVt0RzHVU9AlhK0JJR1R3AB0Aq1mppBTwjIudGvKwFMBjYF3gvi9P2ArYDBwM3BT8Z76sc8BXwPnAA0AboHdF91gNoGLzX/YF/A+mRJw/O8TLQTFUrBMfOyByEiOwPfBEcWxl4AfhCRCpHHHYN0C6IZW/gviw+oz+x/xYrgs+ovKquyOazGACkAUdiLcImwM1BPC2Ah4ArgKrA98DALD4/V0R4onBhGSIim4FlwGrgseDx/bF/dyuzeM1KIOObcOVsjomKiNQAGgP3q+p2VZ0BvI61VDJMUNUhQWtlW6bXlwRaAo+q6p+qOht4K+KQ5sBvqvqmqqap6nTgY+BKESmBJZVOqrpcVXer6g9B8sosHThORMqq6kpVzarr7GLgZ1V9J7jWQGA+cEnEMW+q6sLgfQzi7y24aPz1WWDdfBcB9wTvfTXQE0uGALcBXVV1nqqmAc8A9b1VUXR5onBhuSz4lnw2cCx7EsAG7I/jwVm85mBgbXB7XTbHROsQYL2qbo54bAlQLeL+shxeXxXYK9MxSyJuHwo0EpGNGT/AtcBB2HstA/ySU4DBN/yrsD+8K0XkCxE5Npv3siTTY5nfy6qI21uB8uRN5Ps8FCgVxJTx3vpgrZWM51+KeG49IJnicUWIJwoXKlX9DuvG6BHc/xOYAFyZxeGtsQFsgK+BC4PumfxYAewvIhUiHqsJLI8ML4fXr8G6Xmpken2GZcB3qrpvxE95Vb0dS3bbyTSmkRVVHaWqF2BJcT7QL5v3kvnbeub3Eq3s3nPk48uAHUCViPdWUVXrRjx/a6b3XlZVf8hHPK4Q8ETh4uFF4AIROSG4/wBwo4jcLSIVRGQ/EXkKm9X0RHDMO9gfpI+DQeMSweDyQyJyUW4XVNVlwA9AVxEpIyL1gPbAu9EEHExf/QR4XET2CcYebow45HPgaBG5XkRKBT8niUjtoPvmDeCFYLC4pIicKiKlI68hIgeKSIsgGe4AtpBpHCMwPLjWNSKyl4hcBdQJYsir34HKIlIph/e+EpuV9rzYFOUSInKEiJwVHPIa8KCI1A3eRyURySrxuyLCE4ULnaquAd4GHg3ujwMuxAZDV2LdKCcCp6vqz8ExO7AB7fnYoPEfwCSsW+fHKC99NXAY9o38U+AxVf06D6F3xLpwVmGtojcj3tNmbIC3TXD+VUA3ICMZ3AfMAiZjXTPd+Of/byWAfwWvXw+cBdyeOQhVXYeNiXTGuuT+DTRX1bWZj82Nqs7HBp4XB11Hh2Rz6A3YoPhcrLtwMEFXoKp+GryfD4JZUrOxQXJXRIlvXOSccy4n3qJwzjmXo9AShYi8ISKrRWR2Ns+LiLwsthBqpog0CCsW55xz+Rdmi2IAVnohO82Ao4KfDsCrIcbinHMun0JLFKo6Fhugy04LrIyDqupEYF8RKci8eeeccyFIZPGvavx9kU9q8Ng/VuOKSAes1UG5cuUaHntsVmuSnHPOAWzbBps22U/lLUuoxEZmkrZWVavm53yFokqkqvYF+gKkpKTolClTEhyRc84ljw0b4OuvYcQIGDkSVq602awnnCA8fuCr1D9kNbUGPJ55dX/UEpkolvP3Va/Vyd9KU+ecK1bS02H69D2JYcIEe2zffeGq05fzUOrtVGh/Fft1vJa/luYMeDzf10tkohgKdBSRD4BGwKZgRahzzrlM1q6FL7+0xDBqFKxebY83bAgPPQTNmiqNZr1Oyfvvg127oNTFMbt2aIlCRAZiBeGqiO2o9RhWaAxVfQ0rS3ARVn56K1Yi2TnnHLB7N0yebIlhxAi7rQqVK8OFF0LTpvb7gAOAX36BW26B0aPhnHOgXz84ItdSY1ELLVGo6tW5PK/AnWFd3znnCpvff7fWwogR1npYvx5EoFEjeOwxaNbMWhAlM++4PmsWTJ0KffvCzTfbi2KoUAxmO+dcUZSWBhMn7mk1TJtmjx9wADRvbonhggusFfEPs2fbC264AS67DBYvzubAgvNE4ZxzcbR8+Z5Ww1df2RTWkiXh1FPh6aetS6l+fSiR3Sq3nTvhmWfs58ADoXVrKFMmtCQBniiccy5UO3fCDz/smaE0c6Y9fsgh0KqVJYbzz7cZS7n68Udo3x7mzIHrroOePS1JhMwThXPOxdjSpXsSwzffwObNsNdecPrp0K2bdSkdd1wehxKWL4czzrBWxOefw8Wxm9WUG08UzjlXQDt2wNixe8Ya5s2zx2vWhGuusVbDeedBhQo5nydLCxfC0UdDtWrw4Yd2oooVYxp/bjxROOdcPixevKfV8O23sHUr7L03nHWWTTxq1gyOPbYAE5A2boR//xtefx3GjIEzz4TLL4/lW4iaJwrnnIvCtm329zqj1fDzz/b44YdDu3aWGM4+G8rld5f3SEOHwu23w6pV0KULnHRSDE6af54onHMuC6rW65ORGL77DrZvt7Hjc86Bu+6yLqWjjorxhW++Gfr3h+OPh88+g5SUGF8g7zxROOdcYMsWW9yc0aX066/2+DHHwG23WWI480woWzbGF87YklrEEsOhh8L991tfVhLwROGcK7ZUYe7cPYnh++9tOmu5cjZm3KWLJYdatUIMYtkyy0Jt2sD119vtJOOJwjlXrPzxh01ZzUgOy4JdcerWhbvvtrGGxo2hdOmQA0lPhz59rOWwe3fCBqqj4YnCOVekqdoit4zEMH68lc6oWNEWuv3nP9ZqqFEj93PFzM8/21jE2LEWRN++ITdbCsYThXOuyNmwwcpjjByZsZGPPV6/Ptx3n7UaTj0VSpVKUIBz51r2euMNaNs25kX8Ys0ThXOu0EtPt/p4GTOUJk7cs5FPkyaWGC68EA4+OIFB/vQTzJgBN94ILVrYQoz99ktgQNHzROGcK5QyNvIZMcKK7K1ZY4+npMDDD1t30sknW+mMhNqxA556Cp591jLVVVfZHNtCkiTAE4VzrpDI2MgnY6whYyOfKlX2bOTTpEmwkU+ymDDBivjNm2flwF94IS5F/GLNE4VzLmlltZFPiRLWUnj8cetSatAgi418ksHy5VbP46CDYPhwC7aQ8kThnEsaGRv5ZLQaMjbyOfBAuOQSazVku5FPspg3D2rXtiJ+gwYVoBpg8vBE4ZxLCr/+CldeaTt6liwJp51mG/k0awYnnJDDRj7JYsMG6NwZ3nzTpr2ecYbtPFcEeKJwziXciBFw7bU2U+nNN+3va1Qb+SSLTz+FO+6wEfUHH0x4Eb9YS/Yc7Zwrwnbvhscesz14ata01kTbtoUsSdx0E1xxhY1FTJpkW5QWwgHrnHiLwjmXEGvX2m6eo0ZZcujdO4Rie2GJLOJ3yilWQva++xK4gi9cniicc3E3ebLtF71qlVWvuPnmpF+cvMeSJXDrrbZ13Q03QIcOiY4odN715JyLG1Wrg3f66ZYYxo+HW24pJEkiPR169bLNrseNg127Eh1R3HiicM7Fxdat1sV022228c/UqUmxJ090FiywNREdO9p0rNmzbSFdMeGJwjkXukWLrAjfO+/YQrkvvkjytRCZLVgAc+bAgAG2wOOwwxIdUVz5GIVzLlRDh1pXfsmStkC5adNERxSl6dOtiF+7dnDppVbEr1BNx4odb1E450KRlgYPPWSFUo880rqaCkWS2L7dAj/pJGv+bN9ujxfTJAGeKJxzIVi92gr1de1qk4LGjSskvTXjx9umFV27WjNoxowityYiP7zryTkXUxMn2tTXdetslXXbtomOKErLl9soe7VqtrijSZNER5Q0vEXhnIsJVXjlFTjzTNtvesKEQpIk5s6139Wqwccfw6xZniQy8UThnCuwP/+0VdZ33WVdTlOmWA9OUlu/3jJZ3bpWxA+sRG358gkNKxl515NzrkAWLrRSR/PmWbXXBx4oBJVeP/4Y7rzT+sceftg2uHDZ8kThnMu3Tz6xL+WlS1u3/vnnJzqiKLRtC2+9ZTsejRxZCJo+ieeJwjmXZ2lpVk27Rw/7Mj54MNSokeiochBZxO+002xjoc6dk2BD7cIh1AaiiDQVkQUiskhEHsji+ZoiMlpEpovITBG5KMx4nHMFt2qVbdrWo4dtwTB2bJIniV9/tcHpt9+2+x06wP33e5LIg9AShYiUBHoBzYA6wNUiUifTYY8Ag1T1RKAN0DuseJxzBTdunPXYTJ5s5Th69bJup6S0eze8/LIV8Zs4cU+rwuVZmC2Kk4FFqrpYVXcCHwAtMh2jQMXgdiVgRYjxOOfySRV69oSzz4Zy5eDHH22WU9KaN8+2Iu3UyYr5zZlTSObqJqcw217VgGUR91OBRpmOeRz4UkTuAsoBWQ6FiUgHoANAzZo1Yx6ocy57mzdbodSPPrItSgcMgEqVEh1VLhYtskJ+77xje6wWijrmySvRk9iuBgaoanXgIuAdEflHTKraV1VTVDWlatWqcQ/SueJq7lwbrP74Y3juOZvllLRJYupUeOMNu33JJTY2cd11niRiIMxEsRyIHOKqHjwWqT0wCEBVJwBlgCohxuSci9KHH1qSWL8evvkGunRJ0r+527bZ4o1GjeC//91TxK9ixZxf56IWZqKYDBwlIrVEZG9ssHpopmOWAucBiEhtLFGsCTEm51wudu6Ee+6BNm1sicH06TY2kZTGjoUTToBu3WwMYvp0L+IXgtDGKFQ1TUQ6AqOAksAbqjpHRJ4EpqjqUKAz0E9E7sUGttuq+tQE5xJl+XJo3Rp++MGSxXPPQalSiY4qG8uX2zzdGjXg66/ttguFFLa/yykpKTplypREh+FckTN6tLUi/vwT+veHq65KdETZmDULjj/ebn/+uVV8LVcusTEVAiIyVVXztflsogeznXMJpmoth/PPh/33h0mTkjRJrF0L118P9ertKeLXvLkniTjwpYnOFWObNlnX/pAhcOWV1pKoUCHRUWWianNzO3aEDRvgscds4NrFjScK54qpWbOgZUubRdqzp61NS8pZTTfeaOshUlJs+lVGt5OLG08UzhVD775rJY/23dfGJk4/PdERZRJZxO+ss6y76Z57vD5TgvgYhXPFyI4dtg3D9dfbGolp05IwSSxebAMmAwbY/fbt4b77PEkkkCcK54qJZcvsy3nv3vZ39+uv4aCDEh1VhN274cUXrWtp8uRCsPtR8eEp2rli4Ouv4eqrrUXx8ce2I11SmTsXbrrJqg1efDG89hpUr57oqFzAU7ZzRVh6um1P2qQJHHigfVFPuiQBNqL+yy/w/vswbJgniSTjLQrniqgNG+CGG2xN2jXXQN++SbbkYPJkmDEDbrnFWhGLFyfh3FwH3qJwrkiaPh0aNrR9rP/3P5vllDRJYutWGyQ55RTo2nVPET9PEknLE4VzRcybb9q20Dt3wnff2Tq1pFkfMWaMTXV9/nlrSXgRv0LBE4VzRcT27bY24qaboHFj+xt86qmJjipCaipccIHd/vZbG7BO2s0tXCRPFM4VAb/9Zush+vWDhx6yLqek2ePrp5/sd/Xq8NlnMHOmFfJzhYYnCucKuREjoEED2/3zs89sllPJkomOClizxkbR69e3PjCAiy6CffZJbFwuzzxROFdIpafD44/bhKGaNW0n0EsvTXRUWPmNgQOhTh0YPBieeCLJ+sBcXvn0WOcKoXXrbDvokSOtZl7v3kn0Rf366+G996zCa//+ULduoiNyBRR1ohCRfVR1a5jBOOdyN2UKtGoFK1dCnz42eSjhs5rS0y0IERt/aNgQ7r47SfrAXEHl2vUkIqeJyFxgfnD/BBHpHXpkzrm/UbVFc40b2+1x42yWU8KTxKJFtg3pm2/a/fbt4d57PUkUIdGMUfQELgTWAajqT8CZYQblnPu7bdts2uutt9oX9mnT4KSTEhxUWhr06GFF/KZPh733TnBALixRdT2p6jL5+9eW3eGE45zL7JdfbIOhn36CRx+1n4R/WZ89G9q1s36wFi1skOSQQxIclAtLNIlimYicBqiIlAI6AfPCDcs5B1Yf7/rrreL2F1/Y7NKksHQpLFkCH3wArVsnQf+XC1M0XU+3AXcC1YDlQH3gjjCDcq64270bHn7YprsecYRNfU14kvjxRxskAQtm8WK46ipPEsVANIniGFW9VlUPVNUDVPU6oHbYgTlXXK1ZAxdeCM88AzffDOPHQ61aCQzozz/hX/+ytRDPPWebWgCUL5/AoFw8RZMo/hflY865Apo40VZZjxtnSxD69Utwzbxvv7Uifj17wm232Sh66dIJDMglQrZjFCJyKnAaUFVE/hXxVEUg0UNpzhUpqjYefO+9VhJpwgQ48cQEB5Waak2bWrWsBMeZPtmxuMqpRbE3UB5LJhUifv4AWoUfmnPFw59/2oB1x462E93UqQlOEtOn2+/q1W00/aefPEkUc9m2KFT1O+A7ERmgqkviGJNzxcbChTb1dc4ceOopePBBm+GUEL//bqupBw2yfSPOOguaNk1QMC6ZRDM9dquIdAfqAn/1lqrquaFF5Vwx8Mkn0LatrVMbNWrPVg1xp2q1mTp1gi1bLGOddlqCgnHJKJrvLu9h5TtqAU8AvwGTQ4zJuSItLQ3+/W9rSdSubePDCUsSYKXAr78ejjnG9rB++GEoVSqBAblkE02LorKq9heRThHdUZ4onMuHVaugTRsbG779dptMlJBJRJFF/Jo0samvd96ZBEu+XTKKJlHsCn6vFJGLgRXA/uGF5FzRNH48XHklbNwIb79tX+ITYuFCKzl7ww1WwK9duwQF4gqLaLqenhKRSkBn4D7gdeCeUKNyrghRhRdfhLPPhnLlbK1EQpJEWpotmDvhBNuOtGzZBAThCqNcWxSq+nlwcxNwDoCINA4zKOeKis2bbXX1oEFw2WUwYABUqpSAQGbOtPKzU6fC5ZdDr15w8MEJCMQVRjktuCsJtMZqPI1U1dki0hx4CCgLJHo5kHNJbd48G7BesAC6dYMuXRJYFik1FZYtg48+sqC8PpPLg5xaFP2BGsAk4GURWQGkAA+o6pBoTi4iTYGXsJXcr6vqs1kc0xp4HFDgJ1W9Jk/vwLkkNGiQdf/vsw98/bXtIRF3P/xgLYnbbttTxK9cuQQE4gq7nBJFClBPVdNFpAywCjhCVddFc+KgRdILuABIBSaLyFBVnRtxzFHAg0BjVd0gIgfk9404lwx27bKpry++aBOJPvoIqlWLcxBbttgU1//9z0rPtmtnU6s8Sbh8ymkwe6eqpgOo6nZgcbRJInAysEhVF6vqTuADoEWmY24BeqnqhuA6q/NwfueSyooV1nJ48UVb4DxmTAKSxJdfwnHHWZK4804v4udiIqcWxbEiMjO4LcARwX0BVFXr5XLuasCyiPupQKNMxxwNICLjse6px1V1ZOYTiUgHoANAzZo1c7msc/H33Xe2NcOWLTBwoK2ViLtly+Dii60VMXYsnH56AoJwRVFOiSIee07sBRwFnA1UB8aKyPGqujHyIFXtC/QFSElJ0TjE5VxUVG3b6AcfhCOPhG++gbp14xzE1KnQsCHUqAHDh8MZZyS4NrkrarLtelLVJTn9RHHu5dhgeIbqwWORUoGhqrpLVX8FFmKJw7mkt2mTTSD6979txunkyXFOEqtW2Qq+lBRr0oDVAvEk4WIszDqVk4GjRKSWiOwNtAGGZjpmCNaaQESqYF1Ri0OMybmYmD0bTjoJhg6FF16wWU4VKsTp4qrw1ltQp46VAX/mGS/i50IVTQmPfFHVNBHpCIzCxh/eUNU5IvIkMEVVhwbPNRGRucBuoEseB8ydi7v33oMOHaBiRRg92np64qpNG8tMjRvD66/DscfGOQBX3Ihq7l3+IlIWqKmqC8IPKWcpKSk6ZcqURIfhiqGdO23r6F69bB+fDz+Egw6K08Uji/i99ZYt+b7jjgRuXuEKGxGZqqop+Xltrv/KROQSYAYwMrhfX0QydyE5V6QtW2bJoVcvuO8+W0QXtyQxf75dvH9/u3/jjbYdnicJFyfR/Et7HFsTsRFAVWdge1M4Vyx88w00aABz58LgwdC9e5y2a9i1y8YfTjjBLl6+fBwu6tw/RZModqnqpkyP+RRVV+Slp9vf6SZN4IADbFZTy5ZxuviMGXDyybbC+tJLLVEkZHGGc9ENZs8RkWuAkkHJjbuBH8INy7nE2rjRtmsYNgyuvhr69o3zF/pVq+zn44/hiivieGHn/imaFsVd2H7ZO4D3sXLjvh+FK7JmzLD1ayNGWCWM996LU5IYNw5697bbTZvCL794knBJIZpEcayqPqyqJwU/jwS1n5wrct56y4r57dhhVTA6doxDRe7Nm+1CZ5xhhaJ27LDH99kn5As7F51oEsXzIjJPRP4rIseFHpFzCbB9O9x6K7Rta4li2jT7HbpRo6yIX+/e0KmTF/FzSSnXRKGq52A7260B+ojILBF5JPTInIuTJUvsy3zfvvDAA1aA9YB4FLxftgyaN7eWw7hx1prwmU0uCUU1EVtVV6nqy8Bt2JqKR0ONyrk4GTXKpr4uXAhDhkDXrrBXaPUKsPIbkybZ7Ro1bCBk+nQvweGSWjQL7mqLyOMiMgv4HzbjqXrokTkXovR0eOIJaNYMqle3AqwtMu+WEmsrV9r82kaN9hTxO/98L+Lnkl40353eAD4ELlTVFSHH41zo1q2D666DkSNtCuyrr4Y8bqwKAwZY/Y/t220D7caNQ7ygc7GVa6JQ1XgM6TkXF1On2pf6lSvhtdesuF/os5pat7Yl3WecYUX8jj465As6F1vZJgoRGaSqrYMup8iV2NHucOdc0lC1v9EdO1qNpnHjrEx4aHbvtgxUogRccgmce65Nq/L6TK4QyqlF0Sn43TwegTgXlm3bbPvoN9+0chzvvQdVqoR4wXnzoH17aNcObrnF+recK8Ry2uFuZXDzjix2t7sjPuE5VzCLF9uEojffhEcftZ1CQ0sSu3bBU09B/fqwYAFUqhTShZyLr2jawRdk8VizWAfiXKx9/rmV4liyBL74wmY5lSwZ0sWmT7ctSf/zH9sXdd48G5twrgjIaYzidqzlcLiIzIx4qgIwPuzAnMuv3bvhscfg6afhxBOtrl6tsAvj//47rF1rizFCn2frXHzlNEbxPjAC6Ao8EPH4ZlVdH2pUzuXTmjVwzTW2sVD79vDKKyEuUxg7FmbNsgGQpk1h0SIoWzakizmXODl1Pamq/gbcCWyO+EFE9g8/NOfy5scfravp++9thtPrr4eUJP74w7YhPessePnlPUX8PEm4IiqnRPF+8HsqMCX4PTXivnNJQdVq6p1xho1B/PCDtSZCMXw41K0LffrYAjov4ueKgWy7nlS1efDbtz11SWvrVlue8O67cNFF8M47sH9Y7d1ly2z84ZhjbAFdo0YhXci55BJNrafGIlIuuH2diLwgIjXDD825nP38M5xyiq2LePJJ240u5klCFSZOtNs1alhp2WnTPEm4YiWa6bGvAltF5ASgM/AL8E6oUTmXiyFDbDbqihVWs+k//wlh0fOKFXDZZbYxRUYRv3POgb33jvGFnEtu0fyvlaaqCrQAXlHVXtgUWefiLi0N7r/fliocc4zVbmrSJMYXyaj3UaeOtSB69PAifq5Yi6Z67GYReRC4HjhDREoApcINy7l/+v13aNMGxoyB22+Hnj1DGkdu1Qo++cRmNb3+Ohx5ZAgXca7wiCZRXAVcA9ykqquC8Ynu4Ybl3N+NHw9XXgkbN8Lbb8P118f4ApFF/C67zJopt9ziRfycI7qtUFcB7wGVRKQ5sF1V3w49MuewXqCXXoKzz4Zy5WxcOeZJYvZs61rq39/uX3+9V3p1LkI0s55aA5OAK4HWwI8i0irswJzbsgWuvhruuQcuvhgmT4Z6sSxuv3OnFYBq0AB++QX22y+GJ3eu6Iim6+lh4CRVXQ0gIlWBr4HBYQbmirf58+GKK6wI67PPQpcuMf6CP3UqtG1rrYlrroEXX4SqVWN4AeeKjmgSRYmMJBFYR3SzpZzLl48+gptusooYX31le/7E3Lp1NuAxbBg09y1XnMtJNIlipIiMAgYG968ChocXkiuudu2yqa89e9rShY8+gmrVYniB0aOtiN/dd9tg9c8/h1gx0LmiI5rB7C5AH6Be8NNXVe8POzBXvKxcaS2Hnj3hrrtsCmzMksSmTTY4fe658Oqre4r4eZJwLio57UdxFNADOAKYBdynqsvjFZgrPiSnqwoAABznSURBVMaOtT1+Nm+G99+3AeyYGTYMbrsNVq2C++6zwWsv4udcnuTUongD+BxoiVWM/V9cInLFhqotej73XNs1dNKkGCeJZcugZUuoXNnm1XbvDvvsE8MLOFc85DRGUUFV+wW3F4jItHgE5IqHP/6wAeuPP7a/5W+8ARUrxuDEqjBhgm2UnVHE77TTvD6TcwWQU4uijIicKCINRKQBUDbT/VyJSFMRWSAii0TkgRyOaykiKiIpeX0DrvCZMwdOOskK+/XoYYPWMUkSqalw6aW2eC6jiN/ZZ3uScK6AcmpRrAReiLi/KuK+AjlOWhSRkkAv4AIgFZgsIkNVdW6m4yoAnYAf8xa6K4wGDoSbb7bE8O23cOaZMThpejr062eLLdLS4IUX4PTTY3Bi5xzkvHHROQU898nAIlVdDCAiH2AVaOdmOu6/QDegSwGv55LYzp3QubPtYX366TBoEBx8cIxO3rKlNU/OPdcSxuGHx+jEzjkId+FcNWBZxP3U4LG/BF1YNVT1i5xOJCIdRGSKiExZs2ZN7CN1oUpNtR6gV16xZPHttzFIEmlp1pIASxT9+sHXX3uScC4ECVthHZQrfwHbDClHqtpXVVNUNaWql1koVL75xkopzZplYxE9ekCpghapnznTVuT1C+ZaXHed9WeJFDhe59w/hZkolgM1Iu5XDx7LUAE4DhgjIr8BpwBDfUC7aEhPh65dbQF01aowZYpt81AgO3bAY49Bw4awZInXZnIuTnIt4SEiAlwLHK6qTwb7URykqpNyeelk4CgRqYUliDbYvhYAqOomoErEdcZgi/qm5PlduKSycSPceCMMHWobDfXrB+XLF/CkkydbEb+5c60MeM+etj7CORe6aFoUvYFTgYylUJux2Uw5UtU0oCMwCpgHDFLVOSLypIhcms94XZL76Sfby3r4cHj5ZVtpXeAkAbBhg9UdHz7cdi7yJOFc3ERTFLCRqjYQkekAqrpBRKKamK6qw8lUQFBVH83m2LOjOadLXm+9ZdUy9t/fljGcdloBT/jttza40amT9WEtXOjlN5xLgGhaFLuCNREKf+1HkR5qVK5Q2bHDEkTbtjbGPH16AZPExo22Del550GfPnuK+HmScC4hokkULwOfAgeIyNPAOOCZUKNyhcaSJbYuok8fKxH+5ZdwwAEFOOFnn0GdOlbT49//tg2GPEE4l1C5dj2p6nsiMhU4DxDgMlWdF3pkLumNGmWbw6WlwaefwmWXFfCES5fClVdC7do2Ep7iE+CcSwbR7JldE9gKDAOGAn8Gj7liKj0dnnwSmjWzPSOmTClAklCF77+32zVr2qK5yZM9STiXRKIZzP4CG58QoAxQC1gA1A0xLpek1q+39W0jRtgs1ddeK0Dl7qVLbXBjxAjbqeiss2JU/Mk5F0vRdD0dH3k/KLtxR2gRuaQ1bZpVy1i+HHr3tr/x+VoMnZ5uGeb++61F8fLLXsTPuSQWTYvib1R1mog0CiMYl7z694c777SB6nHj4OSTC3CyK66wQesLLoC+feGww2IVpnMuBNGszP5XxN0SQANgRWgRuaSybRt07GiTkC64wBbQVamS++v+IS0NSpSwn6uughYtbD6t12dyLulFMz22QsRPaWzMokWYQbnksHix7QH0xhvwyCM2lJCvJPHTT9CokbUewPY7bdfOk4RzhUSOLYpgoV0FVb0vTvG4JPHFFzZoDfD553Dxxfk4yfbt8NRT0K2bLdc+6KCYxuici49sWxQispeq7gYaxzEel2C7d8Ojj0Lz5lCrlg1g5ytJTJoEJ54ITz8N114L8+bFYKGFcy4RcmpRTMLGI2aIyFDgI+DPjCdV9ZOQY3NxtnatLaD76iu46SbbaKhs2Xye7I8/bIBj5Ei48MKYxumci69oZj2VAdZhe2RnrKdQwBNFETJpku0XsXo1vP46tG+fj5N8+SXMmQP33gvnnw8LFnj5DeeKgJwGsw8IZjzNBmYFv+cEv2fHITYXB6rw6qu2jKFkSRg/Ph9JYsMGG5y+8EKbR+tF/JwrUnJKFCWB8sFPhYjbGT+ukNu61TYYuuMOm/o6daptHpcnn3xiRfzeeQcefNDqeXiCcK5IyanraaWqPhm3SFxc/fyzrbKePdvqNj38sC1xyJOlS20Lu+OOsw2FTjwxlFidc4mVU6LwSe5F1GefwQ03wF572dqIPI01q8LYsVaXqWZN21yoUSMoVSq0eJ1ziZXTd8jz4haFi4u0NHjgAZulevTRNvU1T0liyRIrGXv22baFHdjghicJ54q0bBOFqq6PZyAuXL//bruJdusGt95q9ZoOPTTKF6en21zZunXthf/7H5xxRqjxOueSR56LArrC54cfbD+g9ethwAAbwM6Tyy6DYcOs+dGnTx4yjHOuKMjr8KUrRFTty/9ZZ9nCuYkT85Akdu2ylgRYbaa33rIBDU8SzhU7niiKqC1brHLG3XfbsMKUKXDCCVG+eNo0qyP+2mt2/+qrbfTbi/g5Vyx5oiiC5s+3iUgffgjPPANDhsC++0bxwm3bbC3EySfDqlVQo0bosTrnkp+PURQxgwfbIumyZa2ixnnRzl3L6JdauNAKPfXoAfvtF2qszrnCwRNFEbFrlzUGnn8eTjkFPvoIqlfPwwn+/NNO8tVXVqfJOecCniiKgJUrbdO477+Hu+6yxsDee0fxwpEjrYhf587W9Jg/P8oXOueKEx+jKOTGjoUGDaxO03vvwcsvR/G3ft0662Zq1sxmM+3caY97knDOZcETRSGlat1M554LFSvCjz/aXhK5vmjwYCvi9/77tr/p5MmeIJxzOfKup0Lojz9svPnjj+GKK+DNNy1Z5GrpUssm9erZSHfU82Wdc8WZtygKmTlzbPbqkCE2FjF4cC5JQtUK94EtlhszxmY4eZJwzkXJE0UhMnCgJYmNG+Gbb2wMOsc1cL/+agWezjtvTxG/006zsrHOORclTxSFwM6dtsL6mmts4HraNCvLka3du+Gll2yfiB9/tC3svIifcy6f/KtlkktNhdatYcIE24q6W7coqnq3aAFffAEXXWRlOHyFtXOuADxRJLFvv7UN5LZtg0GDrAJstnbtsk2vS5SA66+3+kzXXOP1mZxzBRZq15OINBWRBSKySEQeyOL5f4nIXBGZKSLfiIiXJsXGn7t1s32sq1SBSZNySRJTpkBKinUxga2+u/ZaTxLOuZgILVGISEmgF9AMqANcLSJ1Mh02HUhR1XrAYOC5sOIpLDZtgssvt53orrzSkkTt2tkcvG0b3H+/VQBcs8ZLgDvnQhFmi+JkYJGqLlbVncAHQIvIA1R1tKpuDe5OBPJSnajImTnTGgZffAEvvmiznMqXz+bgCRNsiutzz9miirlzoXnzuMbrnCsewhyjqAYsi7ifCjTK4fj2wIisnhCRDkAHgJo1a8YqvqTyzju2Rel++9lSh8aNc3nBtm22sdDXX+ehRKxzzuVdUkyPFZHrgBSge1bPq2pfVU1R1ZSqVavGN7iQ7dgBt99u+wI1amRTX7NNEsOHQ/fgIzr3XJg3z5OEcy50YSaK5UDkvMzqwWN/IyLnAw8Dl6rqjhDjSTpLl8KZZ9oM1vvvtwrfBx6YxYFr18J118HFF1vlv4wifrnOk3XOuYILM1FMBo4SkVoisjfQBhgaeYCInAj0wZLE6hBjSTpffmmL5+bPh08/hWefzWLBtCp88IGNZg8aBI89ZqPbXsTPORdHoSUKVU0DOgKjgHnAIFWdIyJPisilwWHdgfLARyIyQ0SGZnO6IiM9Hf77X2jaFA4+2Ga2XnZZNgcvXWrlwGvVsjrijz/uScI5F3eiqomOIU9SUlJ0ypQpiQ4jX9avt7Vww4dbT9Jrr0G5cpkOUrVCThm7zE2cCCedZIvpnHMun0Rkqqqm5Oe1STGYXRxMmwYNG9o4RO/e8PbbWSSJX36xwekLLthTxO+UUzxJOOcSyhNFHPTvb0Vb09Jsu9Lbb8+0aHr3bnjhBTj+eOti6tPHi/g555KG13oK0fbt0LGjJYrzz7dN5bKc3XvJJTBihC2Ye/VVqF6s1x0655KMtyhC8uuvth6if394+GEYOTJTkti500a2Adq2tSwydKgnCedc0vFEEYLhw208YvFiGDYMnnoq0zDDpEl2QO/edr91a6v26kX8nHNJyBNFDO3eDY8+auviDj3Uhhv+Vn5p61bblu7UU2HDBjjiiITF6pxz0fIxihhZu9Yqe3/5JbRrB716QdmyEQeMG2drIhYvtqJO3bpBpUoJi9c556LliSIGJk+GVq1g1Sro2xduvjmLXqSMjYVGj4azz05EmM45ly/e9VQAqjaT9fTTLTGMHw+33BKRJIYNszLgAOecY6XAPUk45woZTxT5tHWrTVa67TYr5Dp1qu0lAdgmQtdcA5deaptKZBTx+0cxJ+ecS36eKPJh0SIbj37nHXjiCdtoqHJlrInx/vtWxG/wYHjySfjxR6/P5Jwr1Pwrbh4NHWp7R5QsadNgmzaNeHLpUhvJPvFEW0BRt27C4nTOuVjxFkWU0tLgoYegRQs46iir3dS0KbZobtQoO+jQQ61Gx/jxniScc0WGJ4oorF4NF14IXbtChw6WCw49FPj5ZxugaNoUxo61g08+2Yv4OeeKFE8UuZgwwTYY+uEHePNNm+VUZq8025K0Xj2YMcO6mbyIn3OuiPIximyowiuvwL/+BTVrWsKoXz94snlz625q0cLKcBxySEJjdS5Z7dq1i9TUVLZv357oUIqNMmXKUL16dUrFcKtkTxRZ+PNPWw8xcKAVdn37bdi37A5ILwUlStiKuptugiuv9PpMzuUgNTWVChUqcNhhhyH+/0roVJV169aRmppKrVq1YnZe73rKZMECaNQIPvwQnn4ahgyBfedPtP6nXr3soFatrJCf/8N3Lkfbt2+ncuXKniTiRESoXLlyzFtwnigifPyx7Tr6++/Ws/RQpz8p0fle23Vo82ab7uScyxNPEvEVxuftiQKb+nrffdZQqFPHpr6eX/p723HuxRdtS7rZszMtmnDOueKh2CeKVatsm+rnn4c777RZrjVqYNmjVCnbu7pXL6hYMdGhOufyaciQIYgI8+fP/+uxMWPG0Pxv+wBA27ZtGTx4MGAD8Q888ABHHXUUDRo04NRTT2XEiBEFjqVr164ceeSRHHPMMYzKWIOVSdu2balVqxb169enfv36zJgxA4Du3bv/9dhxxx1HyZIlWb9+fYFjyk2xHsz+/nsbati0Cd59F64tNwSenwcPPmhF/ObM8fpMzhUBAwcO5PTTT2fgwIE88cQTUb3mP//5DytXrmT27NmULl2a33//ne+++65AccydO5cPPviAOXPmsGLFCs4//3wWLlxIySzWXnXv3p1WrVr97bEuXbrQpUsXAIYNG0bPnj3Zf//9CxRTNIrlX0FV61Hq0gUOPxy+Hfg7tXvfBR99ZIPWnTtbfSZPEs7FzD332LKjWKpf3/5fzsmWLVsYN24co0eP5pJLLokqUWzdupV+/frx66+/Urp0aQAOPPBAWrduXaB4P/vsM9q0aUPp0qWpVasWRx55JJMmTeLUU0/N87kGDhzI1VdfXaB4olXsup42b4arrrL1EZdeoszo/A61W9aBzz6zaU4TJ3oRP+eKkM8++4ymTZty9NFHU7lyZaZOnZrraxYtWkTNmjWpGEWX87333vtXd1Dkz7PPPvuPY5cvX06NGjX+ul+9enWWL1+e5Xkffvhh6tWrx7333suOHTv+9tzWrVsZOXIkLVu2zDW+WChWX5nnzoWWLa3yRvfu0LnVUuSYm60+eP/+cOyxiQ7RuSIrt2/+YRk4cCCdOnUCoE2bNgwcOJCGDRtmOzsor7OGevbsWeAYM+vatSsHHXQQO3fupEOHDnTr1o1HH330r+eHDRtG48aN49LtBMUoUXz4IbRvDxXKpTP9mVEcf18z4FAr4HfiiV6fybkiaP369Xz77bfMmjULEWH37t2ICN27d6dy5cps2LDhH8dXqVKFI488kqVLl/LHH3/k2qq49957GT169D8eb9OmDQ888MDfHqtWrRrLli37635qairVqlX7x2sPPvhgAEqXLk27du3o0aPH357/4IMP4tbtBNhKvsL007BhQ82LHTtUO3VSBdU2DRbo9kZn2J0xY/J0Hudc3s2dOzeh1+/Tp4926NDhb4+deeaZ+t133+n27dv1sMMO+yvG3377TWvWrKkbN25UVdUuXbpo27ZtdceOHaqqunr1ah00aFCB4pk9e7bWq1dPt2/frosXL9ZatWppWlraP45bsWKFqqqmp6drp06d9P777//ruY0bN+p+++2nW7ZsyfY6WX3uwBTN59/dIj1GsXy5TV565aU0hjbuxvtz6lF6wSyr7nfmmYkOzzkXsoEDB3L55Zf/7bGWLVsycOBASpcuzbvvvku7du2oX78+rVq14vXXX6dSpUoAPPXUU1StWpU6depw3HHH0bx586jGLHJSt25dWrduTZ06dWjatCm9evX6a8bTRRddxIoVKwC49tprOf744zn++ONZu3YtjzzyyF/n+PTTT2nSpAnlypUrUCx5IZZoCo+UlBSdMmVKrseNHg1t2ljdpkVHXMhBM7+EK66wNREHHRSHSJ1z8+bNo3bt2okOo9jJ6nMXkamqmpLNS3JU5MYoVOG55+CJB7dT6+hSjBlTkoPmdgA62Ei2c865PClSiWLTJmjbFlYPGc/PFdpT+aY7KFP7bqjtCcI55/KryIxRzJwJZzbYwnmf3c04OYND9t9OmRO9yetcohW27u3CLozPu0i0KN59F95u/x2f776R6ixFOnaEZ56B8uUTHZpzxVqZMmVYt26dlxqPEw32oyhTpkxMz1uoE8WOHXDvvfDqq3D3CXDw1n2QN7+Hxo0THZpzDlt5nJqaypo1axIdSrGRscNdLBXaRLF0KfQ67xP2XTSfLl0e4plnzmIvmeUL55xLIqVKlYrpTmsuMUIdoxCRpiKyQEQWicgDWTxfWkQ+DJ7/UUQOi+a83324ihlHtaLbopZ0OeJTnntqp9Xv8yThnHMxF1qiEJGSQC+gGVAHuFpE6mQ6rD2wQVWPBHoC3XI776Zf1lGvTW0u3PU5azp3Zb95P3gRP+ecC1GYLYqTgUWqulhVdwIfAC0yHdMCeCu4PRg4T3IZ8aq4cQm/Vz2O3VN/omqPB2xzIeecc6EJc4yiGrAs4n4q0Ci7Y1Q1TUQ2AZWBtZEHiUiwYg6AHbXXjJtNA6/0ClQh02dVjPlnsYd/Fnv4Z7HHMfl9YaEYzFbVvkBfABGZkt9l6EWNfxZ7+Gexh38We/hnsYeI5F77KBthdj0tB2pE3K8ePJblMSKyF1AJWBdiTM455/IozEQxGThKRGqJyN5AG2BopmOGAjcGt1sB36ov43TOuaQSWtdTMObQERgFlATeUNU5IvIkVhd9KNAfeEdEFgHrsWSSm75hxVwI+Wexh38We/hnsYd/Fnvk+7ModGXGnXPOxVeRKQronHMuHJ4onHPO5ShpE0VY5T8Koyg+i3+JyFwRmSki34jIoYmIMx5y+ywijmspIioiRXZqZDSfhYi0Dv5tzBGR9+MdY7xE8f9ITREZLSLTg/9PLkpEnGETkTdEZLWIzM7meRGRl4PPaaaINIjqxPndbDvMH2zw+xfgcGBv4CegTqZj7gBeC263AT5MdNwJ/CzOAfYJbt9enD+L4LgKwFhgIpCS6LgT+O/iKGA6sF9w/4BEx53Az6IvcHtwuw7wW6LjDumzOBNoAMzO5vmLgBGAAKcAP0Zz3mRtUYRS/qOQyvWzUNXRqro1uDsRW7NSFEXz7wLgv1jdsO3xDC7OovksbgF6qeoGAFVdHecY4yWaz0KBisHtSsCKOMYXN6o6FptBmp0WwNtqJgL7isjBuZ03WRNFVuU/qmV3jKqmARnlP4qaaD6LSO2xbwxFUa6fRdCUrqGqX8QzsASI5t/F0cDRIjJeRCaKSNO4RRdf0XwWjwPXiUgqMBy4Kz6hJZ28/j0BCkkJDxcdEbkOSAHOSnQsiSAiJYAXgLYJDiVZ7IV1P52NtTLHisjxqroxoVElxtXAAFV9XkROxdZvHaeq6YkOrDBI1haFl//YI5rPAhE5H3gYuFRVd8QptnjL7bOoABwHjBGR37A+2KFFdEA7mn8XqcBQVd2lqr8CC7HEUdRE81m0BwYBqOoEoAxWMLC4iervSWbJmii8/MceuX4WInIi0AdLEkW1Hxpy+SxUdZOqVlHVw1T1MGy85lJVzXcxtCQWzf8jQ7DWBCJSBeuKWhzPIOMkms9iKXAegIjUxhJFcdyfdShwQzD76RRgk6quzO1FSdn1pOGV/yh0ovwsugPlgY+C8fylqnppwoIOSZSfRbEQ5WcxCmgiInOB3UAXVS1yre4oP4vOQD8RuRcb2G5bFL9YishA7MtBlWA85jGgFICqvoaNz1wELAK2Au2iOm8R/Kycc87FULJ2PTnnnEsSniicc87lyBOFc865HHmicM45lyNPFM4553LkicIlJRHZLSIzIn4Oy+HYLTG43gAR+TW41rRg9W5ez/G6iNQJbj+U6bkfChpjcJ6Mz2W2iAwTkX1zOb5+Ua2U6uLHp8e6pCQiW1S1fKyPzeEcA4DPVXWwiDQBeqhqvQKcr8Ax5XZeEXkLWKiqT+dwfFusgm7HWMfiig9vUbhCQUTKB3ttTBORWSLyj6qxInKwiIyN+MZ9RvB4ExGZELz2IxHJ7Q/4WODI4LX/Cs41W0TuCR4rJyJfiMhPweNXBY+PEZEUEXkWKBvE8V7w3Jbg9wcicnFEzANEpJWIlBSR7iIyOdgn4NYoPpYJBAXdROTk4D1OF5EfROSYYJXyk8BVQSxXBbG/ISKTgmOzqr7r3N8lun66//hPVj/YSuIZwc+nWBWBisFzVbCVpRkt4i3B787Aw8HtkljtpyrYH/5yweP3A49mcb0BQKvg9pXAj0BDYBZQDlv5Pgc4EWgJ9It4baXg9xiC/S8yYoo4JiPGy4G3gtt7Y5U8ywIdgEeCx0sDU4BaWcS5JeL9fQQ0De5XBPYKbp8PfBzcbgu8EvH6Z4Drgtv7YvWfyiX6v7f/JPdPUpbwcA7Ypqr1M+6ISCngGRE5E0jHvkkfCKyKeM1k4I3g2CGqOkNEzsI2qhkflDfZG/smnpXuIvIIVgOoPVYb6FNV/TOI4RPgDGAk8LyIdMO6q77Pw/saAbwkIqWBpsBYVd0WdHfVE5FWwXGVsAJ+v2Z6fVkRmRG8/3nAVxHHvyUiR2ElKkplc/0mwKUicl9wvwxQMziXc1nyROEKi2uBqkBDVd0lVh22TOQBqjo2SCQXAwNE5AVgA/CVql4dxTW6qOrgjDsicl5WB6nqQrF9Ly4CnhKRb1T1yWjehKpuF5ExwIXAVdgmO2A7jt2lqqNyOcU2Va0vIvtgtY3uBF7GNmsaraqXBwP/Y7J5vQAtVXVBNPE6Bz5G4QqPSsDqIEmcA/xjX3CxvcJ/V9V+wOvYlpATgcYikjHmUE5Ejo7ymt8Dl4nIPiJSDus2+l5EDgG2quq7WEHGrPYd3hW0bLLyIVaMLaN1AvZH//aM14jI0cE1s6S2o+HdQGfZU2Y/o1x024hDN2NdcBlGAXdJ0LwSqzzsXI48UbjC4j0gRURmATcA87M45mzgJxGZjn1bf0lV12B/OAeKyEys2+nYaC6oqtOwsYtJ2JjF66o6HTgemBR0AT0GPJXFy/sCMzMGszP5Ettc6mu1rTvBEttcYJqIzMbKxufY4g9imYltyvMc0DV475GvGw3UyRjMxloepYLY5gT3ncuRT491zjmXI29ROOecy5EnCueccznyROGccy5Hniicc87lyBOFc865HHmicM45lyNPFM4553L0fxXRV5ktkiJkAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrBboYxky0wU"
      },
      "source": [
        "##### Feature importance for decision tree\n",
        "\n",
        "Same as the previous feature importance calculation. Code from [here](https://machinelearningmastery.com/calculate-feature-importance-with-python/)]. This would be less efficient to loop over as 1) not every model can produce feature importance plots like this and 2) they rely on different parameters to produce this output. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "KJiSaLPhxvFY",
        "outputId": "92d77cf3-3175-47e0-cd12-c02d415ccfba"
      },
      "source": [
        "# get feature importance for decision tree\n",
        "importance = dectree.feature_importances_\n",
        "\n",
        "# visualize results w bar plot\n",
        "plt.bar([x for x in range(len(importance))], importance)\n",
        "plt.title(\"Feature importance for decision tree\")\n",
        "plt.xlabel(\"Feature\")\n",
        "plt.ylabel(\"Relative importance\")\n",
        "plt.show()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wOF0AllWl9l"
      },
      "source": [
        "### Decision tree with boosting\n",
        "\n",
        "Since AdaBoost is generally performed with decision trees, this is particularly salient to try out. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPEkM_DoWx7p",
        "outputId": "75e5f4d5-af38-4ca7-ba1c-b54f34cbc95d"
      },
      "source": [
        "# set up the booster on the decision tree classifier you already made\n",
        "decAda = AdaBoostClassifier(dectree)\n",
        "\n",
        "# fit it to the data\n",
        "decAdaPred = decAda.fit(xtrain, ytrain).predict(xtest)\n",
        "\n",
        "# calculate the percent error--errors/(size of test set)*100\n",
        "decAdaerror = float((decAdaPred != ytest).sum()/len(xtest))*100\n",
        "\n",
        "# What was the error?\n",
        "print(\"With AdaBoost, we get an decision tree error rate of {}%.\".format(decAdaerror))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With AdaBoost, we get an decision tree error rate of 18.49611063094209%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpFMCirbB6aR"
      },
      "source": [
        "#### K-fold cross validation for decision tree with boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kc28C9j1CB3z",
        "outputId": "450f2f6d-bcdb-46ba-9f17-bafc6ce2864b"
      },
      "source": [
        "# prepare the cross-validation procedure\n",
        "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "\n",
        "# get the task and associated labels\n",
        "task = datasets[taskind]\n",
        "lab = labels[taskind]\n",
        "\n",
        "# evaluate model--n_jobs = -1 means to use all processors\n",
        "# see https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html \n",
        "decAdaTreeScores = cross_val_score(decAda, model, lab, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\n",
        "# report performance--we take the average accuracy over all folds. 1- just gives us the error rate\n",
        "print(\"The k-fold cross-validated error rate is \" + str((1-np.mean(decAdaTreeScores))*100)+ \"%.\")"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The k-fold cross-validated error rate is 17.740225735929638%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XScT3C8SwBFF"
      },
      "source": [
        "#### ROC/AUC measurements for decision tree with boosting\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "6amcvZ7YtOpR",
        "outputId": "42a75022-506e-449c-f9e6-ab4d23e5224f"
      },
      "source": [
        "# get false positive/true positive rates\n",
        "fpr, tpr, threshold = metrics.roc_curve(ytest, decAdaPred)\n",
        "\n",
        "# get roc/auc measurements\n",
        "decAda_auc = roc_auc_score(ytest, decAdaPred)\n",
        "print('Decision tree with adaboost ROC AUC=%.3f' % (decAda_auc))\n",
        "\n",
        "# plot ROC/AUC\n",
        "plt.title('ROC for decision tree with boosting')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % decAda_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "\n",
        "# plot a dotted line for the threshold\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "\n",
        "# set axes limits and labels\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decision tree with adaboost ROC AUC=0.580\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wODImlWSmYfj"
      },
      "source": [
        "##### Feature importance for decision tree with boosting\n",
        "\n",
        "To what degree did each column [feature] contribute to the final output? Let me check feature importance [from [here](https://machinelearningmastery.com/calculate-feature-importance-with-python/)]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "xPYBOStcsMtO",
        "outputId": "481775ba-dfbf-490e-9fa6-06b6a5ee7022"
      },
      "source": [
        "# get feature importance for decision tree\n",
        "importance = decAda.feature_importances_\n",
        "\n",
        "# visualize results w bar plot\n",
        "plt.bar([x for x in range(len(importance))], importance)\n",
        "plt.title(\"Feature importance for decision tree with adaboost\")\n",
        "plt.xlabel(\"Feature\")\n",
        "plt.ylabel(\"Relative importance\")\n",
        "plt.show()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuTd56VeUiii"
      },
      "source": [
        "### SVM classification\n",
        "\n",
        "SVMs are a powerful tool and we hope that the kernel trick [some nice visualizations [here](https://towardsdatascience.com/the-kernel-trick-c98cdbcaeb3f)] will work in our favor here, especially if the data is not linearly separable. Having said that, we are not optimizing for kernel choice here. As a result, these results aren't necessarily an indication that there exists some function that can transform our data into a space where it is linearly separable. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V11oXEuE10Ym",
        "outputId": "b48bf4d4-a0d5-43bc-a072-e4bde8b7fc2e"
      },
      "source": [
        "# set up the svm\n",
        "supportvm = svm.SVC()\n",
        "\n",
        "# predict the test data's labels\n",
        "svmpred = supportvm.fit(xtrain, ytrain).predict(xtest)\n",
        "\n",
        "# compute the error\n",
        "# number of errors\n",
        "numSVMError = (svmpred != ytest).sum()\n",
        "\n",
        "# calculate the percent error--errors/(size of test set)*100\n",
        "svmerror = float(numSVMError/len(xtest))*100\n",
        "\n",
        "# How many errors did we get?\n",
        "print(\"Out of \"+str(len(xtest))+\" points, the SVM produced \"+str(numSVMError)+\" errors, resulting in an error rate of \" + str(svmerror)+\"%.\")"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Out of 3471 points, the SVM produced 402 errors, resulting in an error rate of 11.581676750216076%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqzg6Y5uDTcv"
      },
      "source": [
        "#### K-fold cross validation for SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3zLui5tDWKi",
        "outputId": "c7ab6dc5-bbe5-4273-e678-06696202f5e4"
      },
      "source": [
        "# prepare the cross-validation procedure\n",
        "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "\n",
        "# get the task and associated labels\n",
        "task = datasets[taskind]\n",
        "lab = labels[taskind]\n",
        "\n",
        "# evaluate model--n_jobs = -1 means to use all processors\n",
        "# see https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html \n",
        "svmScores = cross_val_score(supportvm, task, lab, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\n",
        "# report performance--we take the average accuracy over all folds. 1- just gives us the error rate\n",
        "print(\"The k-fold cross-validated error rate is \" + str((1-np.mean(svmScores))*100)+ \"%.\")"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The k-fold cross-validated error rate is 11.619179778271583%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toOcad9ywKXh"
      },
      "source": [
        "#### ROC/AUC measurements for SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "nFtc32basIj3",
        "outputId": "8521fbac-8888-4a34-a951-b2f5e729fc51"
      },
      "source": [
        "# get false positive/true positive rates\n",
        "fpr, tpr, threshold = metrics.roc_curve(ytest, svmpred)\n",
        "\n",
        "# get roc/auc measurements\n",
        "svm_auc = roc_auc_score(ytest, svmpred)\n",
        "print('SVM ROC AUC=%.3f' % (svm_auc))\n",
        "\n",
        "# plot ROC/AUC\n",
        "plt.title('ROC for SVM')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % svm_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "\n",
        "# plot a dotted line for the threshold\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "\n",
        "# set axes limits and labels\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM ROC AUC=0.501\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryonYRCkmd9k"
      },
      "source": [
        "##### Feature importance for SVM\n",
        "\n",
        "Unfortunately the only SVM setting that produces feature importance measurements is a linear kernel. Linear kernels take prohibitively long to run so we're not using them here. Since the separating hyperplane used by a nonlinear-kernel SVM acts on a transformed feature space not drectly related to the input, it doesn't make sense to calculate feature importance. For more information see [here](https://stackoverflow.com/questions/21260691/how-to-obtain-features-weights)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP5kvkLFgVr9"
      },
      "source": [
        "## Ensemble classification approaches\n",
        "\n",
        "Perhaps ensemble classification approaches can leverage the power of multiple classifiers to produce a consensus classifcation that outperforms our other models. We'll use two standard approaches -- random forest and a majority vote combining all previous classifiers. \n",
        "\n",
        "Yes, AdaBoost is an ensemble classification approach. Since we were using it with a non-ensemble classifier that we had run, however, we left it in the section above. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtvpHZ_6UlWp"
      },
      "source": [
        "### Random forest classification\n",
        "\n",
        "This has some superficial similarities with our \"AdaBoost with decision tree\" approach as it uses an ensemble of decision trees to classify. The difference is in the way those decision trees are utilized to facilitate that classification. There is a nice description of random forest [here](https://towardsdatascience.com/understanding-random-forest-58381e0602d2) along with some images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QI8kJdq3gc-k",
        "outputId": "f43ffb6e-c8ea-4075-e2f8-8b3f0b3452d1"
      },
      "source": [
        "# set up your random forest--I'll try these default parameters and see if I need to tune them\n",
        "randomforest = RandomForestClassifier(n_estimators = 50, max_depth = None, random_state = 10, max_features = 'auto')\n",
        "\n",
        "# predict the test data's labels\n",
        "rfpred = randomforest.fit(xtrain, ytrain).predict(xtest)\n",
        "\n",
        "# calculate the percent error--errors/(size of test set)*100\n",
        "numRFError = (rfpred != ytest).sum()\n",
        "rferror = float(numRFError/len(xtest))*100\n",
        "\n",
        "# How many errors did we get?\n",
        "print(\"Out of \"+str(len(xtest))+\" points, the random forest produced \"+str(numRFError)+\" errors, resulting in an error rate of \" + str(rferror)+\"%.\")"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Out of 3471 points, the random forest produced 397 errors, resulting in an error rate of 11.437626044367617%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUig0vRUDmN3"
      },
      "source": [
        "#### K-fold cross validation for random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOF_S7jRDo5G",
        "outputId": "20b9d582-4c8b-4d8d-a351-a80fb871491b"
      },
      "source": [
        "# prepare the cross-validation procedure\n",
        "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "\n",
        "# get the task and associated labels\n",
        "task = datasets[taskind]\n",
        "lab = labels[taskind]\n",
        "\n",
        "# evaluate model--n_jobs = -1 means to use all processors\n",
        "# see https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html \n",
        "rfScores = cross_val_score(randomforest, task, lab, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\n",
        "#report performance--we take the average accuracy over all folds. 1- just gives us the error rate\n",
        "print(\"The k-fold cross-validated error rate is \" + str((1-np.mean(rfScores))*100)+ \"%.\")"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The k-fold cross-validated error rate is 11.325338768381421%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9x7zWYBwRqg"
      },
      "source": [
        "#### ROC/AUC measurements for random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "S-VPSwxntyXq",
        "outputId": "73e4d021-173d-4170-a2c5-44d2cbc97ff6"
      },
      "source": [
        "# get false positive/true positive rates\n",
        "fpr, tpr, threshold = metrics.roc_curve(ytest, rfpred)\n",
        "\n",
        "# get roc/auc measurements\n",
        "rf_auc = roc_auc_score(ytest, rfpred)\n",
        "print('Random forest ROC AUC=%.3f' % (rf_auc))\n",
        "\n",
        "# plot ROC/AUC\n",
        "plt.title('ROC for random forest')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % rf_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "\n",
        "# plot a dotted line for the threshold\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "\n",
        "# set axes limits and labels\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random forest ROC AUC=0.515\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZzN9ffA8dche+gbabGUikKyTSQqSrtojzZbaU+lRalQSqUoZd/bqCjLD6GyJvtuLIkwlhKyZDfn98f5TG7TmLnD3LmznOfjcR9zl/f93DOfdM+8l895i6rinHPOHUuOaAfgnHMuY/NE4ZxzLlmeKJxzziXLE4VzzrlkeaJwzjmXLE8UzjnnkuWJwmVaIlJLRH4RkT0icku040mJiNQRkbh0+qxMdW5cxuaJwp0wEflNRPYFX0pbRGSQiJycqM1lIvKjiOwWkZ0iMlpEyidqU0hEPhCR9cGxfg0eFz3GR78OfKyqJ6vqiEj9fplUVM6NiKiInJ9en+fShycKl1ZuVtWTgcpAFeClhBdEpCYwARgJnAWUBhYBP4nIuUGb3MAPQAXgeqAQUBPYBlQ/xmeeDSw7nmBF5KQw2uQ8nmNnEBE9Ny578UTh0pSqbgHGYwkjwbvAJ6r6oaruVtXtqvoKMBNoH7R5ACgF3Kqqsaoar6p/qOobqjo28eeIyK/AucDooPeRR0TOEpFRIrJdRFaLyEMh7duLyDAR+UxEdgFNkzjmIBHpKSJjReRvoK6I3CQiC0Rkl4hsEJH2Ie3PCf6CbhL0gv4UkbYhr+cLjrlDRGKBSxJ9XjkRmSwif4nIMhFpkCiWHiIyLvj9fhKRM4Ie1g4RWSEiVZL6b5AW50ZECotIfxHZLCIbRaRjQuIUkfNFZErQM/xTRL4Mnp8aHHJR8Ll3JxWfy4RU1W9+O6Eb8BtQL7hfAlgCfBg8zg8cAeom8b5mwObg/lBg8PF+bvB4KtADyIslqq3AVcFr7YFDwC3YH0j5kjjeIGAnUCtokxeoA1QMHl8M/A7cErQ/B1CgL5APqAQcAMoFr78NTANOBUoCS4G44LVcwGrgZSA3cBWwG7ggJJY/gWpBHD8Ca7GEmhPoCEyK1LkBvgV6AwWAYsBs4OGg/RCgbcg5qh3yOQqcH+1/k35L25v3KFxaGSEiu4ENwB9Au+D5U7EvlM1JvGczkDD/UOQYbcIiIiWxL/gXVXW/qi4E+mFfrAl+VtURar2Vfcc41EhV/Slos19VJ6vqkuDxYuxL8spE7+mgqvtUdRE2pFYpeP4u4E21HtQGoFvIey4FTgbeVtWDqvoj8H9A45A236rqPFXdj31x71fVT1T1CPAlNsSX5ucGG/a7EXhaVf9W1T+ArkCjoO0hbGjrrOB408OJw2VenihcWrlFVQtif4FfyNEEsAOIB85M4j1nYn81g81FJNUmXGcB21V1d8hz64DiIY83hHGcf7URkRoiMklEtorITuARjv5uCbaE3N+LJYCEmEKPty5RvBuCL+Zjxft7yP19STz+14KBZKT23JyN9Xg2B8Nif2G9i2LB6y8AAswOhsyahxmHy6Q8Ubg0papTsGGT94LHfwM/A3cm0fwubAIb4HvgOhEpcJwfvQk4VUQKhjxXCtgYGl4Yx0nc5gtgFFBSVQsDvbAvyXBsxoacQuMJjbekiORI9HpovGkltedmAzaEVlRVTwluhVS1Atg8lKo+pKpnAQ8DPXylU9bmicJFwgfANSKSMATTBmgiIk+JSEER+Z+IdMRWNXUI2nyKfUENF5ELRSSHiBQRkZdF5MaUPjAY2pkBdBKRvCJyMdAC+OwEf5eC2F/j+0WkOnBPKt77FfBS8PuWAJ4MeW0W1vt4QURyiUgd4GZsriZNpfbcqOpmbJXa+8GS5Rwicp6IXAkgIncGvw9Yj1GxXiNYr+fctP4dXHR5onBpTlW3Ap8ArwWPpwPXAbdhf2Wvw8bXa6vqL0GbA0A9YAUwEdiFTaAWxb5Uw9EYm2DehI3pt1PV70/w13kMeD2Yf3kN+/IPVwfsd12LffF+mvCCqh7EEsMN2PBbD+ABVV1xgvEeS2rPzQPYJHsslgyGcXRo8BJglojswXpbrVR1TfBae2BwMGR1V1r/Ei46RNU3LnLOOXds3qNwzjmXrIglChEZICJ/iMjSY7wuItItuPhnsYhUjVQszjnnjl8kexSDsFIMx3IDUCa4tQR6RjAW55xzxyliiUJVpwLbk2nSECvroKo6EzhFRE5kHb1zzrkIiGbxr+L8+yKfuOC5/1ydKyItsV4HBQoUqHbhhRemS4DOOZcRHTkCGzfCrl12Pz7ebkkpxTpO4S8Wc/hPVT3teD4vU1SJVNU+QB+AmJgYnTt3bpQjcs656JgwAVq0gG3boGFDKFoUChWCggXtVqgQFDxZ7X5h4ZxxPcn/9x8U+bD9upSPnrRoJoqN/Puq1RJE5qpU55zL9Hbtgueeg759oVw5+PlnqJ5UAf6NG+HRR+Huu+Gme6H2o/b8h+2P+7OjuTx2FPBAsPrpUmBncEWoc865EBMnQsWK0L8/vPgizJ+fRJJQtSxSvjx8/z3s2ZNmnx+xHoWIDMEKxBUV2/6xHVZoDFXtBYzFKlSuxkoZNItULM45lxnt3g3PPw+9e8OFF8KMGVCjRhINf/0VHnoIJk2CunUtYZx3XprFEbFEoaqNU3hdgccj9fnOOZeZ/fCDzUVs2GDJokMHyJfvGI2XLIF586BPH3jwQZBw61aGJ1NMZjvnXHaxZw+88AL07Ally8L06VCzZhINly61MagHHoBbboE1a6BIkYjE5CU8nHMug5g0yeYievWC1q1h4cIkksTBg9C+PVStCm3bwv799nyEkgR4onDOuajbsweeeAKuugpy5YJp0+C995IYapo1yxJEhw62qmnBAsibN+Lx+dCTc85F0ZQp0KwZ/PYbPPMMdOwI+fMn0XDjRrj8cjj9dPi//4Obbkq3GL1H4ZxzUfD33/DUU1CnDuTMaQmjS5ckksSqVfazeHH48ktYtixdkwR4onDOuXQ3bRpUqgQffQStWsGiRdZZ+Je//oKWLW1d7NSp9tytt9ql1+nME4VzzqWTvXtteOnKK+36uClT4IMPkuhFjBoFFSrYFXbPPw+XXBKVeBP4HIVzzqWDn36yuYhffoEnn4ROnaBAgSQaPvigJYiKFWHkSIiJSfdYE/NE4ZxzEbRvH7zyCnTtCmefbUtg69RJ1ChhS2oRSwxnn221OnLnTu9wk+SJwjnnImTGDOtFrFoFjz0G77wDJ5+cqNGGDfDII9CoEdx/v93PYHyOwjnn0ti+fTa1ULs2HDhg5Ti6d0+UJOLj7fLrChVg8mRrmEF5j8I559LQzJnQtCmsXGmdg3fftX0i/uWXX2wuYupUqFfPajSVLh2NcMPiPQrnnEsD+/fbtEKtWtajmDjROgz/SRIAsbGweDEMGGA7EWXgJAHeo3DOuRM2e7b1IpYvt0sfOndO4nKHRYuseFOTJrY13Zo18L//RSPcVPMehXPOHacDB+Cll6xw3549MH687R3xryRx4AC8+qqtZnr11aNF/DJJkgBPFM45d1zmzLH6fG+/Dc2b25YQ116bqNHPP0OVKlbA6Z570q2IX1rzROGcc6lw4IBV965Z0/axHjfONpQrXDhRw40b7RLsPXtg7FgYPDiipcAjyeconHMuTPPm2VzE0qXWi+jSJYkEsXw5lCtnRfy++gquvvoYM9qZh/conHMuBQcP2vRCjRqwfTuMGWNVNv6VJHbssOxRvrxV/QPbeS6TJwnwHoVzziVr/nzrRSxZYj+7doVTTknU6Ntv7dLrrVttdjvKRfzSmvconHMuCQcPQrt21ov480/bK2jgwCSSRPPmcNttcMYZtk72rbcy5YR1crxH4ZxziSxcaL2HRYus/NKHHyZazRpaxO/SS6FMGXjuOdvHNAvyHoVzzgUOHbLtqC+5BH7/3baF+OSTREli3Tq44Qb49FN73LKlDTdl0SQBniiccw6wiho1akD79nD33bbj6M03hzSIj7fKfhddBNOnW1bJJjxROOeytUOH4I037MLpTZtgxAj47DM49dSQRitX2jURTzwBl11m62NbtIhazOnN5yicc9lWwkqm+fOhcWPbwzrJa+JWrrQuxqBB8MADNjeRjXiPwjmX7Rw+DG++CdWqQVwcfPMNfPFFoiSxYIEtcwJo0MCK+DVpku2SBHiicM5lM8uWWfmNV16xVa3LlsGtt4Y02L8fXn7ZZrTbtz9axO8/62KzD08Uzrls4fBh6NTJCvmtWwdffw1Dh0LRoiGNfvoJKle2hg88YOtks9g1EcfD5yicc1lebKzNRcyZA3feaYuXTjstUaONG6FuXavRNH58EqVgsy/vUTjnsqzDh+Gdd6wXsXYtfPml1en7V5KIjbWfxYvD8OHHqBeevXmicM5lSStWQO3a0KYN1K9vcxF33RXSYPt262ZUqGB7V4NdOHHyydEIN0PzROGcy1KOHLGtSCtXhl9+gSFDbD6iWLGQRsOHW5XXzz+3zSWqV49avJmBz1E457KMlSuhWTPbWO7WW6FnTzj99ESNmja1TYSqVoXvvrOM4pLlicI5l+kdOWKF+9q2hXz5rKPQuHHIJQ+hRfwuu8w2FmrdGk7yr8BwRHToSUSuF5GVIrJaRNok8XopEZkkIgtEZLGI3BjJeJxzWc+qVVZdo3VruO46m5u+556QJLF2rU1Of/KJPW7ZEl580ZNEKkQsUYhITqA7cANQHmgsIuUTNXsF+EpVqwCNgB6Risc5l7XEx8MHH0ClSpYcPv3U9g8644ygwZEj0K2bFfGbOfNor8KlWiRTanVgtaquARCRoUBDIDakjQKFgvuFgU0RjMc5l0WsXm1zEdOn20Kl3r3hzDNDGixfbkX7fv7ZSoL36gWlSkUt3swukkNPxYENIY/jgudCtQfuE5E4YCzwZFIHEpGWIjJXROZu3bo1ErE65zKB+HjrJFx8sRVwHTwYRo5MlCTAMsnKldbNGDPGk8QJivby2MbAIFUtAdwIfCoi/4lJVfuoaoyqxpz2n8spnXPZwZo1duF0q1b2c+nSRIVc582DAQPs/s0329zEffdlyyJ+aS2SiWIjUDLkcYnguVAtgK8AVPVnIC9QFOecC8THw8cfQ8WKtjXpwIG2f3XxhPGJffvsqroaNWxjiYQifoUKHfOYLnUimSjmAGVEpLSI5MYmq0clarMeuBpARMphicLHlpxzgHUKrr4annwSrrjCehFNm4Z0EqZOtdnsd96xFxYs8CJ+ERCxyWxVPSwiTwDjgZzAAFVdJiKvA3NVdRTQGugrIs9gE9tNVX1pgnPZXXy8zT+/8ALkzAn9+9vk9b9GkTZutCxSsiR8/73ddxEhme17OSYmRufOnRvtMJxzEfLbb7Zg6ccf7fKHfv0sF/xjyRIbhwIbg6pbFwoUiEaomYqIzFPVmON5b7Qns51zDrDLHHr1shwwZw707WsVNv5JEn/+Cfffb0ueEor41a/vSSId+KWJzrmoW7cOHnzQRpDq1bOhpn9WtKpaVb8nnoAdO6BdO5u4dunGE4VzLmpUbWipdWu737s3PPRQormIJk3seoiYGPjhh6PDTi7deKJwzkXF+vWWFCZMsHnofv3gnHOCF0OL+F15pQ03Pf2012eKEp+jcM6lK1UbWrroItuiumdPmDgxJEmsWWPjT4MG2eMWLeC55zxJRJEnCudcuomLgxtvtPmImBhbwPTII8FQ05EjVuUvYTY7h389ZRT+X8I5F3GqdkV1wq6j3bvbxHXp0kGD2FioVQueecaWu8bG2tyEyxC8L+eci6iNG20LiLFjbbphwAA499xEjdauhV9/hS++gEaNvD5TBuOJwjkXEaq2V1CrVnDokFV9ffzxkBGlOXNg4UKb0b7pJpubKFgwqjG7pPnQk3MuzW3aZAVcmza1BUuLF1u9phw5gL17bXL60kuhU6ejRfw8SWRYniicc2lG1S55qFDBSnB88AFMngznnRc0mDzZMsf771tPwov4ZQo+9OScSxObN8PDD8Po0TYvPXAglCkT0iAuDq65Bs4+27JI3bpRi9WljvconHMnRBU+/9x6ERMnQpcuMGVKSJJYtMh+lihh29EtXuxJIpPxROGcO25btsCtt9pGcuXKWU545hkrDc7WrXDPPVC5smUOsIso8uePaswu9TxROOdSTRWGDLFexHffwXvv2fURZcuGvFi+PAwbBh06QM2a0Q7ZnQCfo3DOpcrvv8Ojj8K339rCpYED4cILQxrcf7+NRdWoYbU6KlSIWqwubYSdKEQkv6rujWQwzrmM7auv4LHHYM8eePddePbZYJgpPt4ukhOx+Ydq1eCpp4IXXWaX4tCTiFwmIrHAiuBxJRHpEfHInHMZxh9/wJ13wt1321LXBQvg+eeDPLB6tZV/HTjQGrdoETJR4bKCcOYougLXAdsAVHURcEUkg3LOZRxff22jR6NGwdtvW8XXcuWAw4dtcqJiRcscuXNHO1QXIWENPanqBvl37ZUjkQnHOZdRbN1qm8p99ZVVeh00KGS6YelSaNYM5s6Fhg2hRw8466xohusiKJxEsUFELgNURHIBrYDlkQ3LORdNw4fbhPVff8Gbb8ILLyTaDmL9etu/dOhQuOsuL+KXxYWTKB4BPgSKAxuBCcBjkQzKORcd27ZZL2LoUJuP/vFH22AIgFmz7EKJli3teog1a+Dkk6Mar0sf4cxRXKCq96rq6apaTFXvA8pFOjDnXPr69lu79GH4cHjjDfj55yBJ/P23LW+qWdOWOh04YG/wJJFthJMoPgrzOedcJrRtG9x7L9x2GxQvbtMOr7wCuXJhXYqLL4auXW0ruvnzIU+eaIfs0tkxh55EpCZwGXCaiDwb8lIhwNe9OZcFjBxphfy2bbMLqF96KUgQYEX8rrvOtqGbMgWu8MWO2VVycxS5gZODNqGF4ncBd0QyKOdcZG3fbhsKffaZlWIaPx4qVQpeXLAAqlSxIn6jR9u2dPnyRTVeF13HTBSqOgWYIiKDVHVdOsbknIug0aOtF7F1K7RrBy+/HFwC8fvvdjX1V1/ZvhFXXgnXXx/tcF0GEM6qp70i0hmoAPyzw4iqXhWxqJxzaW7HDnj6adue9OKLYcwY6zigCp99bl2MPXugY0e47LJoh+sykHAmsz/HyneUBjoAvwFzIhiTcy6NjR1rK5g+/xxefdW2q65SJXjxnnuskN8FF9ge1m3bhkxUOBdej6KIqvYXkVYhw1GeKJzLBP76y8ouDRpkiWLUKLs+gvh40KCI37XX2tLXxx/3+kwuSeH0KA4FPzeLyE0iUgU4NYIxOefSwHffWXL49FPrJMydGySJVauswuuAAdawWTOv9OqSFU6i6CgihYHWwHNAP+DpiEblnDtuO3daAdcbboDChWHmTJt2yJPzsF0wV6mSbUfqK5lcmFIcelLV/wvu7gTqAohIrUgG5Zw7PhMmWJLYtMmuiWjXLrg+bvFiaN4c5s2zvUu7d4czz4x2uC6TSO6Cu5zAXViNp+9UdamI1AdeBvIBVY71Xudc+tq1C1q3hn79rAT4zz9D9eohDeLiYMMGqxl+++1exM+lSnJDT/2BB4EiQDcR+Qx4D3hXVcNKEiJyvYisFJHVItLmGG3uEpFYEVkmIl+k9hdwLrubONHmIgYMgBdftCob1asDM2ZAr17WKKGI3x13eJJwqZbc0FMMcLGqxotIXmALcJ6qbgvnwEGPpDtwDRAHzBGRUaoaG9KmDPASUEtVd4hIseP9RZzLbnbvtl3meve2PatnzLBtqtmzB1q1hY8+su3omjWz8acCBaIdssukkutRHFTVeABV3Q+sCTdJBKoDq1V1jaoeBIYCDRO1eQjorqo7gs/5IxXHdy7b+uEH21iub19LFvPnB0liwgTrXnz0kS139SJ+Lg0k16O4UEQWB/cFOC94LICq6sUpHLs4sCHkcRxQI1GbsgAi8hNWaLC9qn6X+EAi0hJoCVCqVKkUPta5rGvPHttEqGdPKFsWpk+3SyAAm4O46SbrRUydCrVrRzVWl3UklyjSY8+Jk4AyQB2gBDBVRCqq6l+hjVS1D9AHICYmRtMhLucynEmTbOHSunU2cf3GG8EK13nz7AKJkiXtEuzLL4e8eVM8nnPhOubQk6quS+4WxrE3AiVDHpcIngsVB4xS1UOquhZYhSUO51xgzx7bde6qq6yyxrRp8N57kG/nFrjzTtvQesoUa3zNNZ4kXJoL54K74zUHKCMipUUkN9AIGJWozQisN4GIFMWGotZEMCbnMpUpU6yAX48eVopj4UKodZnC4MG2Hd3o0fDWW17Ez0VUxBKFqh4GngDGA8uBr1R1mYi8LiINgmbjgW0iEgtMAp5P5YS5c1nS339bVY06dayyxpQp0KUL5M8PNGoETZtaoli4MNFuQ86lPVFNechfRPIBpVR1ZeRDSl5MTIzOnTs32mE4FzHTptmK1l9/tcrfb70F+fPG2/UPItab2L0bHnsMckRyUMBlJSIyT1Vjjue9Kf4rE5GbgYXAd8HjyiKSeAjJOXeC9u61/SKuvNK2iJgyBT74APKvX2HbkPbvbw2bNLFJC08SLp2E8y+tPXZNxF8AqroQ25vCOZdGpk+3Wn0ffmg5YPFiuKLmIetOVKoEsbFw8snRDtNlU2GVGVfVnYme8yWqzqWBvXvh2Wetw3D4sC2B7dYNCvyy0OpwtG0LDRpYomjUKNrhumwqnI2LlonIPUDOoOTGU8CMyIblXNY3Y4bNSf/yi003vPNOSKdhyxa7DR8Ot90WzTCdC6tH8SS2X/YB4Aus3LjvR+Hccdq3D557zi6cPnjQynF07w4nL5xu62ABrr/eZrM9SbgMIJxEcaGqtlXVS4LbK0HtJ+dcKs2caXtVv/8+PPwwLFkCV12y2yYmLr/cZq8PHLDG+fNHN1jnAuEkivdFZLmIvCEiF0U8IueyoP37rQR4rVrWo5g40eo1FZwx3or49ehha2G9iJ/LgMLZ4a6uiJyBbWLUW0QKAV+qaseIR+dcFjB7ts1FLF8OLVtC585QqBBWxK9+fTj/fFv25FdXuwwqrIXYqrpFVbsBj2DXVLwW0aicywIOHLCLpmvWtHpN48dD715KoRWzrUHJkjBuHCxY4EnCZWjhXHBXTkTai8gS4CNsxVOJiEfmXCY2Zw5UrQpvv20VX5csgWsrbrZtSGvUOFrEr149L+LnMrxwehQDsIvtrlPVOqra0zcYci5pBw7YpQ81a9o+1uPGQd8+SuFvBlptpnHjbB1srVrRDtW5sIUzR1EzpTbOOdsWomlTWLrUehFdukDhwsCdd8GwYbaqqV8/23HIuUzkmIlCRL5S1buCIafQK7HD3eHOuWzh4EHbRKhTJzj9dBgzBm687ogV8CMH3HyzbSbx8MNen8llSsn1KFoFP+unRyDOZUbz51svYskS+9m1K5yyeTlc3sJKwD70EDzwQLTDdO6EJLfD3ebg7mNJ7G73WPqE51zGdPAgtGtn89J//gn/938wsM8hTvm4I1SuDCtXBuNOzmV+4fSDr0niuRvSOhDnMouFQb2+11+Hxo1h2TK46awFtiXpq6/CrbfaRRN33RXtUJ1LE8nNUTyK9RzOFZHFIS8VBH6KdGDOZTSHgqrfHTtC0aIwapRNPwAw63frWowYAQ0bRjVO59JacnMUXwDjgE5Am5Dnd6vq9ohG5VwGs2iRzUEsXAj33mulwE9dOhW6L4HHH7cifqtXQ7580Q7VuTSX3NCTqupvwOPA7pAbInJq5ENzLvoOHbIVTZdcAps3W4fhsx67OPWVx2wrum7djhbx8yThsqiUehT1gXnY8lgJeU2BcyMYl3NRl7CSaf58m4v46CMoMmssVHgYNm2yHYdef92L+Lks75iJQlXrBz9921OXrRw+bBdPd+gA//tfyN5BGzbY/MMFF9gFdDVqRDtU59JFOLWeaolIgeD+fSLSRURKRT4059LfsmVWfuOVVyw5LFuq3HbWTHuxZEmYMMG6GJ4kXDYSzvLYnsBeEakEtAZ+BT6NaFTOpbPDh+3K6qpVYd06+PprGNplE0UfvMUyR0IRv7p1IXfu6AbrXDoLJ1EcVlUFGgIfq2p3bImsc1lCbKxV+X75ZRtZWrZUueOvflbEb8IEeO89L+LnsrUUiwICu0XkJeB+4HIRyQHkimxYzkXe4cO2Jelrr9lGQl9+GVwjd/sd8M03tqqpXz/bWMi5bCycRHE3cA/QXFW3BPMTnSMblnORtWKFrWiaNcu2iOjx0RGKnR4U8bvlFrj2WqvT5EX8nEt56ElVtwCfA4VFpD6wX1U/iXhkzkXAkSO2FWnlyvDLLzBkCHzdbinFbq0F/ftbo/vv90qvzoUIZ9XTXcBs4E5s3+xZInJHpANzLq2tXGlbQrzwAtx4I8QuPEijlR2QalXh119tLaxz7j/CGXpqC1ySsKudiJwGfA8Mi2RgzqWVI0fggw9syWu+fPD559C47Dzkxqa2y9A991iD006LdqjOZUjhJIocibY+3UZ4q6Wci7pVq2xbiBkzbEVTr15wxhnAhG3w118wejTU9y1XnEtOOIniOxEZDwwJHt8NjI1cSM6duCNHrAzTyy9bL+LTT+HesyYhXy2Bp56yyepffoG8eaMdqnMZXjiT2c8DvYGLg1sfVX0x0oE5d7xWr4Y6dawU0zXXQOzPO7lv2sPI1VdBz55Hi/h5knAuLMntR1EGeA84D1gCPKeqG9MrMOdSKz4ePv4Y2rSxOn2DB8P9p4xGrnoEtmyB556zAk5exM+5VElu6GkA8AkwFbgZ+Ai4LT2Cci61fv0VmjeHqVNtRVOfPlA8fgOcdztceKHVB7/kkmiH6VymlFyiKKiqfYP7K0VkfnoE5FxqxMdDjx7w4ouQKxcMHKA0KfszUvwyICjid9llXp/JuROQ3BxFXhGpIiJVRaQqkC/R4xSJyPUislJEVotIm2Ta3S4iKiIxqf0FXPa1Zg1cfTU8+SRccQUsnxhH028aILVrHS3iV6eOJwnnTlByPYrNQJeQx1tCHitwVXIHFpGcQHfgGiAOmCMio1Q1NlG7gkArYFbqQnfZVXy8LXN94QXImQ+FWcsAABqFSURBVBP6942n2eG+yNXPWwGnLl2gdu1oh+lclpHcxkV1T/DY1YHVqroGQESGYhVoYxO1ewN4B3j+BD/PZQO//QYtWsCPP9oK1379oORTt9scxFVXQd++cK5vvuhcWorkhXPFgQ0hj+OC5/4RDGGVVNUxyR1IRFqKyFwRmbt169a0j9RleKrWi6hYEebMgX69DvPd2HhKlsSq+vXtC99/70nCuQiI2hXWQbnyLthmSMlS1T6qGqOqMad5mYVsZ9066z08+ihceims/HoxLfrVRPoFay3uuw8efBBEkj+Qc+64RDJRbARKhjwuETyXoCBwETBZRH4DLgVG+YS2S6Bqy1wrVoSZM6HvxweYULMdZ9avZtnD/2hwLl2kWMJDRAS4FzhXVV8P9qM4Q1Vnp/DWOUAZESmNJYhG2L4WAKjqTqBoyOdMxi7qm5vq38JlOevXWydh4kRb2fTJk3M46+Wmth3d/fdD165QpEi0w3QuWwinR9EDqAk0Dh7vxlYzJUtVDwNPAOOB5cBXqrpMRF4XkQbHGa/L4lRtgvqii6yQX8+elizOyrcD9uyBsWPhk088STiXjsIpClhDVauKyAIAVd0hImEtTFfVsSQqIKiqrx2jbZ1wjumyrrg460WMHw9168LnLX7kzD+XgLSySYpVq7z8hnNREE6P4lBwTYTCP/tRxEc0KpetqMLAgVChAkybBn07/8UP5z7EmfddDb17Hy3i50nCuagIJ1F0A74FionIm8B04K2IRuWyjY0bbTuI5s2hShX4tctIHuxSHhk4wK6omzfPE4RzUZbi0JOqfi4i84CrAQFuUdXlEY/MZWmqNtXQqhUcOmR7Rzx+83pylL0TypWDUaMgxhfAOZcRhLPqqRSwFxgd+pyqro9kYC7r2rQJWraEMWPg8trKkMenU7zR5UApu2ju0ku9PpNzGUg4k9ljsPkJAfICpYGVQIUIxuWyIFX47DPbYO7AAejfbj3NZj2CNB4HZ06GK6+06n7OuQwlnKGniqGPg7Ibj0UsIpclbd4MDz9sW1TXviye4df0otj7L1r26NbNi/g5l4Gl+spsVZ0P1IhALC4LUoXPP7cVTRMnWmHXqUVvo1iHx6FmTVi61OqE58wZ7VCdc8cQzhzFsyEPcwBVgU0Ri8hlGVu2wCOPwMiRUPvSw/QbkIMLyuWAM+6GWxpC06Zen8m5TCCcHkXBkFsebM6iYSSDcpmbKgwZYr2I776Dwc8uYurBGlwwpY81aNwYmjXzJOFcJpFsjyK40K6gqj6XTvG4TO73363K67ffwhXV9zO8SkeKdnsHTj0Vzjgj2uE5547DMXsUInKSqh4BaqVjPC6TUoUvv7RexNix8MkTs5m8qwpFe78J994Ly5fDLbdEO0zn3HFIrkcxG5uPWCgio4Cvgb8TXlTVbyIcm8sk/vgDHnsMhg+H6tVh0CAot3EXjN5nY0/XXRftEJ1zJyCc6yjyAtuwPbITrqdQwBOF4+uvLUns2gVDm0/gjnLLyFnuGShXD1au9PIbzmUBySWKYsGKp6UcTRAJNKJRuQxv61Z4/HFLFHUr72D4Oc/yvwGDbOzpyccsQXiScC5LSG7VU07g5OBWMOR+ws1lU8OHWz4YMQKG3fMNP2wpz/9GfwovvQRz53qCcC6LSa5HsVlVX0+3SFyG9+efdm3c0KFQrRpM+3w9F9zUyHYZGjvWyr8657Kc5BKFL3J3//j2W7t4bsd2ZXDzqTTudSW5cpWCH3+EGjUgV65oh+ici5Dkhp6uTrcoXIa1bZutbr3tNog5bR3bqt/AAwPqkGvGFGtQu7YnCeeyuGP2KFR1e3oG4jKekSOtkN/2P+MZe2MPrp/SxrqZH30El18e7fCcc+kknOWxLpvZvt02FPrsM6hcGVZeeAuFx4626yF694azz452iM65dJTq6rEuaxs92uamhw05RPvX4pk1Cwo/3BgGD4Zx4zxJOJcNeaJwAOzYAU2aQIMGcHmB+Ww7vzrtTu9lG801bgwPPOBF/JzLpjxROMaMsV7E8M/2MeWylxi6tjr5d26BkiWjHZpzLgPwRJGN/fWXVfuuXx/q5J3JnyUqc8WMt5EmTSA2Fm6+OdohOucyAJ/MzqbGjYOHHrLNhdq2hddq/U3uxw/ZNnT16kU7POdcBuKJIpvZuROefRYGDICWpb7jlSeWUbJja+BqWLECm5RwzrmjfOgpG5kwweYiRg3cxryLmtB7/Q2U/HEwHDxoDTxJOOeS4IkiG9i1y4aZrrtOuV2HsemU8lRd8QW88grMmeMJwjmXLB96yuImToQWLWDjRuj0yHpe7H8PcvHF0H8CVKoU7fCcc5mA9yiyqN27rfzGtdcqV/EjM2ZAm55nI5Mnw8yZniScc2HzHkUW9MMP1ovIuX4tK89uSdl138P+ycCVcNll0Q7POZfJeI8iC9m9Gx59FK6td4SH9n7IqjwXUXb7LOjZ04v4OeeOm/cosohJk6B5c1i3Dpae25Dya8bAjTdCr15+hbVz7oR4osjk9uyBNm2gd/dDnHt+TqZNy0H5uPvhcGO45x6vz+ScO2ERTRQicj3wIbb/dj9VfTvR688CDwKHga1Ac1VdF8mYspIpU6wER5G1c1lXtAVFH2tJ7lqPA3dHOzTnXBYSsTkKEckJdAduAMoDjUWkfKJmC4AYVb0YGAa8G6l4spK//4annoLr6+yjzY4XmZ2jBmfl2kruMl4C3DmX9iI5mV0dWK2qa1T1IDAUaBjaQFUnqere4OFMoEQE48kSpk61la1zPvqZdadUouVf7yLNm1sRv/r1ox2ecy4LimSiKA5sCHkcFzx3LC2AcUm9ICItRWSuiMzdunVrGoaYeezdC08/DXXqgCr06rKPYkXi4fvvoW9fOOWUaIfonMuiMsRktojcB8QAVyb1uqr2AfoAxMTEaDqGliFMn25zEWVWj+Wby5ZxzYTnKVDgKnhiOeTKFe3wnHNZXCR7FBuB0HWZJYLn/kVE6gFtgQaqeiCC8WQ6e/dapddbL/+TzpvvYyw3ccvfn1MgV1DEz5OEcy4dRDJRzAHKiEhpEckNNAJGhTYQkSpAbyxJ/BHBWDKdGTOgciVlU9ehrMlbjoYHv4J27WD2bC/i55xLVxFLFKp6GHgCGA8sB75S1WUi8rqINAiadQZOBr4WkYUiMuoYh8s29u2D556D2rXhtH3r+SJXEwpWLI3Mmwft23uScM6lO1HNXEP+MTExOnfu3GiHEREzZ0LTJkqJVT9Q5pF6vPsuFFw2Ey65BHLmjHZ4zrlMTETmqWrM8bw3Q0xmZ3f798Nrr8G37/3K4NwPcRmToNFkKHglXHpptMNzzmVzXhQwymbNgmqVj3C4cxeW5ahIzTzzoHdvL+LnnMswvEcRJfv325RD584wMffNXMU4uKG+VXot4dcdOucyDk8UUTBnDjzU5CCLl59EiwdzcGmtppDnfmjUyIv4OecyHE8U6ejAAXj9dfjx7dkMzdGC+EcfpnyPJ4C7oh2ac84dk89RpJN586B21b2c+lZrftKalC22g/I3nxftsJxzLkXeo4iwgwfhjTdg6lvT+VqacA5roOXD8M47ULhwtMNzzrkUeaKIoPnzoWlTWLIE3r7uECVX54R+k6yyn3POZRKeKCLg4EF4801Y1HE0dxVYTqf/e4GbbqoLh2PhJD/lzrnMxeco0tjChXBd1a1c8Po9jIhvQJtzhnDTNUERP08SzrlMyBNFGjl0CDq0V96v9gXDY8vR6KRh8PrrnDR3ltdncs5lav4nbhpYtMjmIrYvXM/qHM2QqlXIMbg/VKgQ7dCcc+6EeaI4AYcOwdtvxTPzjYlsLnodvUecTa4zp0G1al7EzzmXZfjQ03FasgTurPwLl7e/ijFHrmdl36k0bAhUr+5JwjmXpXiPIpUOH4Z33zrMrg5dGRL/Gjnz54GP+lO4vhfxc85lTZ4oUmHpUpuL6DivPtczngM3NCR3vx5w1lnRDs25DOnQoUPExcWxf//+aIeSbeTNm5cSJUqQKw23SvZEEYbDh6FLpwO89kYuCp2Sg8LPPgg1mpPnzju9iJ9zyYiLi6NgwYKcc845iP+/EnGqyrZt24iLi6N06dJpdlxPFCmIjYX37phJ6+UtKFr5EW6e8CSnnXZHtMNyLlPYv3+/J4l0JCIUKVKErVu3pulxPVEcw+HD0K3T35zU/hX6xX/IviIlqNCpDJwW7cicy1w8SaSvSJxvTxRJWLECut42jReXN+Fc1rK32WMU+KATFCoU7dCccy7d+fLYEEeO2I5zlSvDlrjDFD0zFzp5CvkHdPck4VwmNmLECESEFStW/PPc5MmTqV+//r/aNW3alGHDhgE2Ed+mTRvKlClD1apVqVmzJuPGjTvhWDp16sT555/PBRdcwPjx45Ns07RpU0qXLk3lypWpXLkyCxcuBGDFihXUrFmTPHny8N57751wLOHyHkVg5UoY2HAEsnI5N976Ej171qVQkWVen8m5LGDIkCHUrl2bIUOG0KFDh7De8+qrr7J582aWLl1Knjx5+P3335kyZcoJxREbG8vQoUNZtmwZmzZtol69eqxatYqcSVx71blzZ+6449/zoaeeeirdunVjxIgRJxRHamX7b8EjR6DPG79T7I0neTv+a7afU5X/DWmN5MmNnx7n0s7TT1vRzLRUuTJ88EHybfbs2cP06dOZNGkSN998c1iJYu/evfTt25e1a9eSJ08eAE4//XTuuuvEdqMcOXIkjRo1Ik+ePJQuXZrzzz+f2bNnU7NmzbDeX6xYMYoVK8aYMWNOKI7UytZDT6tWKm9e+Cl3dShPA0ayu82bnLpqZpAknHNZwciRI7n++uspW7YsRYoUYd68eSm+Z/Xq1ZQqVYpCYQw5P/PMM/8MEYXe3n777f+03bhxIyVLlvzncYkSJdi4cWOSx23bti0XX3wxzzzzDAcOHEgxjkjKln8yHzkC3bpBr5fWs/jAg+wsE8NJI/tTsNyF0Q7NuSwrpb/8I2XIkCG0atUKgEaNGjFkyBCqVat2zNVBqV011LVr1xOOMbFOnTpxxhlncPDgQVq2bMk777zDa6+9luafE65slyhWr4qn163jeT/2BurXP5tdj/1EsWureH0m57Kg7du38+OPP7JkyRJEhCNHjiAidO7cmSJFirBjx47/tC9atCjnn38+69evZ9euXSn2Kp555hkmTZr0n+cbNWpEmzZt/vVc8eLF2bBhwz+P4+LiKF68+H/ee+aZZwKQJ08emjVrlq4T10nJNkNP8fEwuO0qtpSrw3uxN/LdS1MYNQpOuyHGk4RzWdSwYcO4//77WbduHb/99hsbNmygdOnSTJs2jTJlyrBp0yaWL18OwLp161i0aBGVK1cmf/78tGjRglatWnHwoG08tnXrVr7++uv/fEbXrl1ZuHDhf26JkwRAgwYNGDp0KAcOHGDt2rX88ssvVK9e/T/tNm/eDNiV1iNGjOCiiy5Ky9OSeqqaqW7VqlXT1Fq94pD2LP227iOP7j7pFN3eZaBqfHyqj+OcS53Y2Niofn6dOnV03Lhx/3ruww8/1EceeURVVadPn641atTQSpUqaUxMjE6YMOGfdgcOHNDnn39ezzvvPK1QoYJWr15dv/vuuxOOqWPHjnruuedq2bJldezYsf88f8MNN+jGjRtVVbVu3bp60UUXaYUKFfTee+/V3bt3q6rq5s2btXjx4lqwYEEtXLiwFi9eXHfu3Pmfz0jqvANz9Ti/d8Xen3nExMTo3Llzw2obHw/du0O5p6+jXvwEfqt2G2eP7o6ceUaEo3TOASxfvpxy5cpFO4xsJ6nzLiLzVDXmeI6XZYee1i7fT726R3jqKZh5cUu29R7GOXOHe5JwzrlUynKJIj4evmn9E4cqVCZmVnf694e282+nSMvbox2ac85lSllq1dO6ZXuYd93L3LLxY/7IW4rn+pWj2L3Rjsq57E1VvTBgOorEdEKW6FGowshnp0DFi7hl48csv+oJTv9jKcXuvSbaoTmXreXNm5dt27ZF5MvL/ZcG+1HkzZs3TY+b6XsU69ZBixZw6Af4pEB+/hg8jQq314p2WM457MrjuLi4NN8fwR1bwg53aSnTJgpVmPjoN/w8cAWzcr/M+72vpFTzJchJfk2EcxlFrly50nSnNRcdER16EpHrRWSliKwWkf9cfSIieUTky+D1WSJyTjjHjZu7heln3MG1vW+nUZ5vWTLvIC1b4knCOeciIGKJQkRyAt2BG4DyQGMRKZ+oWQtgh6qeD3QF3knpuHt+20aBS8pxyR//x8xbOlH2zxmcU9aL+DnnXKREskdRHVitqmtU9SAwFGiYqE1DYHBwfxhwtaSwPKLAtnVsKHwRf36/iEu/bYPkzpXmgTvnnDsqknMUxYENIY/jgBrHaqOqh0VkJ1AE+DO0kYi0BFoGDw9U2jl9KfW80itQlETnKhvzc3GUn4uj/FwcdcHxvjFTTGarah+gD4CIzD3ey9CzGj8XR/m5OMrPxVF+Lo4SkfBqHyUhkkNPG4GSIY9LBM8l2UZETgIKA9siGJNzzrlUimSimAOUEZHSIpIbaASMStRmFNAkuH8H8KP6lTnOOZehRGzoKZhzeAIYD+QEBqjqMhF5HSt3OwroD3wqIquB7VgySUmfSMWcCfm5OMrPxVF+Lo7yc3HUcZ+LTFdm3DnnXPrKErWenHPORY4nCuecc8nKsIkiUuU/MqMwzsWzIhIrIotF5AcROTsacaaHlM5FSLvbRURFJMsujQznXIjIXcG/jWUi8kV6x5hewvh/pJSITBKRBcH/JzdGI85IE5EBIvKHiCw9xusiIt2C87RYRKqGdeDj3UM1kjds8vtX4FwgN7AIKJ+ozWNAr+B+I+DLaMcdxXNRF8gf3H80O5+LoF1BYCowE4iJdtxR/HdRBlgA/C94XCzacUfxXPQBHg3ulwd+i3bcEToXVwBVgaXHeP1GYBwgwKXArHCOm1F7FBEp/5FJpXguVHWSqu4NHs7ErlnJisL5dwHwBlY3bH96BpfOwjkXDwHdVXUHgKr+kc4xppdwzoUChYL7hYFN6RhfulHVqdgK0mNpCHyiZiZwioicmdJxM2qiSKr8R/FjtVHVw0BC+Y+sJpxzEaoF9hdDVpTiuQi60iVVdUx6BhYF4fy7KAuUFZGfRGSmiFyfbtGlr3DORXvgPhGJA8YCT6ZPaBlOar9PgExSwsOFR0TuA2KAK6MdSzSISA6gC9A0yqFkFCdhw091sF7mVBGpqKp/RTWq6GgMDFLV90WkJnb91kWqGh/twDKDjNqj8PIfR4VzLhCRekBboIGqHkin2NJbSueiIHARMFlEfsPGYEdl0QntcP5dxAGjVPWQqq4FVmGJI6sJ51y0AL4CUNWfgbxYwcDsJqzvk8QyaqLw8h9HpXguRKQK0BtLEll1HBpSOBequlNVi6rqOap6DjZf00BVj7sYWgYWzv8jI7DeBCJSFBuKWpOeQaaTcM7FeuBqABEphyWK7Lg/6yjggWD106XATlXdnNKbMuTQk0au/EemE+a56AycDHwdzOevV9UGUQs6QsI8F9lCmOdiPHCtiMQCR4DnVTXL9brDPBetgb4i8gw2sd00K/5hKSJDsD8OigbzMe2AXACq2gubn7kRWA3sBZqFddwseK6cc86loYw69OSccy6D8EThnHMuWZ4onHPOJcsThXPOuWR5onDOOZcsTxQuQxKRIyKyMOR2TjJt96TB5w0SkbXBZ80Prt5N7TH6iUj54P7LiV6bcaIxBsdJOC9LRWS0iJySQvvKWbVSqks/vjzWZUgiskdVT07rtskcYxDwf6o6TESuBd5T1YtP4HgnHFNKxxWRwcAqVX0zmfZNsQq6T6R1LC778B6FyxRE5ORgr435IrJERP5TNVZEzhSRqSF/cV8ePH+tiPwcvPdrEUnpC3wqcH7w3meDYy0VkaeD5wqIyBgRWRQ8f3fw/GQRiRGRt4F8QRyfB6/tCX4OFZGbQmIeJCJ3iEhOEeksInOCfQIeDuO0/ExQ0E1Eqge/4wIRmSEiFwRXKb8O3B3EcncQ+wARmR20Tar6rnP/Fu366X7zW1I37ErihcHtW6yKQKHgtaLYlaUJPeI9wc/WQNvgfk6s9lNR7Iu/QPD8i8BrSXzeIOCO4P6dwCygGrAEKIBd+b4MqALcDvQNeW/h4Odkgv0vEmIKaZMQ463A4OB+bqySZz6gJfBK8HweYC5QOok494T8fl8D1wePCwEnBffrAcOD+02Bj0Pe/xZwX3D/FKz+U4Fo//f2W8a+ZcgSHs4B+1S1csIDEckFvCUiVwDx2F/SpwNbQt4zBxgQtB2hqgtF5Epso5qfgvImubG/xJPSWURewWoAtcBqA32rqn8HMXwDXA58B7wvIu9gw1XTUvF7jQM+FJE8wPXAVFXdFwx3XSwidwTtCmMF/NYmen8+EVkY/P7LgYkh7QeLSBmsREWuY3z+tUADEXkueJwXKBUcy7kkeaJwmcW9wGlANVU9JFYdNm9oA1WdGiSSm4BBItIF2AFMVNXGYXzG86o6LOGBiFydVCNVXSW278WNQEcR+UFVXw/nl1DV/SIyGbgOuBvbZAdsx7EnVXV8CofYp6qVRSQ/VtvocaAbtlnTJFW9NZj4n3yM9wtwu6quDCde58DnKFzmURj4I0gSdYH/7Asutlf476raF+iHbQk5E6glIglzDgVEpGyYnzkNuEVE8otIAWzYaJqInAXsVdXPsIKMSe07fCjo2STlS6wYW0LvBOxL/9GE94hI2eAzk6S2o+FTQGs5WmY/oVx005Cmu7EhuATjgScl6F6JVR52LlmeKFxm8TkQIyJLgAeAFUm0qQMsEpEF2F/rH6rqVuyLc4iILMaGnS4M5wNVdT42dzEbm7Pop6oLgIrA7GAIqB3QMYm39wEWJ0xmJzIB21zqe7WtO8ESWywwX0SWYmXjk+3xB7EsxjbleRfoFPzuoe+bBJRPmMzGeh65gtiWBY+dS5Yvj3XOOZcs71E455xLlicK55xzyfJE4ZxzLlmeKJxzziXLE4VzzrlkeaJwzjmXLE8UzjnnkvX/LkgptAMC+toAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSLYMOWPmjov"
      },
      "source": [
        "##### Feature importance for random forest\n",
        "\n",
        "To what degree did each column [feature] contribute to the final output? Let me check feature importance [from [here](https://machinelearningmastery.com/calculate-feature-importance-with-python/)]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "pCGal9mm0TYY",
        "outputId": "8a7ec3de-6acb-499e-b9e0-f770bcccdd82"
      },
      "source": [
        "# get feature importance for random forest\n",
        "importance = randomforest.feature_importances_\n",
        "\n",
        "# visualize results w bar plot\n",
        "plt.bar([x for x in range(len(importance))], importance)\n",
        "plt.title(\"Feature importance for random forest\")\n",
        "plt.xlabel(\"Feature\")\n",
        "plt.ylabel(\"Relative importance\")\n",
        "plt.show()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5gdVZnv8e+PhLsJ4RI5mAAdIOoJzKjYIqgzckAleAuj8QjHC/ig6AiCdxMVRQYO4jiicwAVuYjICBhRI6CoBPA4o4GOKBow2gKaRNRwCzclNLzzx1oNOzu7u6u6d/W+/T7P00/vqrWq9ltr713vrlpVaysiMDMzK2qzVgdgZmadxYnDzMxKceIwM7NSnDjMzKwUJw4zMyvFicPMzEpx4rCWkvRhSee2Oo52JukZkn4u6QFJx7c6nrFI6pMUkqZOwnN1VNt0C/k+js4l6Q5gZ+CxmtlPj4g/TnCdb42IH04sus4j6SRgr4h4Y6tjqSXpPOD+iHhPq2MpQlIfcDuweUQMVfxcLWmbXv6cgI84usGrIuIpNX/jThrNMBnfMqvQ5nHvDqwcz4JFtqvNt30slbaNjSAi/Nehf8AdwEsazN8OOA+4E1gLnAJMyWV7AsuAu4G7gIuBGbnsIuBx4K/Ag8AHgQOBNSM9L3ASsAT4KnA/8NbRnr9BrCcBX82P+4AA3gKsBu4F3gE8D7gZuA84s2bZo4D/BM4E1gO/Bg6uKX8asBS4BxgE3lb3vLVxHwdsAB7N2/6LXO8twK3AA8BtwNtr1nEgsAZ4H/CXvL1vqSnfGvg34Pc5vh8DW+ey/YH/ytv0C+DAEdpnGemI8m85rqfn9v0KsC6v+6PAZnVtckZ+jU8Zoc3rX7P9gJ/keO7MbbpFzTKRX4vf5jpn8eQZiynAp0nvp9uAY3P9qQVfh6/nWB4Afpm3cXFu09XAy6pqG2DLHPsfgD8DX6h5jXYCrsjbew/w/0lftjf5nLR6XzDp+55WB+C/Cbx4IyeObwJfBLYFngrcQN7hAXsBL80fmJnAj4DPjrROiiWOR4HD8odq69Gev0GsJ7Fp4vgCsBXwsrxT+FZez6y8M3lxrn8UMAS8B9gceD1pB71DLv8RcHZe17PzzuSgUeJ+Ipaa+F5BSrYCXgw8DOxb0zZDwMn5+V+ey7fP5WcB1+W4pwAvyO0+i7Tjenl+7pfm6ZkjtNF1pNMiw9NfAb4NTMtt9hvg6Lo2eRcwlbwTbNDm9dv+XFIym5rXeSvw7pplgrQTnQHslttyfi57Bylp7wrsAFzLxoljrNfhb8Ah+bm/QjrN9ZHcpm8Dbh/lMzChtiElkaU57mnAd4DTcv3TSO/FzfPfP/BksryDBp+9XvlreQD+m8CLl968D5K+Ed1H2sHuDDxSu8MAjgCuHWEdhwE31a2zbOL4UU1Z2ec/iU0Tx6ya8ruB19dMf2N4h5Z3BH8c/jDneTcAb8o7sceAaTVlpwFfbhR3fSyjtPm3gBNq2uav5B1knvcX0g54s1z2rAbr+BBwUd28q4EjR3jO68g7R1IC2gDMqyl/O3BdTZv8YYxt2GTbG9R5N/DNmukAXlQzfRmwKD9eBryjpuxluf7Ugq/DD2rKXkV6Tw8fIU/L65rR7LYhfRl4CNizZt4B5ERF+kLwbVK/V6PPXs8mDp/j63yHRU0HnaT9SN+O7pQ0PHsz0iE/knYGPkf69jQtl907wRhW1zzefbTnL+jPNY//2mD6KTXTayN/krPfk06NPA24JyIeqCvrHyHuhiQdCnycdBpkM2Ab0umUYXfHxh3AD+f4diJ9w/5dg9XuDrxO0qtq5m1O+qY+lp1y3d/XzPs96ShmWJG23qiOpKcDnyG1zzaknf6KumX+VPN4eDshtXXt+mpjK/I61L++d0XEYzXT5Oe6b5TtgfJtM5O0rStq3qsiJSCAfyUltu/n8nMi4pNjxNAT3DnefVaTvvHvFBEz8t/0iNg7l/9f0je4v4uI6cAbSR+WYfWX2T1E+nABIGkK6QNXq3aZsZ6/2Wap5lNPOo3yx/y3g6RpdWVrR4h7k2lJW5KOcD4N7BwRM4Cr2Li9RnIX6RTMng3KVpOOOGbU/G1bcKd0F+k00+4188barkbq63yedLppbn5ffJhi2wmpT2TXuniGFXkdmqVs29xFSkx717wO20XEUwAi4oGIeF9E7AG8GnivpIMbrKfnOHF0mYi4E/g+8G+SpkvaTNKekl6cq0wjnQpYL2kW8IG6VfwZ2KNm+jfAVpJeIWlzUmfjlhN4/mZ7KnC8pM0lvQ74n8BVEbGa1Pl8mqStJP09cDSpE3Ykfwb6JA1/LrYgbes6YCgffbysSFAR8ThwPvAZSU+TNEXSATkZfRV4laRD8vytJB0oaXaB9T5GOk10qqRpknYH3jvGdhUxjdRR/qCkZwL/XGLZy0ivwWxJ2wOLauIdz+swLmXbJr9GXwLOkPRUAEmzJB2SH79S0l75i8l60im3x/Pi9Z+TnuLE0Z3eTNrp3UI6DbUE2CWXfQLYl/RBuBK4vG7Z04CPSrpP0vsjYj3wTuBc0je3h0hXEo33+ZttOTCX9O3xVGBhRNydy44g9Zv8kdRh//EY/br7r+f/d0v6WT69cjxpZ3Qv8H9IHalFvZ90WutG0lU5p5Ou8FkNLCB9q19HOgL5AMU/j+8ivQ63ka7U+g9SkpqI95O27wHSzvTSEst+idRH8wvgZ2z6nir7OkxE2bb5EOlKr59Kuh/4IfCMXDY3Tz9IuuLs7IgYPp240eek6VvR5nwDoHUsSUeROkZf1OpYzHqJjzjMzKwUJw4zMyvFp6rMzKwUH3GYmVkpPXED4E477RR9fX2tDsPMrGOsWLHiroiov2cL6JHE0dfXx8DAQKvDMDPrGJJ+P1KZT1WZmVkpThxmZlaKE4eZmZXixGFmZqU4cZiZWSlOHGZmVooTh5mZleLEYWZmpThxmJlZKU4cZmZWihOHmZmV4sRhZmalOHGYmVkpThxmZlaKE4eZmZXixGFmZqU4cZiZWSlOHGZmVooTh5mZleLEYWZmpThxmJlZKU4cZmZWihOHmZmVUmnikDRf0ipJg5IWNSjfUtKluXy5pL48f0dJ10p6UNKZdcs8V9Iv8zL/LklVboOZmW2sssQhaQpwFnAoMA84QtK8umpHA/dGxF7AGcDpef7fgBOB9zdY9eeBtwFz89/85kdvZmYjqfKIYz9gMCJui4gNwCXAgro6C4AL8+MlwMGSFBEPRcSPSQnkCZJ2AaZHxE8jIoCvAIdVuA1mZlanysQxC1hdM70mz2tYJyKGgPXAjmOsc80Y6wRA0jGSBiQNrFu3rmToZmY2kq7tHI+IcyKiPyL6Z86c2epwzMy6RpWJYy2wa8307DyvYR1JU4HtgLvHWOfsMdZpZmYVqjJx3AjMlTRH0hbA4cDSujpLgSPz44XAstx30VBE3AncL2n/fDXVm4FvNz90MzMbydSqVhwRQ5KOA64GpgDnR8RKSScDAxGxFDgPuEjSIHAPKbkAIOkOYDqwhaTDgJdFxC3AO4EvA1sD381/ZmY2STTKF/yu0d/fHwMDA60Ow8ysY0haERH9jcq6tnPczMyq4cRhZmalOHGYmVkpThxmZlaKE4eZmZXixGFmZqU4cZiZWSlOHGZmVooTh5mZleLEYWZmpThxmJlZKU4cZmZWihOHmZmV4sRhZmalOHGYmVkpThxmZlaKE4eZmZXixGFmZqU4cZiZWSlOHGZmVooTh5mZleLEYWZmpThxmJlZKU4cZmZWihOHmZmV4sRhZmalOHGYmVkpYyYOSdtIOlHSl/L0XEmvrD40MzNrR0WOOC4AHgEOyNNrgVMqi8jMzNpakcSxZ0R8CngUICIeBlRk5ZLmS1olaVDSogblW0q6NJcvl9RXU7Y4z18l6ZCa+e+RtFLSryR9TdJWRWIxM7PmKJI4NkjaGggASXuSjkBGJWkKcBZwKDAPOELSvLpqRwP3RsRewBnA6XnZecDhwN7AfOBsSVMkzQKOB/ojYh9gSq5nZmaTpEji+DjwPWBXSRcD1wAfLLDcfsBgRNwWERuAS4AFdXUWABfmx0uAgyUpz78kIh6JiNuBwbw+gKnA1pKmAtsAfywQi5mZNcmYiSMifgC8BjgK+Brp2/51BdY9C1hdM70mz2tYJyKGgPXAjiMtGxFrgU8DfwDuBNZHxPcbPbmkYyQNSBpYt25dgXDNzKyIIldV/RMwFBFXRsQVwJCkw6oPrWEs25OORuYATwO2lfTGRnUj4pyI6I+I/pkzZ05mmGZmXa3QqaqIWD88ERH3kU5fjWUtsGvN9Ow8r2GdfOppO+DuUZZ9CXB7RKyLiEeBy4EXFIjFzMyapEjiaFRnaoHlbgTmSpojaQtSJ/bSujpLgSPz44XAsoiIPP/wfNXVHGAucAPpFNX++d4SAQcDtxaIxczMmqRIAhiQ9BnSFVIAxwIrxlooIoYkHQdcTbr66fyIWCnpZGAgIpYC5wEXSRoE7iFfIZXrXQbcAgwBx0bEY8BySUuAn+X5NwHnFN9cMzObKKUv+KNUkLYFTiSdJgL4AXBKRDxUcWxN09/fHwMDA60Ow8ysY0haERH9jcrGPOLICWKTm/fMzKw3jZk4JD0deD/QV1s/Ig6qLiwzM2tXRfo4vg58ATgXeKzacMzMrN0VSRxDEfH5yiMxM7OOUORy3O9IeqekXSTtMPxXeWRmZtaWihxxDN9n8YGaeQHs0fxwzMys3RW5qmrOZARiZmadocgRB5L2IQ2N/sRvX0TEV6oKyszM2leRy3E/DhxIShxXkX5f48eAE4eZWQ8q0jm+kDQm1J8i4i3As0iDEZqZWQ8qkjj+GhGPk4ZTnw78hY1HrjUzsx5SdJDDGcCXSIMbPgj8pNKozMysbRW5quqd+eEXJH0PmB4RN1cblpmZtasivwB4zfDjiLgjIm6unWdmZr1lxCMOSVsB2wA75Z9sVS6azqa/HW5mZj1itFNVbwfeTfpt7xU8mTjuB86sOC4zM2tTIyaOiPicpDOBD0fEv0xiTGZm1sZG7ePIP9f6mkmKxczMOkCR+ziukfRaSRq7qpmZdbsiiePtpB9z2iDpfkkPSLq/4rjMzKxNFbmPY9pkBGJmZp2h6Oi4rwb+MU9eFxFXVBeSmZm1syI3AH4SOAG4Jf+dIOm0qgMzM7P2VOSI4+XAs/NAh0i6ELgJWFxlYGZm1p6KdI4DzKh57CHVzcx6WJEjjtOAmyRdS7p7/B+BRZVGZWZmbavIVVVfk3Qd8DwggA9FxJ+qDszMzNpToauqgAOAF5ESx1Tgm5VFZGZmba3IVVVnA+8Afgn8Cni7pLOqDszMzNpTkc7xg4BDIuKCiLiAdJXVQUVWLmm+pFWSBiVt0i8iaUtJl+by5ZL6asoW5/mrJB1SM3+GpCWSfi3pVkkHFInFzMyao0jiGAR2q5neNc8blaQpwFnAocA84AhJ8+qqHQ3cGxF7AWcAp+dl5wGHA3sD84Gz8/oAPgd8LyKeCTwLuLXANpiZWZMUSRzTgFslXZc7yW8BpktaKmnpKMvtBwxGxG0RsQG4BFhQV2cBcGF+vAQ4OA+muAC4JCIeiYjbSYlqP0nbka7qOg8gIjZExH2FttTMzJqiSOf4x8a57lnA6prpNcDzR6oTEUOS1gM75vk/rVt2FvBXYB1wgaRnkX5g6oSIeKj+ySUdAxwDsNtuu9UXm5nZOBW5HPd6AEnTa+tHxD0VxjWSqcC+wLsiYrmkz5HuKTmxvmJEnAOcA9Df3x+TGqWZWRcrclXVMZL+BNwMDJC+5Q8UWPdaUn/IsNl5XsM6kqaS7kq/e5Rl1wBrImJ5nr+ElEjMzGySFOnj+ACwT0T0RcQeETEnIvYosNyNwFxJcyRtQersru8TWQocmR8vBJZFROT5h+erruYAc4Eb8o2HqyU9Iy9zMKnPxczMJkmRPo7fAQ+XXXHuszgOuBqYApwfESslnQwMRMRSUif3RZIGgXtIyYVc7zJSUhgCjs0/YwvwLuDinIxuA95SNjYzMxs/pS/4o1SQngNcACwHHhmeHxHHVxta8/T398fAQJGza2ZmBiBpRUT0NyorcsTxRWAZ6c7xx5sZmJmZdZ4iiWPziHhv5ZGYmVlHKNI5/t18ZdUuknYY/qs8MjMza0tFjjiOyP9rf/EvgCJXVpmZWZcpcgPgnMkIxMzMOsOIiUPSQRGxTNJrGpVHxOXVhWVmZu1qtCOOF5OupnpVg7IAnDjMzHrQiIkjIj6e//sGOzMze0KRq6rMzMye4MRhZmalOHGYmVkpRYZV30bSiZK+lKfnSnpl9aGZmVk7KnLEcQFpcMMD8vRa4JTKIjIzs7ZWJHHsGRGfAh4FiIiHAVUalZmZta0iiWODpK1J924gaU9qhlc3M7PeUmSsqpOA7wG7SroYeCFwVIUxmZlZGysyVtX3Ja0A9iedojohIu6qPDIzM2tLYyYOSd8B/gNYGhEPVR+SmZm1syJ9HJ8G/gG4RdISSQslbVVxXGZm1qaKnKq6Hrhe0hTgIOBtwPnA9IpjMzOzNlSkc5x8VdWrgNcD+wIXVhmUmZm1ryJ9HJcB+5GurDoTuD4iHq86MDMza09F+jjOI90E+I6IuNZJw6w6fYuubHUIZmMa8xcAgW2BBdLGN4v7FwDNzHqTfwHQzMxKGfMXAIGTI+L22jJJcyqNyszM2laRPo5vNJi3pNmBmJlZZxgxcUh6pqTXAttJek3N31GAbwA0a5HROtDduW6TYbQ+jmcArwRmsHE/xwOkmwDNzKwHjdbH8W3g25IOiIifjGflkuYDnwOmAOdGxCfryrcEvgI8F7gbeH1E3JHLFgNHA48Bx0fE1TXLTQEGgLUR4V8jNDObREX6OG6SdKyksyWdP/w31kJ5534WcCgwDzhC0ry6akcD90bEXsAZwOl52XnA4cDewHzg7Ly+YScAtxaI3TqIT7OYdYYiieMi4H8AhwDXA7NJp6vGsh8wGBG3RcQG4BJgQV2dBTw5fMkS4GClG0YWAJdExCP5iq7BvD4kzQZeAZxbIAYzM2uyIoljr4g4EXgoIi4k7bSfX2C5WcDqmuk1eV7DOhExBKwHdhxj2c8CHwRGvYNd0jGSBiQNrFu3rkC4ZmZWRJHE8Wj+f5+kfYDtgKdWF9LIJL0S+EtErBirbkScExH9EdE/c+bMSYjOzKw3FEkc50jaHjgRWArcAnyqwHJrgV1rpmfneQ3rSJpKSkp3j7LsC4FXS7qDdOrrIElfLRCLmZk1yZiJIyLOjYh7I+L6iNgjIp4aEV8osO4bgbmS5kjagtTZvbSuzlLgyPx4IbAsIiLPP1zSlvku9bnADRGxOCJmR0RfXt+yiHhjoS01M7OmGG2Qw/eOtmBEfGaM8iFJxwFXky7HPT8iVko6GRiIiKWkkXcvkjQI3ENKBuR6l5GOboaAYyPisRLbZWZmFRntBsBpE115RFwFXFU372M1j/8GvG6EZU8FTh1l3dcB1000RjMzK2e0GwA/MZmBmJlZZxizj0PS0yVdI+lXefrvJX20+tDMzKwdFbmq6kvAYvJluRFxM7kvwszMek+RxLFNRNxQN2+oimDMzKz9FUkcd0nak/Srf0haCNxZaVRmZta2RruqatixwDnAMyWtBW4H3lBpVGZm1rbGTBwRcRvwEknbko5QHib1cfy+4tjMzKwNjfYLgNMlLZZ0pqSXkhLGkaSRav/3ZAVoZmbtZbQjjouAe4GfkH7x7yOAgH+KiJ9PQmxmZtaGRksce0TE3wFIOpfUIb5bvtvbJqBv0ZXc8clXtDoMM7NxGe2qquHh1MnjRK1x0jAzs9GOOJ4l6f78WMDWeVpARMT0yqMzM7O2M9pYVVNGKjMzs95V5AZAs1H1Lbqy1SGY2SRy4ugC3nG3ltvfeo0Th5mZleLEYTZJqjwy8VGPTSYnDut53umalePEYWZmpThxmLUJH/lYp3DimEQ+x21m3cCJw6yD+QuDtYITh43JR0o2Xn59u5MTh3W8dts5tVs8Zs3mxGFmZqU4cYyTv1WaWa9y4rCmaYdk2g4xmHU7Jw7rCU4oZs3jxGGTyjvw9uXXxoqqNHFImi9plaRBSYsalG8p6dJcvlxSX03Z4jx/laRD8rxdJV0r6RZJKyWdUGX81jk6eafXt+jKccXfydtsna2yxCFpCnAWcCgwDzhC0ry6akcD90bEXsAZwOl52XnA4cDewHzg7Ly+IeB9ETEP2B84tsE6O14rdgjeCTWH29F6QZVHHPsBgxFxW0RsAC4BFtTVWQBcmB8vAQ6WpDz/koh4JCJuBwaB/SLizoj4GUBEPADcCsyqcBu6lndwk8vtbd2kysQxC1hdM72GTXfyT9SJiCFgPbBjkWXzaa3nAMsbPbmkYyQNSBpYt27duDfCrB351Ja1Ukd2jkt6CvAN4N0RcX+jOhFxTkT0R0T/zJkzJzfAHuCdULXcvtbOqkwca4Fda6Zn53kN60iaCmwH3D3aspI2JyWNiyPi8koit45U9c7WO3OzpMrEcSMwV9IcSVuQOruX1tVZChyZHy8ElkVE5PmH56uu5gBzgRty/8d5wK0R8ZkKY2+qbt3h1G5Xt25ju5nsdvbrao1Uljhyn8VxwNWkTuzLImKlpJMlvTpXOw/YUdIg8F5gUV52JXAZcAvwPeDYiHgMeCHwJuAgST/Pfy+vahtazR/a8SnTbu3cxvWxtXOs1lumVrnyiLgKuKpu3sdqHv8NeN0Iy54KnFo378eAmh+pWXP1LbqSOz75ilaHsYl2jcs6S0d2jrfaZHzz870cY8fj3wnZWCfGbJ3JiWMC2uFUQlXP6Z2Q+T1gI3HiaJHJ/FD6m3l76YQ28xcSG40TxwS16oPQjOcdXkenfJg7Jc7RdMM2mDlxlDTRD753HEnRduikIzO/ttYrnDhaaDyjohbtMJ7ITqzRslXsFJsxbIZ31maTz4nDRjXZV5C1S4KqWjvGZFaUE0cJVZ1eGe9OpJd2PpO1rVW8xiPV9RAp1qmcOMbQ7FM+VT6fmdlkcOIoqJt26OP9Vt0NbdDMq9Gavd521c3bZuPjxNFk7XSJa6sHIWz18zfrecf7067WmNuy8zlxdKF2+GC2Qwz12jEms07kxGGTplN23K2Os9XPbzYWJ44O0Mk7kk4/zdPJsbczt2tnc+LoQP7QNZ/btDXc7p3JiaNiHsaimF7ZzsnWa1eA2eRw4jAzs1KcOMysrfiIqP05cXS5Vv6KXrM0O8ZO2OaJmOgFCd3ePjZxThxm1jROOr3BicOsBO8Yn9TKtvDr0FpOHGbWtpwg2pMTh5mZleLEYWYTMtm/J+OjkNZz4jCzJ/TqTrlXt3u8nDjMOkBVO7Z23mF2w6Xk3cqJw8x6jodimRgnDrMe1KwbBFv1e+pltFMs3cKJw8xKK7Mz7vQddy9ta1GVJg5J8yWtkjQoaVGD8i0lXZrLl0vqqylbnOevknRI0XWaWXWK7Bgnc4iYiRzxlI2zfiiXZo983UlJp7LEIWkKcBZwKDAPOELSvLpqRwP3RsRewBnA6XnZecDhwN7AfOBsSVMKrtPMCqh6R9XM9Y8neTTTRDrqOykhFFXlEcd+wGBE3BYRG4BLgAV1dRYAF+bHS4CDJSnPvyQiHomI24HBvL4i6zSzClS5A2zGusfzDX6sASEn2ofTzCOUdqKIqGbF0kJgfkS8NU+/CXh+RBxXU+dXuc6aPP074PnAScBPI+Kref55wHfzYqOus2bdxwDH5MlnAKvGuSk7AXeNc9lu5TZpzO2yKbdJY53QLrtHxMxGBVMnO5LJEhHnAOdMdD2SBiKivwkhdQ23SWNul025TRrr9Hap8lTVWmDXmunZeV7DOpKmAtsBd4+ybJF1mplZhapMHDcCcyXNkbQFqbN7aV2dpcCR+fFCYFmkc2dLgcPzVVdzgLnADQXXaWZmFarsVFVEDEk6DrgamAKcHxErJZ0MDETEUuA84CJJg8A9pERArncZcAswBBwbEY8BNFpnVduQTfh0VxdymzTmdtmU26Sxjm6XyjrHzcysO/nOcTMzK8WJw8zMSnHiGEEvD20iaVdJ10q6RdJKSSfk+TtI+oGk3+b/2+f5kvTvua1ulrRva7egOnkEg5skXZGn5+Thcgbz8Dlb5PkjDqfTbSTNkLRE0q8l3SrpgF5/r0h6T/7s/ErS1yRt1U3vFSeOBjy0CUPA+yJiHrA/cGze/kXANRExF7gmT0Nqp7n57xjg85Mf8qQ5Abi1Zvp04Iw8bM69pGF0YIThdLrU54DvRcQzgWeR2qdn3yuSZgHHA/0RsQ/pQp7D6ab3SkT4r+4POAC4umZ6MbC41XG1sD2+DbyUdPf9LnneLsCq/PiLwBE19Z+o101/pPuGrgEOAq4ARLr7d2r9+4Z05d8B+fHUXE+t3oYK2mQ74Pb6bevl9wowC1gN7JBf+yuAQ7rpveIjjsaGX/hha/K8npMPm58DLAd2jog7c9GfgJ3z415pr88CHwQez9M7AvdFxFCert3uJ9okl6/P9bvNHGAdcEE+hXeupG3p4fdKRKwFPg38AbiT9NqvoIveK04cNiJJTwG+Abw7Iu6vLYv09ahnruWW9ErgLxGxotWxtJmpwL7A5yPiOcBDPHlaCujJ98r2pMFX5wBPA7YljfLdNZw4Guv5oU0kbU5KGhdHxOV59p8l7ZLLdwH+kuf3Qnu9EHi1pDtIozIfRDq3PyMPlwMbb/dIw+l0mzXAmohYnqeXkBJJL79XXgLcHhHrIuJR4HLS+6dr3itOHI319NAmeWj784BbI+IzNUW1Q8QcSer7GJ7/5nzFzP7A+prTFF0hIhZHxOyI6CO9H5ZFxBuAa0nD5cCmbdJoOJ2uEhF/AlZLekaedTBpxIeefa+QTlHtL2mb/FkabpPuea+0upOlXf+AlwO/AX4HfKTV8Uzytr+IdGrhZuDn+e/lpPOu1wC/BX4I7JDri3QV2u+AX5KuJmn5dlTYPgcCV+THe5DGURsEvg5smedvlacHc/kerY67wvZ4NjCQ3y/fArbv9fcK8Ang18CvgIuALbvpveIhR8zMrBSfqjIzs1KcOMzMrBQnDjMzK8WJw8zMSnHiMDOzUpw4zMZB0mOSfiZR03EAAAHPSURBVF7z1zeOdRzWY4NnWpeo7KdjzbrcXyPi2RNcx2GkAfBuKbqApKnx5HhHZi3hIw6zJpH0XEnXS1oh6eqaITfeJulGSb+Q9I18R/ELgFcD/5qPWPaUdJ2k/rzMTnl4EyQdJWmppGXANZK2lXS+pBvywIILWrXN1pucOMzGZ+ua01TfzGN7/T9gYUQ8FzgfODXXvTwinhcRw79VcXRE/BdpqIkPRMSzI+J3YzzfvnndLwY+QhqWYj/gf5GSz7YVbKNZQz5VZTY+G52qkrQPsA/wgzQ8EVNIQ2oD7CPpFGAG8BTS7y+U9YOIuCc/fhlpwMX35+mtgN3Y+AemzCrjxGHWHAJWRsQBDcq+DBwWEb+QdBRprKtGhnjyLMBWdWUP1T3XayNi1bijNZsAn6oya45VwExJB0Aall7S3rlsGnBnPp31hpplHshlw+4AnpsfL2RkVwPvyiOvIuk5Ew/frDgnDrMmiIgNpJ396ZJ+QRpR+AW5+ETSLyj+J2nE1GGXAB/IHdx7kn417p8l3QTsNMrT/QuwOXCzpJV52mzSeHRcMzMrxUccZmZWihOHmZmV4sRhZmalOHGYmVkpThxmZlaKE4eZmZXixGFmZqX8N0SJfyBrYnrGAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LZVQAiJhSyw"
      },
      "source": [
        "### Majority vote classification\n",
        "\n",
        "We'll just take all our previous models [GLM, GLM+adaboost, decision tree, decision tree+adaboost, SVM and random forest] and produce an ensemble -- see if that improves performance. \n",
        "\n",
        "\n",
        "As a small note -- we did try a \"soft\" voting approach [predicts class based on _argmax(sum(predicted class probabilities))_ ] but found that it did not execute properly, so we use \"hard\" voting here. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6SX6dqWhSj6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3813d511-c296-4ba5-a730-7b9c8bbd3325"
      },
      "source": [
        "# set up the majority vote from all our previous models [without adaboost]\n",
        "# \"hard\" voting just means that we predict the label for each data point using the labels from each constituent classifier\n",
        "majvote = VotingClassifier(estimators=[('glm', LR), ('LA', LRAda), ('dt', dectree), ('da', decAda), ('svm', supportvm), ('rf', randomforest)], voting='hard')\n",
        "\n",
        "# predict the test data's labels\n",
        "majpred = majvote.fit(xtrain, ytrain).predict(xtest)\n",
        "\n",
        "# calculate the percent error--errors/(size of test set)*100\n",
        "majerror = ((majpred != ytest).sum()/len(xtest))*100"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KB0QUZ4AEgC"
      },
      "source": [
        "What's our error rate?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tw5zryAMAFog",
        "outputId": "b9fbe227-b858-4e53-9a78-389e3691d36f"
      },
      "source": [
        "# How many errors did we get?\n",
        "print(\"Out of \"+str(len(xtest))+\" points, the majority vote produced \"+str((majpred != ytest).sum())+\" errors, resulting in an error rate of \" + str(majerror)+\"%.\")"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Out of 3471 points, the majority vote produced 403 errors, resulting in an error rate of 11.610486891385769%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YN9enJ19EFMm"
      },
      "source": [
        "#### K-fold cross validation for majority vote"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwYc8Xx9EJR3",
        "outputId": "731b5714-022a-47cc-8d6c-ce30c4760e6c"
      },
      "source": [
        "# prepare the cross-validation procedure\n",
        "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "\n",
        "# get the task and associated labels\n",
        "task = datasets[taskind]\n",
        "lab = labels[taskind]\n",
        "\n",
        "# evaluate model--n_jobs = -1 means to use all processors\n",
        "# see https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html \n",
        "rfScores = cross_val_score(majvote, taskind, lab, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\n",
        "# report performance--we take the average accuracy over all folds. 1- just gives us the error rate\n",
        "print(\"The k-fold cross-validated error rate is \" + str((1-np.mean(rfScores))*100)+ \"%.\")"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The k-fold cross-validated error rate is 11.472233104945673%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RN5x0V2wwVIz"
      },
      "source": [
        "#### ROC/AUC measurements for majority vote\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "NIF8fDO_qYUY",
        "outputId": "651ef252-dc96-4acd-d3bb-a3af423743bc"
      },
      "source": [
        "# get false positive/true positive rates\n",
        "fpr, tpr, threshold = metrics.roc_curve(ytest, majpred)\n",
        "\n",
        "# get roc/auc measurements\n",
        "majvote_auc = roc_auc_score(ytest, majpred)\n",
        "print('Majority vote: ROC AUC=%.3f' % (majvote_auc))\n",
        "\n",
        "# plot ROC/AUC\n",
        "plt.title('ROC for majority vote')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % majvote_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "\n",
        "# plot a dotted line for the threshold\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "\n",
        "# set axes limits and labels\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Majority vote: ROC AUC=0.506\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f06p0JZmnac"
      },
      "source": [
        "##### Feature importance for majority vote\n",
        "\n",
        "We couldn't find a way to calculate feature importance here. Additionally, since we are using a SVM with nonlinear kernel as part of the majority voter it doesn't make much sense to do so anyway. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUYZranaXDuE"
      },
      "source": [
        "## Analyzing data structure and labels from the non-text LABEVENTS data matrix\n",
        "\n",
        "We wanted to take a look at the data matrix structure to understand why its performance was so poor. We thought that it may have been due to a large amount of NA values throughout the matrix. Coupled with our imputation procedure [substitute NA with column mean] it seems that the LABEVENTS data is not very effective at classifying. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0u4EXYmwlIIt"
      },
      "source": [
        "### Looking at NA values throughout the matrix\n",
        "\n",
        "We noticed that our non-text matrix has a lot of NA values. We calculated  the percent of non-NA values by column as a result -- we realized that a lot of values are either all-NA or are nearly all-NA. This is a caveat of our work! When we fill NA values with the mean from each column it looks like, in the case of many columns, those means are based on a small fraction of values and most of the column consists of these imputed values. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "lKGEypHNXCZQ",
        "outputId": "8af4ca34-2aa4-44a1-850e-6ebc4a2a2f9a"
      },
      "source": [
        "# looks like all the rows have na values somewhere...so we'll have to deal with that\n",
        "n = nontext.dropna()\n",
        "\n",
        "# figure out the % of non-NAs per column and plot it\n",
        "# see here https://stackoverflow.com/questions/22257527/how-do-i-get-a-summary-count-of-missing-nan-data-by-column-in-pandas\n",
        "\n",
        "# calculate % non-NA [hence the 1-]\n",
        "nacount = (1-(nontext.isnull().sum()/len(nontext)))*100\n",
        "\n",
        "# plot as a bar chart\n",
        "plt.bar([x for x in range(len(nacount))], nacount, color=\"r\")\n",
        "plt.xlabel(\"Features\")\n",
        "plt.ylabel(\"Percent non-NA\")\n",
        "plt.title(\"Percent non-NA values for LABEVENTS data matrix\")\n",
        "plt.show()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}